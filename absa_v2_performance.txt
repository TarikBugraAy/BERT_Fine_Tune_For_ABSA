Using device: cuda:0
GPU in use: NVIDIA GeForce RTX 4060 Laptop GPU
Starting to train ABSA model...
Starting ABSA Training...
Epoch 1/10...
  Batch 10/226 - Loss: 0.9920
  Batch 20/226 - Loss: 1.1363
  Batch 30/226 - Loss: 0.9188
  Batch 40/226 - Loss: 1.1420
  Batch 50/226 - Loss: 0.9132
  Batch 60/226 - Loss: 1.1840
  Batch 70/226 - Loss: 0.8379
  Batch 80/226 - Loss: 1.0445
  Batch 90/226 - Loss: 0.8811
  Batch 100/226 - Loss: 1.0093
  Batch 110/226 - Loss: 1.0700
  Batch 120/226 - Loss: 0.7045
  Batch 130/226 - Loss: 0.7475
  Batch 140/226 - Loss: 0.9264
  Batch 150/226 - Loss: 0.9248
  Batch 160/226 - Loss: 0.7990
  Batch 170/226 - Loss: 0.6599
  Batch 180/226 - Loss: 0.7852
  Batch 190/226 - Loss: 1.1386
  Batch 200/226 - Loss: 0.9940
  Batch 210/226 - Loss: 0.7953
  Batch 220/226 - Loss: 1.2030
Epoch 1 completed. Average Loss: 0.9547
  Validating...
  Validation Loss: 0.9291
  Model saved with improved validation loss.
Epoch 2/10...
  Batch 10/226 - Loss: 0.8994
  Batch 210/226 - Loss: 0.7953
  Batch 220/226 - Loss: 1.2030
Epoch 1 completed. Average Loss: 0.9547
  Validating...
  Validation Loss: 0.9291
  Model saved with improved validation loss.
Epoch 2/10...
  Batch 10/226 - Loss: 0.8994
  Batch 20/226 - Loss: 1.1399
  Batch 30/226 - Loss: 0.9502
  Batch 40/226 - Loss: 0.8395
  Batch 210/226 - Loss: 0.7953
  Batch 220/226 - Loss: 1.2030
Epoch 1 completed. Average Loss: 0.9547
  Validating...
  Validation Loss: 0.9291
  Model saved with improved validation loss.
Epoch 2/10...
  Batch 10/226 - Loss: 0.8994
  Batch 20/226 - Loss: 1.1399
  Batch 30/226 - Loss: 0.9502
  Batch 220/226 - Loss: 1.2030
Epoch 1 completed. Average Loss: 0.9547
  Validating...
  Validation Loss: 0.9291
  Model saved with improved validation loss.
Epoch 2/10...
  Batch 10/226 - Loss: 0.8994
  Validating...
  Validation Loss: 0.9291
  Model saved with improved validation loss.
Epoch 2/10...
  Batch 10/226 - Loss: 0.8994
  Validation Loss: 0.9291
  Model saved with improved validation loss.
Epoch 2/10...
  Batch 10/226 - Loss: 0.8994
  Batch 20/226 - Loss: 1.1399
  Model saved with improved validation loss.
Epoch 2/10...
  Batch 10/226 - Loss: 0.8994
  Batch 20/226 - Loss: 1.1399
  Batch 30/226 - Loss: 0.9502
  Batch 40/226 - Loss: 0.8395
  Batch 50/226 - Loss: 1.4908
  Batch 60/226 - Loss: 0.9921
  Batch 20/226 - Loss: 1.1399
  Batch 30/226 - Loss: 0.9502
  Batch 40/226 - Loss: 0.8395
  Batch 50/226 - Loss: 1.4908
  Batch 60/226 - Loss: 0.9921
  Batch 30/226 - Loss: 0.9502
  Batch 40/226 - Loss: 0.8395
  Batch 50/226 - Loss: 1.4908
  Batch 60/226 - Loss: 0.9921
  Batch 70/226 - Loss: 0.9496
  Batch 80/226 - Loss: 0.9237
  Batch 90/226 - Loss: 1.2192
  Batch 60/226 - Loss: 0.9921
  Batch 70/226 - Loss: 0.9496
  Batch 80/226 - Loss: 0.9237
  Batch 90/226 - Loss: 1.2192
  Batch 100/226 - Loss: 0.9055
  Batch 70/226 - Loss: 0.9496
  Batch 80/226 - Loss: 0.9237
  Batch 90/226 - Loss: 1.2192
  Batch 100/226 - Loss: 0.9055
  Batch 90/226 - Loss: 1.2192
  Batch 100/226 - Loss: 0.9055
  Batch 100/226 - Loss: 0.9055
  Batch 110/226 - Loss: 1.0763
  Batch 120/226 - Loss: 1.1992
  Batch 130/226 - Loss: 1.0796
  Batch 130/226 - Loss: 1.0796
  Batch 140/226 - Loss: 0.9945
  Batch 150/226 - Loss: 1.0828
  Batch 150/226 - Loss: 1.0828
  Batch 160/226 - Loss: 1.0133
  Batch 170/226 - Loss: 1.2633
  Batch 180/226 - Loss: 0.9407
  Batch 190/226 - Loss: 0.9879
  Batch 200/226 - Loss: 1.1179
  Batch 180/226 - Loss: 0.9407
  Batch 190/226 - Loss: 0.9879
  Batch 180/226 - Loss: 0.9407
  Batch 190/226 - Loss: 0.9879
  Batch 200/226 - Loss: 1.1179
  Batch 180/226 - Loss: 0.9407
  Batch 180/226 - Loss: 0.9407
  Batch 190/226 - Loss: 0.9879
  Batch 200/226 - Loss: 1.1179
  Batch 210/226 - Loss: 0.9904
  Batch 220/226 - Loss: 0.9445
Epoch 2 completed. Average Loss: 0.9948
  Validating...
  Validation Loss: 1.2999
Epoch 3/10...
  Batch 10/226 - Loss: 0.9768
  Batch 20/226 - Loss: 0.8514
  Batch 30/226 - Loss: 1.0484
  Batch 40/226 - Loss: 0.8333
  Batch 50/226 - Loss: 1.1000
  Batch 60/226 - Loss: 0.7172
  Batch 70/226 - Loss: 1.1706
  Batch 80/226 - Loss: 1.1298
  Batch 90/226 - Loss: 0.6851
  Batch 100/226 - Loss: 0.6003
  Batch 110/226 - Loss: 0.9226
  Batch 120/226 - Loss: 1.0613
  Batch 130/226 - Loss: 1.0268
  Batch 140/226 - Loss: 0.7967
  Batch 150/226 - Loss: 0.8054
  Batch 160/226 - Loss: 0.7641
  Batch 170/226 - Loss: 0.4432
  Batch 180/226 - Loss: 0.8160
  Batch 190/226 - Loss: 0.4702
  Batch 200/226 - Loss: 0.7395
  Batch 210/226 - Loss: 0.8178
  Batch 220/226 - Loss: 0.7901
Epoch 3 completed. Average Loss: 0.8297
  Validating...
  Validation Loss: 0.8355
  Model saved with improved validation loss.
Epoch 4/10...
  Batch 10/226 - Loss: 0.5526
  Batch 20/226 - Loss: 0.7280
  Batch 30/226 - Loss: 0.3668
  Batch 40/226 - Loss: 0.3517
  Batch 50/226 - Loss: 0.5920
  Batch 60/226 - Loss: 0.3120
  Batch 70/226 - Loss: 0.7225
  Batch 80/226 - Loss: 0.6992
  Batch 90/226 - Loss: 0.7007
  Batch 100/226 - Loss: 0.7614
  Batch 110/226 - Loss: 0.6565
  Batch 120/226 - Loss: 0.2892
  Batch 130/226 - Loss: 0.8928
  Batch 140/226 - Loss: 0.6179
  Batch 150/226 - Loss: 0.5225
  Batch 160/226 - Loss: 0.8194
  Batch 170/226 - Loss: 0.4387
  Batch 180/226 - Loss: 0.5467
  Batch 190/226 - Loss: 0.8898
  Batch 200/226 - Loss: 0.5692
  Batch 210/226 - Loss: 0.5001
  Batch 220/226 - Loss: 0.6567
Epoch 4 completed. Average Loss: 0.6191
  Validating...
  Validation Loss: 1.2182
Epoch 5/10...
  Batch 10/226 - Loss: 0.6760
  Batch 20/226 - Loss: 0.5263
  Batch 30/226 - Loss: 0.3299
  Batch 40/226 - Loss: 0.8179
  Batch 50/226 - Loss: 0.1301
  Batch 60/226 - Loss: 0.4692
  Batch 70/226 - Loss: 0.2835
  Batch 80/226 - Loss: 0.3942
  Batch 90/226 - Loss: 0.4300
  Batch 100/226 - Loss: 0.4579
  Batch 110/226 - Loss: 0.5771
  Batch 120/226 - Loss: 0.1371
  Batch 130/226 - Loss: 0.4773
  Batch 140/226 - Loss: 0.5772
  Batch 150/226 - Loss: 0.5651
  Batch 160/226 - Loss: 0.3974
  Batch 170/226 - Loss: 0.3171
  Batch 180/226 - Loss: 0.4173
  Batch 190/226 - Loss: 0.4719
  Batch 200/226 - Loss: 0.6433
  Batch 210/226 - Loss: 0.3254
  Batch 220/226 - Loss: 0.8288
Epoch 5 completed. Average Loss: 0.4979
  Validating...
  Validation Loss: 0.8557
Epoch 6/10...
  Batch 10/226 - Loss: 0.2380
  Batch 20/226 - Loss: 0.3652
  Batch 30/226 - Loss: 1.0123
  Batch 40/226 - Loss: 0.3305
  Batch 50/226 - Loss: 1.1284
  Batch 60/226 - Loss: 0.5559
  Batch 70/226 - Loss: 0.6193
  Batch 80/226 - Loss: 0.4999
  Batch 90/226 - Loss: 0.3499
  Batch 100/226 - Loss: 0.3872
  Batch 110/226 - Loss: 0.2948
  Batch 120/226 - Loss: 0.2554
  Batch 130/226 - Loss: 0.4579
  Batch 140/226 - Loss: 0.4992
  Batch 150/226 - Loss: 0.2108
  Batch 160/226 - Loss: 0.3087
  Batch 170/226 - Loss: 0.2315
  Batch 180/226 - Loss: 0.3861
  Batch 190/226 - Loss: 0.2565
  Batch 200/226 - Loss: 0.1557
  Batch 210/226 - Loss: 0.2733
  Batch 220/226 - Loss: 0.1324
Epoch 6 completed. Average Loss: 0.4028
  Validating...
  Validation Loss: 1.0737
Epoch 7/10...
  Batch 10/226 - Loss: 0.2651
  Batch 20/226 - Loss: 0.2570
  Batch 30/226 - Loss: 0.2133
  Batch 40/226 - Loss: 0.5080
  Batch 50/226 - Loss: 0.1671
  Batch 60/226 - Loss: 0.2545
  Batch 70/226 - Loss: 0.8829
  Batch 80/226 - Loss: 0.4931
  Batch 90/226 - Loss: 0.2767
  Batch 100/226 - Loss: 0.1382
  Batch 110/226 - Loss: 0.4565
  Batch 120/226 - Loss: 0.1517
  Batch 130/226 - Loss: 0.5288
  Batch 140/226 - Loss: 0.3045
  Batch 150/226 - Loss: 0.1525
  Batch 160/226 - Loss: 0.3639
  Batch 170/226 - Loss: 0.2476
  Batch 180/226 - Loss: 0.0960
  Batch 190/226 - Loss: 0.2142
  Batch 200/226 - Loss: 0.6656
  Batch 210/226 - Loss: 0.3827
  Batch 220/226 - Loss: 0.7194
Epoch 7 completed. Average Loss: 0.3014
  Validating...
  Validation Loss: 1.0900
Epoch 8/10...
  Batch 10/226 - Loss: 0.3677
  Batch 20/226 - Loss: 0.1592
  Batch 30/226 - Loss: 0.0287
  Batch 40/226 - Loss: 0.1527
  Batch 50/226 - Loss: 0.6889
  Batch 60/226 - Loss: 0.2148
  Batch 70/226 - Loss: 0.0442
  Batch 80/226 - Loss: 0.5044
  Batch 90/226 - Loss: 0.1455
  Batch 100/226 - Loss: 0.1916
  Batch 110/226 - Loss: 0.0684
  Batch 120/226 - Loss: 0.0851
  Batch 130/226 - Loss: 0.4236
  Batch 140/226 - Loss: 0.2117
  Batch 150/226 - Loss: 0.4213
  Batch 160/226 - Loss: 0.2723
  Batch 170/226 - Loss: 0.1059
  Batch 180/226 - Loss: 0.2724
  Batch 190/226 - Loss: 0.2169
  Batch 200/226 - Loss: 0.1182
  Batch 210/226 - Loss: 0.5739
  Batch 220/226 - Loss: 0.0424
Epoch 8 completed. Average Loss: 0.2355
  Validating...
  Validation Loss: 0.8599
Epoch 9/10...
  Batch 10/226 - Loss: 0.2513
  Batch 20/226 - Loss: 0.2674
  Batch 30/226 - Loss: 0.0723
  Batch 40/226 - Loss: 0.1043
  Batch 50/226 - Loss: 0.0399
  Batch 60/226 - Loss: 0.0601
  Batch 70/226 - Loss: 0.5359
  Batch 80/226 - Loss: 0.2059
  Batch 90/226 - Loss: 0.0426
  Batch 100/226 - Loss: 0.0246
  Batch 110/226 - Loss: 0.5280
  Batch 120/226 - Loss: 0.1294
  Batch 130/226 - Loss: 0.4932
  Batch 140/226 - Loss: 0.0214
  Batch 150/226 - Loss: 0.2838
  Batch 160/226 - Loss: 0.0606
  Batch 170/226 - Loss: 0.0300
  Batch 180/226 - Loss: 0.2236
  Batch 190/226 - Loss: 0.2233
  Batch 200/226 - Loss: 0.2000
  Batch 210/226 - Loss: 0.2865
  Batch 220/226 - Loss: 0.1850
Epoch 9 completed. Average Loss: 0.1845
  Validating...
  Validation Loss: 0.9753
Epoch 10/10...
  Batch 10/226 - Loss: 0.0856
  Batch 20/226 - Loss: 0.0282
  Batch 30/226 - Loss: 0.1575
  Batch 40/226 - Loss: 0.3391
  Batch 50/226 - Loss: 0.0377
  Batch 60/226 - Loss: 0.1632
  Batch 70/226 - Loss: 0.0258
  Batch 80/226 - Loss: 0.1518
  Batch 90/226 - Loss: 0.2873
  Batch 100/226 - Loss: 0.0209
  Batch 110/226 - Loss: 0.6510
  Batch 120/226 - Loss: 0.1773
  Batch 130/226 - Loss: 0.1875
  Batch 140/226 - Loss: 0.1994
  Batch 150/226 - Loss: 0.0232
  Batch 160/226 - Loss: 0.0764
  Batch 170/226 - Loss: 0.2648
  Batch 180/226 - Loss: 0.0559
  Batch 190/226 - Loss: 0.0266
  Batch 200/226 - Loss: 0.4502
  Batch 210/226 - Loss: 0.0371
  Batch 220/226 - Loss: 0.1522
Epoch 10 completed. Average Loss: 0.1637
  Validating...
  Validation Loss: 1.0210
ABSA Training Completed.
Starting to test ABSA model...
              precision    recall  f1-score   support

    Negative       0.80      0.73      0.76       196
     Neutral       0.65      0.46      0.54       196
    Positive       0.87      0.96      0.91       727

    accuracy                           0.83      1119
   macro avg       0.77      0.72      0.74      1119
weighted avg       0.82      0.83      0.82      1119