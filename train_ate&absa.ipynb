{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the current working directory (notebooks do not have __file__)\n",
    "data_path = os.path.join(os.getcwd(), 'data')\n",
    "sys.path.append(data_path)\n",
    "\n",
    "\n",
    "#Use this one if you are running the code from a script not a notebook\n",
    "# import sys\n",
    "# import os\n",
    "\n",
    "# # Add the 'data' directory to the Python path\n",
    "# data_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'data')\n",
    "# sys.path.append(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emink\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from model.bert import bert_ATE, bert_ABSA\n",
    "\n",
    "from dataset import dataset_ATM, dataset_ABSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from transformers import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emink\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#pretrain_model_name = \"bert-base-uncased\"\n",
    "pretrain_model_name = \"bert-large-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(pretrain_model_name)\n",
    "lr = 2e-5\n",
    "model_ATE = bert_ATE(pretrain_model_name).to(DEVICE)\n",
    "optimizer_ATE = torch.optim.Adam(model_ATE.parameters(), lr=lr)\n",
    "#model_ABSA = bert_ABSA(pretrain_model_name).to(DEVICE)\n",
    "model_ABSA = bert_ABSA(pretrain_model_name, DEVICE).to(DEVICE)\n",
    "#optimizer_ABSA = torch.optim.Adam(model_ABSA.parameters(), lr=lr)\n",
    "optimizer_ABSA = AdamW(\n",
    "    model_ABSA.parameters(), \n",
    "    lr=lr, \n",
    "    weight_decay=1e-4  # or 1e-5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evl_time(t):\n",
    "    min, sec= divmod(t, 60)\n",
    "    hr, min = divmod(min, 60)\n",
    "    return int(hr), int(min), int(sec)\n",
    "\n",
    "def load_model(model, path):\n",
    "    model.load_state_dict(torch.load(path), strict=False)\n",
    "    return model\n",
    "    \n",
    "def save_model(model, name):\n",
    "    torch.save(model.state_dict(), name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acpect Term Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "restaurants_train_ds = dataset_ATM(pd.read_csv(\"data/restaurants_train.csv\"), tokenizer)\n",
    "restaurants_test_ds = dataset_ATM(pd.read_csv(\"data/restaurants_test.csv\"), tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds = ConcatDataset([restaurants_train_ds])\n",
    "# test_ds = ConcatDataset([restaurants_test_ds])\n",
    "\n",
    "train_ds =restaurants_train_ds\n",
    "test_ds = restaurants_test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mini_batch(samples):\n",
    "    ids_tensors = [s[1] for s in samples]\n",
    "    ids_tensors = pad_sequence(ids_tensors, batch_first=True)\n",
    "\n",
    "    tags_tensors = [s[2] for s in samples]\n",
    "    tags_tensors = pad_sequence(tags_tensors, batch_first=True)\n",
    "\n",
    "    pols_tensors = [s[3] for s in samples]\n",
    "    pols_tensors = pad_sequence(pols_tensors, batch_first=True)\n",
    "    \n",
    "    masks_tensors = torch.zeros(ids_tensors.shape, dtype=torch.long)\n",
    "    masks_tensors = masks_tensors.masked_fill(ids_tensors != 0, 1)\n",
    "    \n",
    "    return ids_tensors, tags_tensors, pols_tensors, masks_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size=5, collate_fn=create_mini_batch, shuffle = True)\n",
    "test_loader = DataLoader(test_ds, batch_size=50, collate_fn=create_mini_batch, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in train_loader:\n",
    "#     w,x,y,z = batch\n",
    "#     print(w)\n",
    "#     print(w.size())\n",
    "#     print(x)\n",
    "#     print(x.size())\n",
    "#     print(y)\n",
    "#     print(y.size())\n",
    "#     print(z)\n",
    "#     print(z.size())\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_ATE(loader, epochs):\n",
    "    all_data = len(loader)\n",
    "    for epoch in range(epochs):\n",
    "        finish_data = 0\n",
    "        losses = []\n",
    "        current_times = []\n",
    "        correct_predictions = 0\n",
    "        \n",
    "        for data in loader:\n",
    "            t0 = time.time()\n",
    "            ids_tensors, tags_tensors, _, masks_tensors = data\n",
    "            ids_tensors = ids_tensors.to(DEVICE)\n",
    "            tags_tensors = tags_tensors.to(DEVICE)\n",
    "            masks_tensors = masks_tensors.to(DEVICE)\n",
    "\n",
    "            loss = model_ATE(ids_tensors=ids_tensors, tags_tensors=tags_tensors, masks_tensors=masks_tensors)\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer_ATE.step()\n",
    "            optimizer_ATE.zero_grad()\n",
    "\n",
    "            finish_data += 1\n",
    "            current_times.append(round(time.time()-t0,3))\n",
    "            current = np.mean(current_times)\n",
    "            hr, min, sec = evl_time(current*(all_data-finish_data) + current*all_data*(epochs-epoch-1))\n",
    "            print('epoch:', epoch, \" batch:\", finish_data, \"/\" , all_data, \" loss:\", np.mean(losses), \" hr:\", hr, \" min:\", min,\" sec:\", sec)         \n",
    "\n",
    "        save_model(model_ATE, 'bert_ATE.pkl')\n",
    "        \n",
    "def test_model_ATE(loader):\n",
    "    pred = []\n",
    "    trueth = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "\n",
    "            ids_tensors, tags_tensors, _, masks_tensors = data\n",
    "            ids_tensors = ids_tensors.to(DEVICE)\n",
    "            tags_tensors = tags_tensors.to(DEVICE)\n",
    "            masks_tensors = masks_tensors.to(DEVICE)\n",
    "\n",
    "            outputs = model_ATE(ids_tensors=ids_tensors, tags_tensors=None, masks_tensors=masks_tensors)\n",
    "\n",
    "            _, predictions = torch.max(outputs, dim=2)\n",
    "\n",
    "            pred += list([int(j) for i in predictions for j in i ])\n",
    "            trueth += list([int(j) for i in tags_tensors for j in i ])\n",
    "\n",
    "    return trueth, pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  batch: 1 / 721  loss: 1.1760302782058716  hr: 2  min: 47  sec: 3\n",
      "epoch: 0  batch: 2 / 721  loss: 1.0005813837051392  hr: 2  min: 21  sec: 39\n",
      "epoch: 0  batch: 3 / 721  loss: 0.8143057525157928  hr: 2  min: 1  sec: 17\n",
      "epoch: 0  batch: 4 / 721  loss: 0.7612844333052635  hr: 1  min: 50  sec: 0\n",
      "epoch: 0  batch: 5 / 721  loss: 0.7228415668010711  hr: 1  min: 43  sec: 34\n",
      "epoch: 0  batch: 6 / 721  loss: 0.6985220064719518  hr: 1  min: 40  sec: 21\n",
      "epoch: 0  batch: 7 / 721  loss: 0.6895694264343807  hr: 1  min: 37  sec: 2\n",
      "epoch: 0  batch: 8 / 721  loss: 0.6649655289947987  hr: 1  min: 37  sec: 6\n",
      "epoch: 0  batch: 9 / 721  loss: 0.6353972984684838  hr: 1  min: 39  sec: 36\n",
      "epoch: 0  batch: 10 / 721  loss: 0.611596867442131  hr: 1  min: 40  sec: 21\n",
      "epoch: 0  batch: 11 / 721  loss: 0.5791776857592843  hr: 1  min: 41  sec: 40\n",
      "epoch: 0  batch: 12 / 721  loss: 0.5523741270105044  hr: 1  min: 41  sec: 29\n",
      "epoch: 0  batch: 13 / 721  loss: 0.5363121903859652  hr: 1  min: 42  sec: 29\n",
      "epoch: 0  batch: 14 / 721  loss: 0.5100677332707814  hr: 1  min: 43  sec: 18\n",
      "epoch: 0  batch: 15 / 721  loss: 0.49625723361968993  hr: 1  min: 43  sec: 26\n",
      "epoch: 0  batch: 16 / 721  loss: 0.48866856284439564  hr: 1  min: 43  sec: 58\n",
      "epoch: 0  batch: 17 / 721  loss: 0.47613193182384267  hr: 1  min: 43  sec: 15\n",
      "epoch: 0  batch: 18 / 721  loss: 0.4620092676745521  hr: 1  min: 45  sec: 12\n",
      "epoch: 0  batch: 19 / 721  loss: 0.46763048987639577  hr: 1  min: 44  sec: 4\n",
      "epoch: 0  batch: 20 / 721  loss: 0.45867025703191755  hr: 1  min: 43  sec: 39\n",
      "epoch: 0  batch: 21 / 721  loss: 0.45775950238818214  hr: 1  min: 43  sec: 32\n",
      "epoch: 0  batch: 22 / 721  loss: 0.44820380075411365  hr: 1  min: 43  sec: 24\n",
      "epoch: 0  batch: 23 / 721  loss: 0.44039259267889935  hr: 1  min: 43  sec: 16\n",
      "epoch: 0  batch: 24 / 721  loss: 0.43452300255497295  hr: 1  min: 43  sec: 21\n",
      "epoch: 0  batch: 25 / 721  loss: 0.423542212843895  hr: 1  min: 43  sec: 56\n",
      "epoch: 0  batch: 26 / 721  loss: 0.41659911893881285  hr: 1  min: 43  sec: 59\n",
      "epoch: 0  batch: 27 / 721  loss: 0.41699874842608414  hr: 1  min: 43  sec: 27\n",
      "epoch: 0  batch: 28 / 721  loss: 0.41119119205645155  hr: 1  min: 42  sec: 27\n",
      "epoch: 0  batch: 29 / 721  loss: 0.41142643731215905  hr: 1  min: 41  sec: 43\n",
      "epoch: 0  batch: 30 / 721  loss: 0.4030487765868505  hr: 1  min: 41  sec: 6\n",
      "epoch: 0  batch: 31 / 721  loss: 0.40026078781773966  hr: 1  min: 40  sec: 28\n",
      "epoch: 0  batch: 32 / 721  loss: 0.39700216613709927  hr: 1  min: 40  sec: 6\n",
      "epoch: 0  batch: 33 / 721  loss: 0.3983787840062922  hr: 1  min: 39  sec: 53\n",
      "epoch: 0  batch: 34 / 721  loss: 0.39372171198620515  hr: 1  min: 39  sec: 50\n",
      "epoch: 0  batch: 35 / 721  loss: 0.39340871231896535  hr: 1  min: 39  sec: 43\n",
      "epoch: 0  batch: 36 / 721  loss: 0.3941144487924046  hr: 1  min: 38  sec: 55\n",
      "epoch: 0  batch: 37 / 721  loss: 0.39141721016651876  hr: 1  min: 38  sec: 6\n",
      "epoch: 0  batch: 38 / 721  loss: 0.38916487678101186  hr: 1  min: 37  sec: 43\n",
      "epoch: 0  batch: 39 / 721  loss: 0.3843813744875101  hr: 1  min: 37  sec: 24\n",
      "epoch: 0  batch: 40 / 721  loss: 0.3818816788494587  hr: 1  min: 36  sec: 42\n",
      "epoch: 0  batch: 41 / 721  loss: 0.38013266281383795  hr: 1  min: 36  sec: 23\n",
      "epoch: 0  batch: 42 / 721  loss: 0.3755704579608781  hr: 1  min: 35  sec: 54\n",
      "epoch: 0  batch: 43 / 721  loss: 0.37091185429761575  hr: 1  min: 35  sec: 34\n",
      "epoch: 0  batch: 44 / 721  loss: 0.3684462136165662  hr: 1  min: 35  sec: 12\n",
      "epoch: 0  batch: 45 / 721  loss: 0.3641804774602254  hr: 1  min: 35  sec: 8\n",
      "epoch: 0  batch: 46 / 721  loss: 0.36107036957274313  hr: 1  min: 34  sec: 55\n",
      "epoch: 0  batch: 47 / 721  loss: 0.3572279221199928  hr: 1  min: 34  sec: 55\n",
      "epoch: 0  batch: 48 / 721  loss: 0.35596226652463275  hr: 1  min: 34  sec: 29\n",
      "epoch: 0  batch: 49 / 721  loss: 0.3523838964043831  hr: 1  min: 34  sec: 45\n",
      "epoch: 0  batch: 50 / 721  loss: 0.3486375650763512  hr: 1  min: 34  sec: 28\n",
      "epoch: 0  batch: 51 / 721  loss: 0.3470960940216102  hr: 1  min: 34  sec: 1\n",
      "epoch: 0  batch: 52 / 721  loss: 0.34486934485343784  hr: 1  min: 33  sec: 45\n",
      "epoch: 0  batch: 53 / 721  loss: 0.3432253677889986  hr: 1  min: 33  sec: 51\n",
      "epoch: 0  batch: 54 / 721  loss: 0.3443527000921744  hr: 1  min: 33  sec: 28\n",
      "epoch: 0  batch: 55 / 721  loss: 0.34381186962127686  hr: 1  min: 33  sec: 12\n",
      "epoch: 0  batch: 56 / 721  loss: 0.34121739624866415  hr: 1  min: 32  sec: 58\n",
      "epoch: 0  batch: 57 / 721  loss: 0.3400087024559054  hr: 1  min: 32  sec: 50\n",
      "epoch: 0  batch: 58 / 721  loss: 0.3386060608358219  hr: 1  min: 32  sec: 59\n",
      "epoch: 0  batch: 59 / 721  loss: 0.33660436636310515  hr: 1  min: 32  sec: 43\n",
      "epoch: 0  batch: 60 / 721  loss: 0.33403768986463545  hr: 1  min: 32  sec: 28\n",
      "epoch: 0  batch: 61 / 721  loss: 0.3317973254645457  hr: 1  min: 32  sec: 16\n",
      "epoch: 0  batch: 62 / 721  loss: 0.33170527532216043  hr: 1  min: 32  sec: 34\n",
      "epoch: 0  batch: 63 / 721  loss: 0.32779544686514234  hr: 1  min: 32  sec: 18\n",
      "epoch: 0  batch: 64 / 721  loss: 0.32619576272554696  hr: 1  min: 32  sec: 6\n",
      "epoch: 0  batch: 65 / 721  loss: 0.3240740111240974  hr: 1  min: 31  sec: 56\n",
      "epoch: 0  batch: 66 / 721  loss: 0.3218077586004228  hr: 1  min: 31  sec: 31\n",
      "epoch: 0  batch: 67 / 721  loss: 0.319775151672648  hr: 1  min: 31  sec: 24\n",
      "epoch: 0  batch: 68 / 721  loss: 0.31727927156230984  hr: 1  min: 31  sec: 15\n",
      "epoch: 0  batch: 69 / 721  loss: 0.31457435026548913  hr: 1  min: 31  sec: 7\n",
      "epoch: 0  batch: 70 / 721  loss: 0.3124089419841766  hr: 1  min: 31  sec: 2\n",
      "epoch: 0  batch: 71 / 721  loss: 0.31227779178552223  hr: 1  min: 31  sec: 6\n",
      "epoch: 0  batch: 72 / 721  loss: 0.3133292819062869  hr: 1  min: 30  sec: 53\n",
      "epoch: 0  batch: 73 / 721  loss: 0.3112828939744871  hr: 1  min: 30  sec: 58\n",
      "epoch: 0  batch: 74 / 721  loss: 0.31061915972748316  hr: 1  min: 30  sec: 57\n",
      "epoch: 0  batch: 75 / 721  loss: 0.3078416399161021  hr: 1  min: 30  sec: 52\n",
      "epoch: 0  batch: 76 / 721  loss: 0.30752425758462204  hr: 1  min: 30  sec: 39\n",
      "epoch: 0  batch: 77 / 721  loss: 0.3057721681022025  hr: 1  min: 30  sec: 27\n",
      "epoch: 0  batch: 78 / 721  loss: 0.30345954306614703  hr: 1  min: 30  sec: 15\n",
      "epoch: 0  batch: 79 / 721  loss: 0.3002157764910143  hr: 1  min: 30  sec: 7\n",
      "epoch: 0  batch: 80 / 721  loss: 0.2979182847775519  hr: 1  min: 30  sec: 0\n",
      "epoch: 0  batch: 81 / 721  loss: 0.29577376334755506  hr: 1  min: 30  sec: 18\n",
      "epoch: 0  batch: 82 / 721  loss: 0.2945326713890564  hr: 1  min: 30  sec: 19\n",
      "epoch: 0  batch: 83 / 721  loss: 0.2924591544342328  hr: 1  min: 30  sec: 24\n",
      "epoch: 0  batch: 84 / 721  loss: 0.29049987301585223  hr: 1  min: 30  sec: 18\n",
      "epoch: 0  batch: 85 / 721  loss: 0.28877582716591216  hr: 1  min: 30  sec: 35\n",
      "epoch: 0  batch: 86 / 721  loss: 0.28744171239262406  hr: 1  min: 30  sec: 36\n",
      "epoch: 0  batch: 87 / 721  loss: 0.28672182345869895  hr: 1  min: 30  sec: 24\n",
      "epoch: 0  batch: 88 / 721  loss: 0.2846062494949861  hr: 1  min: 30  sec: 16\n",
      "epoch: 0  batch: 89 / 721  loss: 0.2823138773608743  hr: 1  min: 30  sec: 5\n",
      "epoch: 0  batch: 90 / 721  loss: 0.2815928968290488  hr: 1  min: 29  sec: 57\n",
      "epoch: 0  batch: 91 / 721  loss: 0.27946562655679474  hr: 1  min: 29  sec: 52\n",
      "epoch: 0  batch: 92 / 721  loss: 0.2783660616563714  hr: 1  min: 29  sec: 48\n",
      "epoch: 0  batch: 93 / 721  loss: 0.27625249053842277  hr: 1  min: 29  sec: 43\n",
      "epoch: 0  batch: 94 / 721  loss: 0.27423868494782044  hr: 1  min: 29  sec: 41\n",
      "epoch: 0  batch: 95 / 721  loss: 0.272876351052209  hr: 1  min: 29  sec: 34\n",
      "epoch: 0  batch: 96 / 721  loss: 0.27229770498039824  hr: 1  min: 29  sec: 23\n",
      "epoch: 0  batch: 97 / 721  loss: 0.2711338426188095  hr: 1  min: 29  sec: 27\n",
      "epoch: 0  batch: 98 / 721  loss: 0.27078184736322386  hr: 1  min: 29  sec: 37\n",
      "epoch: 0  batch: 99 / 721  loss: 0.26863179348333915  hr: 1  min: 29  sec: 30\n",
      "epoch: 0  batch: 100 / 721  loss: 0.2668531870096922  hr: 1  min: 29  sec: 21\n",
      "epoch: 0  batch: 101 / 721  loss: 0.2654977398786214  hr: 1  min: 29  sec: 8\n",
      "epoch: 0  batch: 102 / 721  loss: 0.2642354339215101  hr: 1  min: 29  sec: 1\n",
      "epoch: 0  batch: 103 / 721  loss: 0.2628474652911853  hr: 1  min: 28  sec: 56\n",
      "epoch: 0  batch: 104 / 721  loss: 0.26172203090615  hr: 1  min: 28  sec: 47\n",
      "epoch: 0  batch: 105 / 721  loss: 0.2614758016807692  hr: 1  min: 28  sec: 40\n",
      "epoch: 0  batch: 106 / 721  loss: 0.2599267101372188  hr: 1  min: 28  sec: 38\n",
      "epoch: 0  batch: 107 / 721  loss: 0.26027153968532507  hr: 1  min: 28  sec: 32\n",
      "epoch: 0  batch: 108 / 721  loss: 0.2603264210262784  hr: 1  min: 28  sec: 35\n",
      "epoch: 0  batch: 109 / 721  loss: 0.2601165967660213  hr: 1  min: 28  sec: 24\n",
      "epoch: 0  batch: 110 / 721  loss: 0.25943500243804674  hr: 1  min: 28  sec: 25\n",
      "epoch: 0  batch: 111 / 721  loss: 0.25790840038308155  hr: 1  min: 28  sec: 18\n",
      "epoch: 0  batch: 112 / 721  loss: 0.25688854711396353  hr: 1  min: 28  sec: 10\n",
      "epoch: 0  batch: 113 / 721  loss: 0.25602462307541773  hr: 1  min: 28  sec: 15\n",
      "epoch: 0  batch: 114 / 721  loss: 0.2549586880363916  hr: 1  min: 28  sec: 11\n",
      "epoch: 0  batch: 115 / 721  loss: 0.2536821279188861  hr: 1  min: 28  sec: 3\n",
      "epoch: 0  batch: 116 / 721  loss: 0.25254864534684296  hr: 1  min: 27  sec: 59\n",
      "epoch: 0  batch: 117 / 721  loss: 0.2518610511707444  hr: 1  min: 27  sec: 52\n",
      "epoch: 0  batch: 118 / 721  loss: 0.2512075114932101  hr: 1  min: 27  sec: 41\n",
      "epoch: 0  batch: 119 / 721  loss: 0.25021757354505925  hr: 1  min: 27  sec: 37\n",
      "epoch: 0  batch: 120 / 721  loss: 0.2505500600362817  hr: 1  min: 27  sec: 31\n",
      "epoch: 0  batch: 121 / 721  loss: 0.24918641513290485  hr: 1  min: 27  sec: 36\n",
      "epoch: 0  batch: 122 / 721  loss: 0.24771025563116933  hr: 1  min: 27  sec: 29\n",
      "epoch: 0  batch: 123 / 721  loss: 0.24709773457389536  hr: 1  min: 27  sec: 26\n",
      "epoch: 0  batch: 124 / 721  loss: 0.24709525782494776  hr: 1  min: 27  sec: 16\n",
      "epoch: 0  batch: 125 / 721  loss: 0.245861070394516  hr: 1  min: 27  sec: 32\n",
      "epoch: 0  batch: 126 / 721  loss: 0.245055419939851  hr: 1  min: 27  sec: 26\n",
      "epoch: 0  batch: 127 / 721  loss: 0.24397499343072335  hr: 1  min: 27  sec: 16\n",
      "epoch: 0  batch: 128 / 721  loss: 0.24275978095829487  hr: 1  min: 27  sec: 21\n",
      "epoch: 0  batch: 129 / 721  loss: 0.24168449045382728  hr: 1  min: 27  sec: 15\n",
      "epoch: 0  batch: 130 / 721  loss: 0.24179714190272183  hr: 1  min: 27  sec: 7\n",
      "epoch: 0  batch: 131 / 721  loss: 0.240936387188107  hr: 1  min: 27  sec: 0\n",
      "epoch: 0  batch: 132 / 721  loss: 0.24021015288026043  hr: 1  min: 26  sec: 53\n",
      "epoch: 0  batch: 133 / 721  loss: 0.23942832575928896  hr: 1  min: 26  sec: 50\n",
      "epoch: 0  batch: 134 / 721  loss: 0.23849916997462955  hr: 1  min: 26  sec: 57\n",
      "epoch: 0  batch: 135 / 721  loss: 0.23729824942571145  hr: 1  min: 27  sec: 5\n",
      "epoch: 0  batch: 136 / 721  loss: 0.2362825481001945  hr: 1  min: 27  sec: 3\n",
      "epoch: 0  batch: 137 / 721  loss: 0.2352301920526219  hr: 1  min: 27  sec: 3\n",
      "epoch: 0  batch: 138 / 721  loss: 0.2347401076576848  hr: 1  min: 27  sec: 4\n",
      "epoch: 0  batch: 139 / 721  loss: 0.23435935286952436  hr: 1  min: 26  sec: 55\n",
      "epoch: 0  batch: 140 / 721  loss: 0.23351943897349495  hr: 1  min: 26  sec: 50\n",
      "epoch: 0  batch: 141 / 721  loss: 0.2324268953702974  hr: 1  min: 26  sec: 54\n",
      "epoch: 0  batch: 142 / 721  loss: 0.23165218033631083  hr: 1  min: 26  sec: 51\n",
      "epoch: 0  batch: 143 / 721  loss: 0.23101036464209324  hr: 1  min: 26  sec: 46\n",
      "epoch: 0  batch: 144 / 721  loss: 0.23014273096082938  hr: 1  min: 26  sec: 40\n",
      "epoch: 0  batch: 145 / 721  loss: 0.22937038597361795  hr: 1  min: 26  sec: 31\n",
      "epoch: 0  batch: 146 / 721  loss: 0.22841482012443345  hr: 1  min: 26  sec: 31\n",
      "epoch: 0  batch: 147 / 721  loss: 0.22773163917721534  hr: 1  min: 26  sec: 29\n",
      "epoch: 0  batch: 148 / 721  loss: 0.22689486264779762  hr: 1  min: 26  sec: 26\n",
      "epoch: 0  batch: 149 / 721  loss: 0.22666413942039412  hr: 1  min: 26  sec: 22\n",
      "epoch: 0  batch: 150 / 721  loss: 0.22580421457688013  hr: 1  min: 26  sec: 14\n",
      "epoch: 0  batch: 151 / 721  loss: 0.22502340011249314  hr: 1  min: 26  sec: 7\n",
      "epoch: 0  batch: 152 / 721  loss: 0.224847987490265  hr: 1  min: 26  sec: 1\n",
      "epoch: 0  batch: 153 / 721  loss: 0.22390544078513688  hr: 1  min: 26  sec: 3\n",
      "epoch: 0  batch: 154 / 721  loss: 0.22345735263321306  hr: 1  min: 25  sec: 59\n",
      "epoch: 0  batch: 155 / 721  loss: 0.22272153376571593  hr: 1  min: 25  sec: 54\n",
      "epoch: 0  batch: 156 / 721  loss: 0.222045076581148  hr: 1  min: 25  sec: 53\n",
      "epoch: 0  batch: 157 / 721  loss: 0.22144956621015147  hr: 1  min: 25  sec: 55\n",
      "epoch: 0  batch: 158 / 721  loss: 0.22068475799847254  hr: 1  min: 25  sec: 51\n",
      "epoch: 0  batch: 159 / 721  loss: 0.22007372422413257  hr: 1  min: 25  sec: 48\n",
      "epoch: 0  batch: 160 / 721  loss: 0.21978970924392344  hr: 1  min: 25  sec: 46\n",
      "epoch: 0  batch: 161 / 721  loss: 0.21894896048936785  hr: 1  min: 25  sec: 41\n",
      "epoch: 0  batch: 162 / 721  loss: 0.2179406147312235  hr: 1  min: 25  sec: 57\n",
      "epoch: 0  batch: 163 / 721  loss: 0.21738163925753048  hr: 1  min: 26  sec: 2\n",
      "epoch: 0  batch: 164 / 721  loss: 0.21746963825894566  hr: 1  min: 25  sec: 59\n",
      "epoch: 0  batch: 165 / 721  loss: 0.21689122955907475  hr: 1  min: 25  sec: 54\n",
      "epoch: 0  batch: 166 / 721  loss: 0.21683501528508692  hr: 1  min: 25  sec: 47\n",
      "epoch: 0  batch: 167 / 721  loss: 0.2158533013509419  hr: 1  min: 26  sec: 2\n",
      "epoch: 0  batch: 168 / 721  loss: 0.2148311915807426  hr: 1  min: 26  sec: 2\n",
      "epoch: 0  batch: 169 / 721  loss: 0.21415940978558812  hr: 1  min: 26  sec: 0\n",
      "epoch: 0  batch: 170 / 721  loss: 0.21332537753178793  hr: 1  min: 25  sec: 52\n",
      "epoch: 0  batch: 171 / 721  loss: 0.21287073789719949  hr: 1  min: 25  sec: 45\n",
      "epoch: 0  batch: 172 / 721  loss: 0.2118326299932114  hr: 1  min: 25  sec: 55\n",
      "epoch: 0  batch: 173 / 721  loss: 0.21145957527477618  hr: 1  min: 25  sec: 51\n",
      "epoch: 0  batch: 174 / 721  loss: 0.21099532327090187  hr: 1  min: 25  sec: 45\n",
      "epoch: 0  batch: 175 / 721  loss: 0.2103345992735454  hr: 1  min: 25  sec: 40\n",
      "epoch: 0  batch: 176 / 721  loss: 0.20963251374831254  hr: 1  min: 25  sec: 35\n",
      "epoch: 0  batch: 177 / 721  loss: 0.20872319407634815  hr: 1  min: 25  sec: 38\n",
      "epoch: 0  batch: 178 / 721  loss: 0.20843193912355418  hr: 1  min: 25  sec: 33\n",
      "epoch: 0  batch: 179 / 721  loss: 0.20762381534086927  hr: 1  min: 25  sec: 31\n",
      "epoch: 0  batch: 180 / 721  loss: 0.20673521906137465  hr: 1  min: 25  sec: 30\n",
      "epoch: 0  batch: 181 / 721  loss: 0.20614913015405117  hr: 1  min: 25  sec: 28\n",
      "epoch: 0  batch: 182 / 721  loss: 0.20538754548345292  hr: 1  min: 25  sec: 26\n",
      "epoch: 0  batch: 183 / 721  loss: 0.20455447456142942  hr: 1  min: 25  sec: 27\n",
      "epoch: 0  batch: 184 / 721  loss: 0.20378627759687926  hr: 1  min: 25  sec: 28\n",
      "epoch: 0  batch: 185 / 721  loss: 0.20288698894752039  hr: 1  min: 25  sec: 24\n",
      "epoch: 0  batch: 186 / 721  loss: 0.2021542277227166  hr: 1  min: 25  sec: 20\n",
      "epoch: 0  batch: 187 / 721  loss: 0.2015467340295965  hr: 1  min: 25  sec: 13\n",
      "epoch: 0  batch: 188 / 721  loss: 0.20089610075538464  hr: 1  min: 25  sec: 24\n",
      "epoch: 0  batch: 189 / 721  loss: 0.2001209123424752  hr: 1  min: 25  sec: 21\n",
      "epoch: 0  batch: 190 / 721  loss: 0.19938252570205614  hr: 1  min: 25  sec: 20\n",
      "epoch: 0  batch: 191 / 721  loss: 0.19881272278921142  hr: 1  min: 25  sec: 14\n",
      "epoch: 0  batch: 192 / 721  loss: 0.19871186420399076  hr: 1  min: 25  sec: 12\n",
      "epoch: 0  batch: 193 / 721  loss: 0.1981126730344765  hr: 1  min: 25  sec: 12\n",
      "epoch: 0  batch: 194 / 721  loss: 0.1972318257195587  hr: 1  min: 25  sec: 21\n",
      "epoch: 0  batch: 195 / 721  loss: 0.19687764615011522  hr: 1  min: 25  sec: 15\n",
      "epoch: 0  batch: 196 / 721  loss: 0.19612958391520138  hr: 1  min: 25  sec: 13\n",
      "epoch: 0  batch: 197 / 721  loss: 0.195543856591667  hr: 1  min: 25  sec: 7\n",
      "epoch: 0  batch: 198 / 721  loss: 0.19509546269634456  hr: 1  min: 25  sec: 2\n",
      "epoch: 0  batch: 199 / 721  loss: 0.19438699192025855  hr: 1  min: 25  sec: 0\n",
      "epoch: 0  batch: 200 / 721  loss: 0.1937525706458837  hr: 1  min: 24  sec: 55\n",
      "epoch: 0  batch: 201 / 721  loss: 0.1932782272145671  hr: 1  min: 24  sec: 55\n",
      "epoch: 0  batch: 202 / 721  loss: 0.19284789718798187  hr: 1  min: 24  sec: 52\n",
      "epoch: 0  batch: 203 / 721  loss: 0.1923662165060566  hr: 1  min: 24  sec: 46\n",
      "epoch: 0  batch: 204 / 721  loss: 0.19178511648822358  hr: 1  min: 24  sec: 42\n",
      "epoch: 0  batch: 205 / 721  loss: 0.1911178397241889  hr: 1  min: 24  sec: 38\n",
      "epoch: 0  batch: 206 / 721  loss: 0.19059814931372704  hr: 1  min: 24  sec: 31\n",
      "epoch: 0  batch: 207 / 721  loss: 0.19043952859218283  hr: 1  min: 24  sec: 28\n",
      "epoch: 0  batch: 208 / 721  loss: 0.19000589058627015  hr: 1  min: 24  sec: 26\n",
      "epoch: 0  batch: 209 / 721  loss: 0.1894251858129313  hr: 1  min: 24  sec: 26\n",
      "epoch: 0  batch: 210 / 721  loss: 0.1889747789129615  hr: 1  min: 24  sec: 19\n",
      "epoch: 0  batch: 211 / 721  loss: 0.189082767364185  hr: 1  min: 24  sec: 13\n",
      "epoch: 0  batch: 212 / 721  loss: 0.18843971353621697  hr: 1  min: 24  sec: 18\n",
      "epoch: 0  batch: 213 / 721  loss: 0.18783174314374376  hr: 1  min: 24  sec: 13\n",
      "epoch: 0  batch: 214 / 721  loss: 0.18770511544997168  hr: 1  min: 24  sec: 7\n",
      "epoch: 0  batch: 215 / 721  loss: 0.18703004304579524  hr: 1  min: 24  sec: 4\n",
      "epoch: 0  batch: 216 / 721  loss: 0.18697391604763214  hr: 1  min: 24  sec: 1\n",
      "epoch: 0  batch: 217 / 721  loss: 0.18658096229116763  hr: 1  min: 23  sec: 57\n",
      "epoch: 0  batch: 218 / 721  loss: 0.18651770150135144  hr: 1  min: 23  sec: 59\n",
      "epoch: 0  batch: 219 / 721  loss: 0.186013681014583  hr: 1  min: 24  sec: 0\n",
      "epoch: 0  batch: 220 / 721  loss: 0.185439077637751  hr: 1  min: 23  sec: 56\n",
      "epoch: 0  batch: 221 / 721  loss: 0.18503148696170404  hr: 1  min: 23  sec: 53\n",
      "epoch: 0  batch: 222 / 721  loss: 0.18458927413532594  hr: 1  min: 23  sec: 49\n",
      "epoch: 0  batch: 223 / 721  loss: 0.18395711983566596  hr: 1  min: 23  sec: 45\n",
      "epoch: 0  batch: 224 / 721  loss: 0.18347478289589553  hr: 1  min: 23  sec: 41\n",
      "epoch: 0  batch: 225 / 721  loss: 0.18299326897495322  hr: 1  min: 23  sec: 35\n",
      "epoch: 0  batch: 226 / 721  loss: 0.1832460426206214  hr: 1  min: 23  sec: 32\n",
      "epoch: 0  batch: 227 / 721  loss: 0.1832205800314963  hr: 1  min: 23  sec: 28\n",
      "epoch: 0  batch: 228 / 721  loss: 0.18255324537555376  hr: 1  min: 23  sec: 33\n",
      "epoch: 0  batch: 229 / 721  loss: 0.1824850378858991  hr: 1  min: 23  sec: 27\n",
      "epoch: 0  batch: 230 / 721  loss: 0.18192827468333037  hr: 1  min: 23  sec: 24\n",
      "epoch: 0  batch: 231 / 721  loss: 0.18162759474087586  hr: 1  min: 23  sec: 22\n",
      "epoch: 0  batch: 232 / 721  loss: 0.1811963727312355  hr: 1  min: 23  sec: 18\n",
      "epoch: 0  batch: 233 / 721  loss: 0.18093143189285957  hr: 1  min: 23  sec: 14\n",
      "epoch: 0  batch: 234 / 721  loss: 0.18047809581726026  hr: 1  min: 23  sec: 16\n",
      "epoch: 0  batch: 235 / 721  loss: 0.18018414061120216  hr: 1  min: 23  sec: 12\n",
      "epoch: 0  batch: 236 / 721  loss: 0.17984333444954986  hr: 1  min: 23  sec: 8\n",
      "epoch: 0  batch: 237 / 721  loss: 0.17933657039192658  hr: 1  min: 23  sec: 16\n",
      "epoch: 0  batch: 238 / 721  loss: 0.1792743446133217  hr: 1  min: 23  sec: 18\n",
      "epoch: 0  batch: 239 / 721  loss: 0.17880900226003454  hr: 1  min: 23  sec: 14\n",
      "epoch: 0  batch: 240 / 721  loss: 0.17827596467298765  hr: 1  min: 23  sec: 11\n",
      "epoch: 0  batch: 241 / 721  loss: 0.17844467756968316  hr: 1  min: 23  sec: 6\n",
      "epoch: 0  batch: 242 / 721  loss: 0.17834033375251884  hr: 1  min: 23  sec: 1\n",
      "epoch: 0  batch: 243 / 721  loss: 0.17785542547212216  hr: 1  min: 22  sec: 57\n",
      "epoch: 0  batch: 244 / 721  loss: 0.17745852329936185  hr: 1  min: 22  sec: 53\n",
      "epoch: 0  batch: 245 / 721  loss: 0.17768479524826516  hr: 1  min: 22  sec: 50\n",
      "epoch: 0  batch: 246 / 721  loss: 0.17740669607268117  hr: 1  min: 22  sec: 46\n",
      "epoch: 0  batch: 247 / 721  loss: 0.17694683578091594  hr: 1  min: 22  sec: 46\n",
      "epoch: 0  batch: 248 / 721  loss: 0.176469951086948  hr: 1  min: 22  sec: 43\n",
      "epoch: 0  batch: 249 / 721  loss: 0.17602472797215704  hr: 1  min: 22  sec: 40\n",
      "epoch: 0  batch: 250 / 721  loss: 0.17551932157576083  hr: 1  min: 22  sec: 36\n",
      "epoch: 0  batch: 251 / 721  loss: 0.17567074793090384  hr: 1  min: 22  sec: 31\n",
      "epoch: 0  batch: 252 / 721  loss: 0.1751939556783154  hr: 1  min: 22  sec: 30\n",
      "epoch: 0  batch: 253 / 721  loss: 0.17487514363564993  hr: 1  min: 22  sec: 30\n",
      "epoch: 0  batch: 254 / 721  loss: 0.17439133610840388  hr: 1  min: 22  sec: 25\n",
      "epoch: 0  batch: 255 / 721  loss: 0.17399196725557833  hr: 1  min: 22  sec: 21\n",
      "epoch: 0  batch: 256 / 721  loss: 0.17351246031466872  hr: 1  min: 22  sec: 17\n",
      "epoch: 0  batch: 257 / 721  loss: 0.17378066886027962  hr: 1  min: 22  sec: 11\n",
      "epoch: 0  batch: 258 / 721  loss: 0.17358647503478583  hr: 1  min: 22  sec: 6\n",
      "epoch: 0  batch: 259 / 721  loss: 0.17349911268268312  hr: 1  min: 22  sec: 0\n",
      "epoch: 0  batch: 260 / 721  loss: 0.1729244186829489  hr: 1  min: 21  sec: 56\n",
      "epoch: 0  batch: 261 / 721  loss: 0.1723703526716922  hr: 1  min: 21  sec: 53\n",
      "epoch: 0  batch: 262 / 721  loss: 0.17192560001383073  hr: 1  min: 21  sec: 49\n",
      "epoch: 0  batch: 263 / 721  loss: 0.17161096419303362  hr: 1  min: 21  sec: 44\n",
      "epoch: 0  batch: 264 / 721  loss: 0.17116461020442797  hr: 1  min: 21  sec: 39\n",
      "epoch: 0  batch: 265 / 721  loss: 0.17062027204149174  hr: 1  min: 21  sec: 35\n",
      "epoch: 0  batch: 266 / 721  loss: 0.17040642947518736  hr: 1  min: 21  sec: 30\n",
      "epoch: 0  batch: 267 / 721  loss: 0.17006636475132647  hr: 1  min: 21  sec: 26\n",
      "epoch: 0  batch: 268 / 721  loss: 0.16976512988000664  hr: 1  min: 21  sec: 26\n",
      "epoch: 0  batch: 269 / 721  loss: 0.16944006437151848  hr: 1  min: 21  sec: 21\n",
      "epoch: 0  batch: 270 / 721  loss: 0.1690124745860144  hr: 1  min: 21  sec: 17\n",
      "epoch: 0  batch: 271 / 721  loss: 0.16862037130442492  hr: 1  min: 21  sec: 17\n",
      "epoch: 0  batch: 272 / 721  loss: 0.16821909753386588  hr: 1  min: 21  sec: 16\n",
      "epoch: 0  batch: 273 / 721  loss: 0.1678025317907115  hr: 1  min: 21  sec: 12\n",
      "epoch: 0  batch: 274 / 721  loss: 0.1675442878809506  hr: 1  min: 21  sec: 9\n",
      "epoch: 0  batch: 275 / 721  loss: 0.16715745596723122  hr: 1  min: 21  sec: 5\n",
      "epoch: 0  batch: 276 / 721  loss: 0.16701831588980512  hr: 1  min: 21  sec: 3\n",
      "epoch: 0  batch: 277 / 721  loss: 0.16661145801686209  hr: 1  min: 21  sec: 1\n",
      "epoch: 0  batch: 278 / 721  loss: 0.16611867098526345  hr: 1  min: 21  sec: 0\n",
      "epoch: 0  batch: 279 / 721  loss: 0.16567379247570765  hr: 1  min: 20  sec: 58\n",
      "epoch: 0  batch: 280 / 721  loss: 0.16546366532067103  hr: 1  min: 20  sec: 55\n",
      "epoch: 0  batch: 281 / 721  loss: 0.16509631685117174  hr: 1  min: 20  sec: 52\n",
      "epoch: 0  batch: 282 / 721  loss: 0.16458590479950744  hr: 1  min: 20  sec: 48\n",
      "epoch: 0  batch: 283 / 721  loss: 0.16437520943055514  hr: 1  min: 20  sec: 43\n",
      "epoch: 0  batch: 284 / 721  loss: 0.16413151638739756  hr: 1  min: 20  sec: 41\n",
      "epoch: 0  batch: 285 / 721  loss: 0.16387968011723275  hr: 1  min: 20  sec: 39\n",
      "epoch: 0  batch: 286 / 721  loss: 0.16356957863391072  hr: 1  min: 20  sec: 40\n",
      "epoch: 0  batch: 287 / 721  loss: 0.16334398156388918  hr: 1  min: 20  sec: 36\n",
      "epoch: 0  batch: 288 / 721  loss: 0.16323801448905012  hr: 1  min: 20  sec: 31\n",
      "epoch: 0  batch: 289 / 721  loss: 0.1627799146148057  hr: 1  min: 20  sec: 28\n",
      "epoch: 0  batch: 290 / 721  loss: 0.16254917654883244  hr: 1  min: 20  sec: 24\n",
      "epoch: 0  batch: 291 / 721  loss: 0.16204850657929465  hr: 1  min: 20  sec: 21\n",
      "epoch: 0  batch: 292 / 721  loss: 0.1616717186271634  hr: 1  min: 20  sec: 17\n",
      "epoch: 0  batch: 293 / 721  loss: 0.1612388744835866  hr: 1  min: 20  sec: 13\n",
      "epoch: 0  batch: 294 / 721  loss: 0.16077084022694502  hr: 1  min: 20  sec: 14\n",
      "epoch: 0  batch: 295 / 721  loss: 0.1603449119286517  hr: 1  min: 20  sec: 14\n",
      "epoch: 0  batch: 296 / 721  loss: 0.16019303147127298  hr: 1  min: 20  sec: 11\n",
      "epoch: 0  batch: 297 / 721  loss: 0.16008615044105534  hr: 1  min: 20  sec: 7\n",
      "epoch: 0  batch: 298 / 721  loss: 0.1596590234466747  hr: 1  min: 20  sec: 6\n",
      "epoch: 0  batch: 299 / 721  loss: 0.15956607998588612  hr: 1  min: 20  sec: 1\n",
      "epoch: 0  batch: 300 / 721  loss: 0.1594403423803548  hr: 1  min: 19  sec: 56\n",
      "epoch: 0  batch: 301 / 721  loss: 0.15916738802090633  hr: 1  min: 19  sec: 51\n",
      "epoch: 0  batch: 302 / 721  loss: 0.15890987853316085  hr: 1  min: 19  sec: 48\n",
      "epoch: 0  batch: 303 / 721  loss: 0.1588863855283154  hr: 1  min: 19  sec: 46\n",
      "epoch: 0  batch: 304 / 721  loss: 0.15856261007904418  hr: 1  min: 19  sec: 45\n",
      "epoch: 0  batch: 305 / 721  loss: 0.15807364504540064  hr: 1  min: 19  sec: 42\n",
      "epoch: 0  batch: 306 / 721  loss: 0.15794919014549236  hr: 1  min: 19  sec: 38\n",
      "epoch: 0  batch: 307 / 721  loss: 0.15826162775669017  hr: 1  min: 19  sec: 34\n",
      "epoch: 0  batch: 308 / 721  loss: 0.15784592289997676  hr: 1  min: 19  sec: 27\n",
      "epoch: 0  batch: 309 / 721  loss: 0.15748203778187336  hr: 1  min: 19  sec: 23\n",
      "epoch: 0  batch: 310 / 721  loss: 0.15727449262274368  hr: 1  min: 19  sec: 19\n",
      "epoch: 0  batch: 311 / 721  loss: 0.1568168165623375  hr: 1  min: 19  sec: 14\n",
      "epoch: 0  batch: 312 / 721  loss: 0.15706169047655585  hr: 1  min: 19  sec: 10\n",
      "epoch: 0  batch: 313 / 721  loss: 0.1567627796040366  hr: 1  min: 19  sec: 6\n",
      "epoch: 0  batch: 314 / 721  loss: 0.15634024874040275  hr: 1  min: 19  sec: 2\n",
      "epoch: 0  batch: 315 / 721  loss: 0.15601350433296626  hr: 1  min: 18  sec: 59\n",
      "epoch: 0  batch: 316 / 721  loss: 0.15578326677219778  hr: 1  min: 18  sec: 56\n",
      "epoch: 0  batch: 317 / 721  loss: 0.15589545559055798  hr: 1  min: 18  sec: 52\n",
      "epoch: 0  batch: 318 / 721  loss: 0.15559564249695473  hr: 1  min: 18  sec: 47\n",
      "epoch: 0  batch: 319 / 721  loss: 0.15538872820456573  hr: 1  min: 18  sec: 45\n",
      "epoch: 0  batch: 320 / 721  loss: 0.1549796807055827  hr: 1  min: 18  sec: 42\n",
      "epoch: 0  batch: 321 / 721  loss: 0.15463350692943806  hr: 1  min: 18  sec: 48\n",
      "epoch: 0  batch: 322 / 721  loss: 0.1543293053469395  hr: 1  min: 18  sec: 54\n",
      "epoch: 0  batch: 323 / 721  loss: 0.15403581971746666  hr: 1  min: 18  sec: 53\n",
      "epoch: 0  batch: 324 / 721  loss: 0.15371652275760783  hr: 1  min: 18  sec: 54\n",
      "epoch: 0  batch: 325 / 721  loss: 0.15351729990771185  hr: 1  min: 18  sec: 50\n",
      "epoch: 0  batch: 326 / 721  loss: 0.15308305696567143  hr: 1  min: 18  sec: 49\n",
      "epoch: 0  batch: 327 / 721  loss: 0.15299979191763322  hr: 1  min: 18  sec: 46\n",
      "epoch: 0  batch: 328 / 721  loss: 0.15268891981643876  hr: 1  min: 18  sec: 46\n",
      "epoch: 0  batch: 329 / 721  loss: 0.15235063636330123  hr: 1  min: 18  sec: 41\n",
      "epoch: 0  batch: 330 / 721  loss: 0.15234242735261266  hr: 1  min: 18  sec: 38\n",
      "epoch: 0  batch: 331 / 721  loss: 0.15194833377134223  hr: 1  min: 18  sec: 35\n",
      "epoch: 0  batch: 332 / 721  loss: 0.15203547086678895  hr: 1  min: 18  sec: 30\n",
      "epoch: 0  batch: 333 / 721  loss: 0.15166129873836184  hr: 1  min: 18  sec: 26\n",
      "epoch: 0  batch: 334 / 721  loss: 0.15147671839055007  hr: 1  min: 18  sec: 22\n",
      "epoch: 0  batch: 335 / 721  loss: 0.15112919832454688  hr: 1  min: 18  sec: 19\n",
      "epoch: 0  batch: 336 / 721  loss: 0.15088246182339  hr: 1  min: 18  sec: 13\n",
      "epoch: 0  batch: 337 / 721  loss: 0.15083695179299184  hr: 1  min: 18  sec: 10\n",
      "epoch: 0  batch: 338 / 721  loss: 0.1505974692584583  hr: 1  min: 18  sec: 6\n",
      "epoch: 0  batch: 339 / 721  loss: 0.15028830312719915  hr: 1  min: 18  sec: 3\n",
      "epoch: 0  batch: 340 / 721  loss: 0.14989068275043632  hr: 1  min: 18  sec: 4\n",
      "epoch: 0  batch: 341 / 721  loss: 0.1496628726425627  hr: 1  min: 18  sec: 1\n",
      "epoch: 0  batch: 342 / 721  loss: 0.14933363412784642  hr: 1  min: 18  sec: 0\n",
      "epoch: 0  batch: 343 / 721  loss: 0.14903656627070538  hr: 1  min: 17  sec: 59\n",
      "epoch: 0  batch: 344 / 721  loss: 0.14927034934733582  hr: 1  min: 17  sec: 56\n",
      "epoch: 0  batch: 345 / 721  loss: 0.14899828716086735  hr: 1  min: 17  sec: 55\n",
      "epoch: 0  batch: 346 / 721  loss: 0.148709977898919  hr: 1  min: 17  sec: 52\n",
      "epoch: 0  batch: 347 / 721  loss: 0.14849875191285647  hr: 1  min: 17  sec: 49\n",
      "epoch: 0  batch: 348 / 721  loss: 0.1481622715411044  hr: 1  min: 17  sec: 46\n",
      "epoch: 0  batch: 349 / 721  loss: 0.14784741167107165  hr: 1  min: 17  sec: 45\n",
      "epoch: 0  batch: 350 / 721  loss: 0.14777350951784424  hr: 1  min: 17  sec: 40\n",
      "epoch: 0  batch: 351 / 721  loss: 0.14745981785657145  hr: 1  min: 17  sec: 38\n",
      "epoch: 0  batch: 352 / 721  loss: 0.14713996991949072  hr: 1  min: 17  sec: 37\n",
      "epoch: 0  batch: 353 / 721  loss: 0.1470318434327292  hr: 1  min: 17  sec: 32\n",
      "epoch: 0  batch: 354 / 721  loss: 0.14676803779014844  hr: 1  min: 17  sec: 29\n",
      "epoch: 0  batch: 355 / 721  loss: 0.1467412325619182  hr: 1  min: 17  sec: 25\n",
      "epoch: 0  batch: 356 / 721  loss: 0.14673484961523184  hr: 1  min: 17  sec: 23\n",
      "epoch: 0  batch: 357 / 721  loss: 0.14636259227051956  hr: 1  min: 17  sec: 18\n",
      "epoch: 0  batch: 358 / 721  loss: 0.14607302024023994  hr: 1  min: 17  sec: 15\n",
      "epoch: 0  batch: 359 / 721  loss: 0.14574990537235497  hr: 1  min: 17  sec: 13\n",
      "epoch: 0  batch: 360 / 721  loss: 0.14569558569023178  hr: 1  min: 17  sec: 9\n",
      "epoch: 0  batch: 361 / 721  loss: 0.14539383259444522  hr: 1  min: 17  sec: 7\n",
      "epoch: 0  batch: 362 / 721  loss: 0.14520952945770643  hr: 1  min: 17  sec: 4\n",
      "epoch: 0  batch: 363 / 721  loss: 0.14509674416695909  hr: 1  min: 17  sec: 0\n",
      "epoch: 0  batch: 364 / 721  loss: 0.14489327940660027  hr: 1  min: 16  sec: 57\n",
      "epoch: 0  batch: 365 / 721  loss: 0.1446242018972766  hr: 1  min: 16  sec: 51\n",
      "epoch: 0  batch: 366 / 721  loss: 0.14460918967372896  hr: 1  min: 16  sec: 48\n",
      "epoch: 0  batch: 367 / 721  loss: 0.1443900634110867  hr: 1  min: 16  sec: 47\n",
      "epoch: 0  batch: 368 / 721  loss: 0.1441285072815726  hr: 1  min: 16  sec: 44\n",
      "epoch: 0  batch: 369 / 721  loss: 0.14437391683156411  hr: 1  min: 16  sec: 40\n",
      "epoch: 0  batch: 370 / 721  loss: 0.144204912833064  hr: 1  min: 16  sec: 37\n",
      "epoch: 0  batch: 371 / 721  loss: 0.14459712272685654  hr: 1  min: 16  sec: 35\n",
      "epoch: 0  batch: 372 / 721  loss: 0.14436731164553954  hr: 1  min: 16  sec: 30\n",
      "epoch: 0  batch: 373 / 721  loss: 0.1444275888686765  hr: 1  min: 16  sec: 28\n",
      "epoch: 0  batch: 374 / 721  loss: 0.1442559065177718  hr: 1  min: 16  sec: 26\n",
      "epoch: 0  batch: 375 / 721  loss: 0.1439728613346815  hr: 1  min: 16  sec: 21\n",
      "epoch: 0  batch: 376 / 721  loss: 0.14374854816421073  hr: 1  min: 16  sec: 18\n",
      "epoch: 0  batch: 377 / 721  loss: 0.14361652906302275  hr: 1  min: 16  sec: 16\n",
      "epoch: 0  batch: 378 / 721  loss: 0.14338669551920796  hr: 1  min: 16  sec: 14\n",
      "epoch: 0  batch: 379 / 721  loss: 0.1431921552670112  hr: 1  min: 16  sec: 10\n",
      "epoch: 0  batch: 380 / 721  loss: 0.14294724949194412  hr: 1  min: 16  sec: 7\n",
      "epoch: 0  batch: 381 / 721  loss: 0.14277207701322758  hr: 1  min: 16  sec: 11\n",
      "epoch: 0  batch: 382 / 721  loss: 0.1424954591748056  hr: 1  min: 16  sec: 7\n",
      "epoch: 0  batch: 383 / 721  loss: 0.14237348352590523  hr: 1  min: 16  sec: 5\n",
      "epoch: 0  batch: 384 / 721  loss: 0.14216396766035663  hr: 1  min: 16  sec: 5\n",
      "epoch: 0  batch: 385 / 721  loss: 0.14193580171407819  hr: 1  min: 16  sec: 3\n",
      "epoch: 0  batch: 386 / 721  loss: 0.14163538260588066  hr: 1  min: 16  sec: 2\n",
      "epoch: 0  batch: 387 / 721  loss: 0.1414516229057343  hr: 1  min: 15  sec: 59\n",
      "epoch: 0  batch: 388 / 721  loss: 0.14161464622839517  hr: 1  min: 15  sec: 56\n",
      "epoch: 0  batch: 389 / 721  loss: 0.14130898584207102  hr: 1  min: 15  sec: 53\n",
      "epoch: 0  batch: 390 / 721  loss: 0.14108763026694457  hr: 1  min: 15  sec: 52\n",
      "epoch: 0  batch: 391 / 721  loss: 0.14079759175153186  hr: 1  min: 15  sec: 53\n",
      "epoch: 0  batch: 392 / 721  loss: 0.14072613467994546  hr: 1  min: 15  sec: 48\n",
      "epoch: 0  batch: 393 / 721  loss: 0.14050934637681067  hr: 1  min: 15  sec: 48\n",
      "epoch: 0  batch: 394 / 721  loss: 0.14029097358039036  hr: 1  min: 15  sec: 44\n",
      "epoch: 0  batch: 395 / 721  loss: 0.14006228700185877  hr: 1  min: 15  sec: 41\n",
      "epoch: 0  batch: 396 / 721  loss: 0.13993371974658034  hr: 1  min: 15  sec: 36\n",
      "epoch: 0  batch: 397 / 721  loss: 0.1396688997079278  hr: 1  min: 15  sec: 33\n",
      "epoch: 0  batch: 398 / 721  loss: 0.13941845069896786  hr: 1  min: 15  sec: 30\n",
      "epoch: 0  batch: 399 / 721  loss: 0.13928748766674584  hr: 1  min: 15  sec: 27\n",
      "epoch: 0  batch: 400 / 721  loss: 0.1396122151473537  hr: 1  min: 15  sec: 23\n",
      "epoch: 0  batch: 401 / 721  loss: 0.13948860010619918  hr: 1  min: 15  sec: 20\n",
      "epoch: 0  batch: 402 / 721  loss: 0.1391982400270911  hr: 1  min: 15  sec: 17\n",
      "epoch: 0  batch: 403 / 721  loss: 0.13914005623358502  hr: 1  min: 15  sec: 12\n",
      "epoch: 0  batch: 404 / 721  loss: 0.13899972356653006  hr: 1  min: 15  sec: 12\n",
      "epoch: 0  batch: 405 / 721  loss: 0.13887255692647563  hr: 1  min: 15  sec: 9\n",
      "epoch: 0  batch: 406 / 721  loss: 0.13863730632924828  hr: 1  min: 15  sec: 7\n",
      "epoch: 0  batch: 407 / 721  loss: 0.13872341303205168  hr: 1  min: 15  sec: 3\n",
      "epoch: 0  batch: 408 / 721  loss: 0.13842834525869466  hr: 1  min: 14  sec: 59\n",
      "epoch: 0  batch: 409 / 721  loss: 0.13813291400361324  hr: 1  min: 14  sec: 56\n",
      "epoch: 0  batch: 410 / 721  loss: 0.1383651681198943  hr: 1  min: 14  sec: 55\n",
      "epoch: 0  batch: 411 / 721  loss: 0.13823122414703642  hr: 1  min: 14  sec: 50\n",
      "epoch: 0  batch: 412 / 721  loss: 0.1382499517447957  hr: 1  min: 14  sec: 48\n",
      "epoch: 0  batch: 413 / 721  loss: 0.13798390978780412  hr: 1  min: 14  sec: 45\n",
      "epoch: 0  batch: 414 / 721  loss: 0.13768180981413394  hr: 1  min: 14  sec: 48\n",
      "epoch: 0  batch: 415 / 721  loss: 0.13747889646160674  hr: 1  min: 14  sec: 44\n",
      "epoch: 0  batch: 416 / 721  loss: 0.13758592815093623  hr: 1  min: 14  sec: 42\n",
      "epoch: 0  batch: 417 / 721  loss: 0.13817919357244274  hr: 1  min: 14  sec: 40\n",
      "epoch: 0  batch: 418 / 721  loss: 0.1380447613489792  hr: 1  min: 14  sec: 37\n",
      "epoch: 0  batch: 419 / 721  loss: 0.1377946610289108  hr: 1  min: 14  sec: 34\n",
      "epoch: 0  batch: 420 / 721  loss: 0.13774569830857217  hr: 1  min: 14  sec: 31\n",
      "epoch: 0  batch: 421 / 721  loss: 0.13756111840056057  hr: 1  min: 14  sec: 27\n",
      "epoch: 0  batch: 422 / 721  loss: 0.13752778738481103  hr: 1  min: 14  sec: 23\n",
      "epoch: 0  batch: 423 / 721  loss: 0.13733002316012943  hr: 1  min: 14  sec: 20\n",
      "epoch: 0  batch: 424 / 721  loss: 0.13709435142567908  hr: 1  min: 14  sec: 16\n",
      "epoch: 0  batch: 425 / 721  loss: 0.13689330508384634  hr: 1  min: 14  sec: 13\n",
      "epoch: 0  batch: 426 / 721  loss: 0.1366562898130869  hr: 1  min: 14  sec: 12\n",
      "epoch: 0  batch: 427 / 721  loss: 0.13651700318513973  hr: 1  min: 14  sec: 8\n",
      "epoch: 0  batch: 428 / 721  loss: 0.13633457269893837  hr: 1  min: 14  sec: 5\n",
      "epoch: 0  batch: 429 / 721  loss: 0.13610202640008467  hr: 1  min: 14  sec: 2\n",
      "epoch: 0  batch: 430 / 721  loss: 0.13585608071149435  hr: 1  min: 14  sec: 1\n",
      "epoch: 0  batch: 431 / 721  loss: 0.13573189337117697  hr: 1  min: 13  sec: 57\n",
      "epoch: 0  batch: 432 / 721  loss: 0.13553132057077838  hr: 1  min: 13  sec: 55\n",
      "epoch: 0  batch: 433 / 721  loss: 0.13544328287717033  hr: 1  min: 13  sec: 51\n",
      "epoch: 0  batch: 434 / 721  loss: 0.13528159802161535  hr: 1  min: 13  sec: 47\n",
      "epoch: 0  batch: 435 / 721  loss: 0.1352714034568133  hr: 1  min: 13  sec: 43\n",
      "epoch: 0  batch: 436 / 721  loss: 0.1350011263029872  hr: 1  min: 13  sec: 42\n",
      "epoch: 0  batch: 437 / 721  loss: 0.13480415131504597  hr: 1  min: 13  sec: 40\n",
      "epoch: 0  batch: 438 / 721  loss: 0.13514362604965427  hr: 1  min: 13  sec: 37\n",
      "epoch: 0  batch: 439 / 721  loss: 0.13496623669617336  hr: 1  min: 13  sec: 34\n",
      "epoch: 0  batch: 440 / 721  loss: 0.13479514989197594  hr: 1  min: 13  sec: 32\n",
      "epoch: 0  batch: 441 / 721  loss: 0.13454268381734485  hr: 1  min: 13  sec: 31\n",
      "epoch: 0  batch: 442 / 721  loss: 0.13433169857367064  hr: 1  min: 13  sec: 28\n",
      "epoch: 0  batch: 443 / 721  loss: 0.1341156526773529  hr: 1  min: 13  sec: 27\n",
      "epoch: 0  batch: 444 / 721  loss: 0.13396522728096996  hr: 1  min: 13  sec: 26\n",
      "epoch: 0  batch: 445 / 721  loss: 0.1337507954453317  hr: 1  min: 13  sec: 23\n",
      "epoch: 0  batch: 446 / 721  loss: 0.13353825894063298  hr: 1  min: 13  sec: 19\n",
      "epoch: 0  batch: 447 / 721  loss: 0.1335772878867501  hr: 1  min: 13  sec: 16\n",
      "epoch: 0  batch: 448 / 721  loss: 0.13332955113686953  hr: 1  min: 13  sec: 15\n",
      "epoch: 0  batch: 449 / 721  loss: 0.1330682100678373  hr: 1  min: 13  sec: 14\n",
      "epoch: 0  batch: 450 / 721  loss: 0.13294216722456945  hr: 1  min: 13  sec: 11\n",
      "epoch: 0  batch: 451 / 721  loss: 0.1327543774198435  hr: 1  min: 13  sec: 8\n",
      "epoch: 0  batch: 452 / 721  loss: 0.1326098864490117  hr: 1  min: 13  sec: 5\n",
      "epoch: 0  batch: 453 / 721  loss: 0.132383711194048  hr: 1  min: 13  sec: 4\n",
      "epoch: 0  batch: 454 / 721  loss: 0.1324740771700665  hr: 1  min: 13  sec: 1\n",
      "epoch: 0  batch: 455 / 721  loss: 0.13254080863649045  hr: 1  min: 12  sec: 59\n",
      "epoch: 0  batch: 456 / 721  loss: 0.13228240258901855  hr: 1  min: 12  sec: 56\n",
      "epoch: 0  batch: 457 / 721  loss: 0.13214182575932282  hr: 1  min: 12  sec: 52\n",
      "epoch: 0  batch: 458 / 721  loss: 0.13194445457398957  hr: 1  min: 12  sec: 50\n",
      "epoch: 0  batch: 459 / 721  loss: 0.1320009445041126  hr: 1  min: 12  sec: 46\n",
      "epoch: 0  batch: 460 / 721  loss: 0.1317477915517014  hr: 1  min: 12  sec: 43\n",
      "epoch: 0  batch: 461 / 721  loss: 0.13154140178623272  hr: 1  min: 12  sec: 39\n",
      "epoch: 0  batch: 462 / 721  loss: 0.1313937728523047  hr: 1  min: 12  sec: 36\n",
      "epoch: 0  batch: 463 / 721  loss: 0.13136204110848723  hr: 1  min: 12  sec: 32\n",
      "epoch: 0  batch: 464 / 721  loss: 0.13109299727085302  hr: 1  min: 12  sec: 30\n",
      "epoch: 0  batch: 465 / 721  loss: 0.13100826718133463  hr: 1  min: 12  sec: 27\n",
      "epoch: 0  batch: 466 / 721  loss: 0.13081376535454245  hr: 1  min: 12  sec: 23\n",
      "epoch: 0  batch: 467 / 721  loss: 0.13085515168046766  hr: 1  min: 12  sec: 19\n",
      "epoch: 0  batch: 468 / 721  loss: 0.13063186363607612  hr: 1  min: 12  sec: 16\n",
      "epoch: 0  batch: 469 / 721  loss: 0.13058712045405943  hr: 1  min: 12  sec: 15\n",
      "epoch: 0  batch: 470 / 721  loss: 0.1304358434912927  hr: 1  min: 12  sec: 12\n",
      "epoch: 0  batch: 471 / 721  loss: 0.13023080072027576  hr: 1  min: 12  sec: 9\n",
      "epoch: 0  batch: 472 / 721  loss: 0.1299750810455515  hr: 1  min: 12  sec: 6\n",
      "epoch: 0  batch: 473 / 721  loss: 0.13002542844514733  hr: 1  min: 12  sec: 2\n",
      "epoch: 0  batch: 474 / 721  loss: 0.12997828452564963  hr: 1  min: 11  sec: 58\n",
      "epoch: 0  batch: 475 / 721  loss: 0.12987266702381403  hr: 1  min: 11  sec: 54\n",
      "epoch: 0  batch: 476 / 721  loss: 0.12967061590571582  hr: 1  min: 11  sec: 52\n",
      "epoch: 0  batch: 477 / 721  loss: 0.1294743979625029  hr: 1  min: 11  sec: 49\n",
      "epoch: 0  batch: 478 / 721  loss: 0.12936283883669855  hr: 1  min: 11  sec: 46\n",
      "epoch: 0  batch: 479 / 721  loss: 0.12934032328609602  hr: 1  min: 11  sec: 43\n",
      "epoch: 0  batch: 480 / 721  loss: 0.12930594807160864  hr: 1  min: 11  sec: 39\n",
      "epoch: 0  batch: 481 / 721  loss: 0.12906335867852314  hr: 1  min: 11  sec: 35\n",
      "epoch: 0  batch: 482 / 721  loss: 0.12887613965039957  hr: 1  min: 11  sec: 32\n",
      "epoch: 0  batch: 483 / 721  loss: 0.1286276504214213  hr: 1  min: 11  sec: 31\n",
      "epoch: 0  batch: 484 / 721  loss: 0.12869256417447902  hr: 1  min: 11  sec: 27\n",
      "epoch: 0  batch: 485 / 721  loss: 0.12914815031702526  hr: 1  min: 11  sec: 24\n",
      "epoch: 0  batch: 486 / 721  loss: 0.12903398279687045  hr: 1  min: 11  sec: 21\n",
      "epoch: 0  batch: 487 / 721  loss: 0.12887033383845825  hr: 1  min: 11  sec: 18\n",
      "epoch: 0  batch: 488 / 721  loss: 0.1286670724283064  hr: 1  min: 11  sec: 13\n",
      "epoch: 0  batch: 489 / 721  loss: 0.12843476184158145  hr: 1  min: 11  sec: 11\n",
      "epoch: 0  batch: 490 / 721  loss: 0.12824196677978095  hr: 1  min: 11  sec: 8\n",
      "epoch: 0  batch: 491 / 721  loss: 0.12821540596957515  hr: 1  min: 11  sec: 5\n",
      "epoch: 0  batch: 492 / 721  loss: 0.12806646929527596  hr: 1  min: 11  sec: 3\n",
      "epoch: 0  batch: 493 / 721  loss: 0.12784375545510201  hr: 1  min: 11  sec: 1\n",
      "epoch: 0  batch: 494 / 721  loss: 0.12762327178999752  hr: 1  min: 10  sec: 58\n",
      "epoch: 0  batch: 495 / 721  loss: 0.1274224220624551  hr: 1  min: 10  sec: 54\n",
      "epoch: 0  batch: 496 / 721  loss: 0.12781381980805176  hr: 1  min: 10  sec: 50\n",
      "epoch: 0  batch: 497 / 721  loss: 0.12759934717384533  hr: 1  min: 10  sec: 48\n",
      "epoch: 0  batch: 498 / 721  loss: 0.12738815499151718  hr: 1  min: 10  sec: 44\n",
      "epoch: 0  batch: 499 / 721  loss: 0.127176445728739  hr: 1  min: 10  sec: 41\n",
      "epoch: 0  batch: 500 / 721  loss: 0.12699527799803764  hr: 1  min: 10  sec: 38\n",
      "epoch: 0  batch: 501 / 721  loss: 0.1267797401938922  hr: 1  min: 10  sec: 36\n",
      "epoch: 0  batch: 502 / 721  loss: 0.12654710153166013  hr: 1  min: 10  sec: 33\n",
      "epoch: 0  batch: 503 / 721  loss: 0.12647180397259755  hr: 1  min: 10  sec: 29\n",
      "epoch: 0  batch: 504 / 721  loss: 0.12624985636267366  hr: 1  min: 10  sec: 26\n",
      "epoch: 0  batch: 505 / 721  loss: 0.12604814305956855  hr: 1  min: 10  sec: 22\n",
      "epoch: 0  batch: 506 / 721  loss: 0.1258336623436716  hr: 1  min: 10  sec: 19\n",
      "epoch: 0  batch: 507 / 721  loss: 0.12562942670849273  hr: 1  min: 10  sec: 17\n",
      "epoch: 0  batch: 508 / 721  loss: 0.1253960316562585  hr: 1  min: 10  sec: 16\n",
      "epoch: 0  batch: 509 / 721  loss: 0.1255026732293307  hr: 1  min: 10  sec: 13\n",
      "epoch: 0  batch: 510 / 721  loss: 0.12535708231541018  hr: 1  min: 10  sec: 9\n",
      "epoch: 0  batch: 511 / 721  loss: 0.12535514107061488  hr: 1  min: 10  sec: 7\n",
      "epoch: 0  batch: 512 / 721  loss: 0.12517931250931724  hr: 1  min: 10  sec: 3\n",
      "epoch: 0  batch: 513 / 721  loss: 0.1249518246920035  hr: 1  min: 10  sec: 0\n",
      "epoch: 0  batch: 514 / 721  loss: 0.12484791027001514  hr: 1  min: 9  sec: 57\n",
      "epoch: 0  batch: 515 / 721  loss: 0.12464084178299724  hr: 1  min: 9  sec: 54\n",
      "epoch: 0  batch: 516 / 721  loss: 0.12446385843033159  hr: 1  min: 9  sec: 50\n",
      "epoch: 0  batch: 517 / 721  loss: 0.12426787299667873  hr: 1  min: 9  sec: 48\n",
      "epoch: 0  batch: 518 / 721  loss: 0.12419787925689636  hr: 1  min: 9  sec: 46\n",
      "epoch: 0  batch: 519 / 721  loss: 0.12401302747144893  hr: 1  min: 9  sec: 43\n",
      "epoch: 0  batch: 520 / 721  loss: 0.12393524036115895  hr: 1  min: 9  sec: 40\n",
      "epoch: 0  batch: 521 / 721  loss: 0.12374253704475378  hr: 1  min: 9  sec: 38\n",
      "epoch: 0  batch: 522 / 721  loss: 0.12352061874796975  hr: 1  min: 9  sec: 35\n",
      "epoch: 0  batch: 523 / 721  loss: 0.12329816935943656  hr: 1  min: 9  sec: 34\n",
      "epoch: 0  batch: 524 / 721  loss: 0.12307428167990715  hr: 1  min: 9  sec: 32\n",
      "epoch: 0  batch: 525 / 721  loss: 0.1229543437099173  hr: 1  min: 9  sec: 30\n",
      "epoch: 0  batch: 526 / 721  loss: 0.12284009925978605  hr: 1  min: 9  sec: 27\n",
      "epoch: 0  batch: 527 / 721  loss: 0.12269644818464877  hr: 1  min: 9  sec: 25\n",
      "epoch: 0  batch: 528 / 721  loss: 0.12247864756323962  hr: 1  min: 9  sec: 22\n",
      "epoch: 0  batch: 529 / 721  loss: 0.12238382439292785  hr: 1  min: 9  sec: 19\n",
      "epoch: 0  batch: 530 / 721  loss: 0.12222946602148267  hr: 1  min: 9  sec: 16\n",
      "epoch: 0  batch: 531 / 721  loss: 0.12201410916804033  hr: 1  min: 9  sec: 14\n",
      "epoch: 0  batch: 532 / 721  loss: 0.12180736004830078  hr: 1  min: 9  sec: 11\n",
      "epoch: 0  batch: 533 / 721  loss: 0.12159411073094462  hr: 1  min: 9  sec: 9\n",
      "epoch: 0  batch: 534 / 721  loss: 0.12138471452254201  hr: 1  min: 9  sec: 9\n",
      "epoch: 0  batch: 535 / 721  loss: 0.12121906592989358  hr: 1  min: 9  sec: 5\n",
      "epoch: 0  batch: 536 / 721  loss: 0.12104448906681153  hr: 1  min: 9  sec: 2\n",
      "epoch: 0  batch: 537 / 721  loss: 0.12094126409873561  hr: 1  min: 8  sec: 59\n",
      "epoch: 0  batch: 538 / 721  loss: 0.12076655673694045  hr: 1  min: 8  sec: 56\n",
      "epoch: 0  batch: 539 / 721  loss: 0.12075043449796916  hr: 1  min: 8  sec: 54\n",
      "epoch: 0  batch: 540 / 721  loss: 0.12067517863965972  hr: 1  min: 8  sec: 50\n",
      "epoch: 0  batch: 541 / 721  loss: 0.12050678796012664  hr: 1  min: 8  sec: 49\n",
      "epoch: 0  batch: 542 / 721  loss: 0.12034926813171413  hr: 1  min: 8  sec: 46\n",
      "epoch: 0  batch: 543 / 721  loss: 0.12024064583817075  hr: 1  min: 8  sec: 43\n",
      "epoch: 0  batch: 544 / 721  loss: 0.12004272826187148  hr: 1  min: 8  sec: 40\n",
      "epoch: 0  batch: 545 / 721  loss: 0.11993232983412272  hr: 1  min: 8  sec: 36\n",
      "epoch: 0  batch: 546 / 721  loss: 0.11973642141152269  hr: 1  min: 8  sec: 32\n",
      "epoch: 0  batch: 547 / 721  loss: 0.11954751887428532  hr: 1  min: 8  sec: 29\n",
      "epoch: 0  batch: 548 / 721  loss: 0.1193939784871428  hr: 1  min: 8  sec: 27\n",
      "epoch: 0  batch: 549 / 721  loss: 0.11918451686140374  hr: 1  min: 8  sec: 24\n",
      "epoch: 0  batch: 550 / 721  loss: 0.11916040827181529  hr: 1  min: 8  sec: 21\n",
      "epoch: 0  batch: 551 / 721  loss: 0.11897340338734635  hr: 1  min: 8  sec: 21\n",
      "epoch: 0  batch: 552 / 721  loss: 0.11877196341199611  hr: 1  min: 8  sec: 18\n",
      "epoch: 0  batch: 553 / 721  loss: 0.11858053516872753  hr: 1  min: 8  sec: 16\n",
      "epoch: 0  batch: 554 / 721  loss: 0.11844195538479499  hr: 1  min: 8  sec: 12\n",
      "epoch: 0  batch: 555 / 721  loss: 0.11895141714328045  hr: 1  min: 8  sec: 10\n",
      "epoch: 0  batch: 556 / 721  loss: 0.1187450369868575  hr: 1  min: 8  sec: 7\n",
      "epoch: 0  batch: 557 / 721  loss: 0.11857607647779948  hr: 1  min: 8  sec: 5\n",
      "epoch: 0  batch: 558 / 721  loss: 0.11845089776331298  hr: 1  min: 8  sec: 2\n",
      "epoch: 0  batch: 559 / 721  loss: 0.11824640639422858  hr: 1  min: 7  sec: 59\n",
      "epoch: 0  batch: 560 / 721  loss: 0.11812517503692237  hr: 1  min: 7  sec: 56\n",
      "epoch: 0  batch: 561 / 721  loss: 0.11814124217263544  hr: 1  min: 7  sec: 53\n",
      "epoch: 0  batch: 562 / 721  loss: 0.11803056738916055  hr: 1  min: 7  sec: 55\n",
      "epoch: 0  batch: 563 / 721  loss: 0.11788164432281314  hr: 1  min: 7  sec: 52\n",
      "epoch: 0  batch: 564 / 721  loss: 0.11776392572437222  hr: 1  min: 7  sec: 49\n",
      "epoch: 0  batch: 565 / 721  loss: 0.1176028103205021  hr: 1  min: 7  sec: 47\n",
      "epoch: 0  batch: 566 / 721  loss: 0.11744565333818931  hr: 1  min: 7  sec: 45\n",
      "epoch: 0  batch: 567 / 721  loss: 0.11726886891830561  hr: 1  min: 7  sec: 42\n",
      "epoch: 0  batch: 568 / 721  loss: 0.11708144597056597  hr: 1  min: 7  sec: 40\n",
      "epoch: 0  batch: 569 / 721  loss: 0.11700096871844626  hr: 1  min: 7  sec: 37\n",
      "epoch: 0  batch: 570 / 721  loss: 0.11686764760841534  hr: 1  min: 7  sec: 34\n",
      "epoch: 0  batch: 571 / 721  loss: 0.11670740645610435  hr: 1  min: 7  sec: 32\n",
      "epoch: 0  batch: 572 / 721  loss: 0.11653839119863078  hr: 1  min: 7  sec: 31\n",
      "epoch: 0  batch: 573 / 721  loss: 0.11636762724487179  hr: 1  min: 7  sec: 29\n",
      "epoch: 0  batch: 574 / 721  loss: 0.11619620742065384  hr: 1  min: 7  sec: 26\n",
      "epoch: 0  batch: 575 / 721  loss: 0.1160095131567315  hr: 1  min: 7  sec: 24\n",
      "epoch: 0  batch: 576 / 721  loss: 0.11589606948756329  hr: 1  min: 7  sec: 21\n",
      "epoch: 0  batch: 577 / 721  loss: 0.11579020221699901  hr: 1  min: 7  sec: 18\n",
      "epoch: 0  batch: 578 / 721  loss: 0.11563193621226686  hr: 1  min: 7  sec: 14\n",
      "epoch: 0  batch: 579 / 721  loss: 0.11552401111961466  hr: 1  min: 7  sec: 11\n",
      "epoch: 0  batch: 580 / 721  loss: 0.11571665862013168  hr: 1  min: 7  sec: 9\n",
      "epoch: 0  batch: 581 / 721  loss: 0.11553369704137031  hr: 1  min: 7  sec: 6\n",
      "epoch: 0  batch: 582 / 721  loss: 0.11540538445675164  hr: 1  min: 7  sec: 3\n",
      "epoch: 0  batch: 583 / 721  loss: 0.115285851967906  hr: 1  min: 7  sec: 0\n",
      "epoch: 0  batch: 584 / 721  loss: 0.11519460774852881  hr: 1  min: 6  sec: 57\n",
      "epoch: 0  batch: 585 / 721  loss: 0.1151317440602196  hr: 1  min: 6  sec: 54\n",
      "epoch: 0  batch: 586 / 721  loss: 0.11513634476693087  hr: 1  min: 6  sec: 51\n",
      "epoch: 0  batch: 587 / 721  loss: 0.11502300546737784  hr: 1  min: 6  sec: 49\n",
      "epoch: 0  batch: 588 / 721  loss: 0.11486059285583114  hr: 1  min: 6  sec: 48\n",
      "epoch: 0  batch: 589 / 721  loss: 0.1147229085069194  hr: 1  min: 6  sec: 45\n",
      "epoch: 0  batch: 590 / 721  loss: 0.11454390005555824  hr: 1  min: 6  sec: 42\n",
      "epoch: 0  batch: 591 / 721  loss: 0.11440209117552577  hr: 1  min: 6  sec: 41\n",
      "epoch: 0  batch: 592 / 721  loss: 0.1142602671807745  hr: 1  min: 6  sec: 37\n",
      "epoch: 0  batch: 593 / 721  loss: 0.11408580292226718  hr: 1  min: 6  sec: 36\n",
      "epoch: 0  batch: 594 / 721  loss: 0.11392704810812342  hr: 1  min: 6  sec: 33\n",
      "epoch: 0  batch: 595 / 721  loss: 0.11380881290929783  hr: 1  min: 6  sec: 29\n",
      "epoch: 0  batch: 596 / 721  loss: 0.11373410295873206  hr: 1  min: 6  sec: 26\n",
      "epoch: 0  batch: 597 / 721  loss: 0.1136055942102206  hr: 1  min: 6  sec: 25\n",
      "epoch: 0  batch: 598 / 721  loss: 0.1134596495557402  hr: 1  min: 6  sec: 23\n",
      "epoch: 0  batch: 599 / 721  loss: 0.11330451085955179  hr: 1  min: 6  sec: 20\n",
      "epoch: 0  batch: 600 / 721  loss: 0.11318703893960143  hr: 1  min: 6  sec: 17\n",
      "epoch: 0  batch: 601 / 721  loss: 0.1130127334609293  hr: 1  min: 6  sec: 15\n",
      "epoch: 0  batch: 602 / 721  loss: 0.11286404874234575  hr: 1  min: 6  sec: 12\n",
      "epoch: 0  batch: 603 / 721  loss: 0.11272870972798905  hr: 1  min: 6  sec: 9\n",
      "epoch: 0  batch: 604 / 721  loss: 0.11275521720010195  hr: 1  min: 6  sec: 6\n",
      "epoch: 0  batch: 605 / 721  loss: 0.11274120207829785  hr: 1  min: 6  sec: 3\n",
      "epoch: 0  batch: 606 / 721  loss: 0.11268993796513296  hr: 1  min: 6  sec: 0\n",
      "epoch: 0  batch: 607 / 721  loss: 0.11265597494834607  hr: 1  min: 5  sec: 56\n",
      "epoch: 0  batch: 608 / 721  loss: 0.11251971105919342  hr: 1  min: 5  sec: 53\n",
      "epoch: 0  batch: 609 / 721  loss: 0.11248130372026553  hr: 1  min: 5  sec: 51\n",
      "epoch: 0  batch: 610 / 721  loss: 0.11237426525913179  hr: 1  min: 5  sec: 48\n",
      "epoch: 0  batch: 611 / 721  loss: 0.1122828874723306  hr: 1  min: 5  sec: 45\n",
      "epoch: 0  batch: 612 / 721  loss: 0.11212904125168993  hr: 1  min: 5  sec: 43\n",
      "epoch: 0  batch: 613 / 721  loss: 0.11209795471709252  hr: 1  min: 5  sec: 40\n",
      "epoch: 0  batch: 614 / 721  loss: 0.11198087790389379  hr: 1  min: 5  sec: 37\n",
      "epoch: 0  batch: 615 / 721  loss: 0.11184026154242759  hr: 1  min: 5  sec: 34\n",
      "epoch: 0  batch: 616 / 721  loss: 0.11180066905066056  hr: 1  min: 5  sec: 31\n",
      "epoch: 0  batch: 617 / 721  loss: 0.11174259955407614  hr: 1  min: 5  sec: 28\n",
      "epoch: 0  batch: 618 / 721  loss: 0.11172945305485049  hr: 1  min: 5  sec: 25\n",
      "epoch: 0  batch: 619 / 721  loss: 0.11172328004613519  hr: 1  min: 5  sec: 22\n",
      "epoch: 0  batch: 620 / 721  loss: 0.11159365509952147  hr: 1  min: 5  sec: 20\n",
      "epoch: 0  batch: 621 / 721  loss: 0.11143681434344578  hr: 1  min: 5  sec: 16\n",
      "epoch: 0  batch: 622 / 721  loss: 0.11127146047545998  hr: 1  min: 5  sec: 14\n",
      "epoch: 0  batch: 623 / 721  loss: 0.11111723676093677  hr: 1  min: 5  sec: 14\n",
      "epoch: 0  batch: 624 / 721  loss: 0.11131628032233447  hr: 1  min: 5  sec: 10\n",
      "epoch: 0  batch: 625 / 721  loss: 0.11126742722019553  hr: 1  min: 5  sec: 7\n",
      "epoch: 0  batch: 626 / 721  loss: 0.11111000585726823  hr: 1  min: 5  sec: 4\n",
      "epoch: 0  batch: 627 / 721  loss: 0.11102082726710508  hr: 1  min: 5  sec: 2\n",
      "epoch: 0  batch: 628 / 721  loss: 0.11091480092931491  hr: 1  min: 4  sec: 58\n",
      "epoch: 0  batch: 629 / 721  loss: 0.11077802768569374  hr: 1  min: 4  sec: 55\n",
      "epoch: 0  batch: 630 / 721  loss: 0.1106964925681019  hr: 1  min: 4  sec: 52\n",
      "epoch: 0  batch: 631 / 721  loss: 0.11074794198293386  hr: 1  min: 4  sec: 50\n",
      "epoch: 0  batch: 632 / 721  loss: 0.11063473932135591  hr: 1  min: 4  sec: 48\n",
      "epoch: 0  batch: 633 / 721  loss: 0.11055947245741601  hr: 1  min: 4  sec: 46\n",
      "epoch: 0  batch: 634 / 721  loss: 0.11055524031373111  hr: 1  min: 4  sec: 44\n",
      "epoch: 0  batch: 635 / 721  loss: 0.11045976636608637  hr: 1  min: 4  sec: 42\n",
      "epoch: 0  batch: 636 / 721  loss: 0.11043201625836228  hr: 1  min: 4  sec: 37\n",
      "epoch: 0  batch: 637 / 721  loss: 0.11028160464846101  hr: 1  min: 4  sec: 35\n",
      "epoch: 0  batch: 638 / 721  loss: 0.11019495141920181  hr: 1  min: 4  sec: 33\n",
      "epoch: 0  batch: 639 / 721  loss: 0.11040839525551793  hr: 1  min: 4  sec: 30\n",
      "epoch: 0  batch: 640 / 721  loss: 0.11025425738553167  hr: 1  min: 4  sec: 27\n",
      "epoch: 0  batch: 641 / 721  loss: 0.1102714807575339  hr: 1  min: 4  sec: 25\n",
      "epoch: 0  batch: 642 / 721  loss: 0.11017110010513287  hr: 1  min: 4  sec: 22\n",
      "epoch: 0  batch: 643 / 721  loss: 0.11000892801158142  hr: 1  min: 4  sec: 20\n",
      "epoch: 0  batch: 644 / 721  loss: 0.10992320657271012  hr: 1  min: 4  sec: 18\n",
      "epoch: 0  batch: 645 / 721  loss: 0.11004043947111151  hr: 1  min: 4  sec: 16\n",
      "epoch: 0  batch: 646 / 721  loss: 0.10988982612391121  hr: 1  min: 4  sec: 12\n",
      "epoch: 0  batch: 647 / 721  loss: 0.10974663446860322  hr: 1  min: 4  sec: 9\n",
      "epoch: 0  batch: 648 / 721  loss: 0.10967556863554673  hr: 1  min: 4  sec: 6\n",
      "epoch: 0  batch: 649 / 721  loss: 0.10954398434330782  hr: 1  min: 4  sec: 3\n",
      "epoch: 0  batch: 650 / 721  loss: 0.10940384851983534  hr: 1  min: 4  sec: 2\n",
      "epoch: 0  batch: 651 / 721  loss: 0.10931412492608351  hr: 1  min: 3  sec: 59\n",
      "epoch: 0  batch: 652 / 721  loss: 0.10917896806031031  hr: 1  min: 3  sec: 57\n",
      "epoch: 0  batch: 653 / 721  loss: 0.10904239502394569  hr: 1  min: 3  sec: 54\n",
      "epoch: 0  batch: 654 / 721  loss: 0.10892065215801723  hr: 1  min: 3  sec: 51\n",
      "epoch: 0  batch: 655 / 721  loss: 0.10879439790981985  hr: 1  min: 3  sec: 48\n",
      "epoch: 0  batch: 656 / 721  loss: 0.10866433768831307  hr: 1  min: 3  sec: 45\n",
      "epoch: 0  batch: 657 / 721  loss: 0.10853768708581273  hr: 1  min: 3  sec: 43\n",
      "epoch: 0  batch: 658 / 721  loss: 0.10838278746274851  hr: 1  min: 3  sec: 40\n",
      "epoch: 0  batch: 659 / 721  loss: 0.1082395025011723  hr: 1  min: 3  sec: 38\n",
      "epoch: 0  batch: 660 / 721  loss: 0.10812049593959906  hr: 1  min: 3  sec: 36\n",
      "epoch: 0  batch: 661 / 721  loss: 0.10797335966962211  hr: 1  min: 3  sec: 34\n",
      "epoch: 0  batch: 662 / 721  loss: 0.10783135793396915  hr: 1  min: 3  sec: 30\n",
      "epoch: 0  batch: 663 / 721  loss: 0.10768115155042049  hr: 1  min: 3  sec: 28\n",
      "epoch: 0  batch: 664 / 721  loss: 0.10788089221873579  hr: 1  min: 3  sec: 25\n",
      "epoch: 0  batch: 665 / 721  loss: 0.10782827333638206  hr: 1  min: 3  sec: 22\n",
      "epoch: 0  batch: 666 / 721  loss: 0.10769690510358203  hr: 1  min: 3  sec: 19\n",
      "epoch: 0  batch: 667 / 721  loss: 0.10766546139800767  hr: 1  min: 3  sec: 15\n",
      "epoch: 0  batch: 668 / 721  loss: 0.10751465288294802  hr: 1  min: 3  sec: 13\n",
      "epoch: 0  batch: 669 / 721  loss: 0.10746178640921354  hr: 1  min: 3  sec: 10\n",
      "epoch: 0  batch: 670 / 721  loss: 0.10735664416813473  hr: 1  min: 3  sec: 7\n",
      "epoch: 0  batch: 671 / 721  loss: 0.10724292196619328  hr: 1  min: 3  sec: 4\n",
      "epoch: 0  batch: 672 / 721  loss: 0.10727814805258754  hr: 1  min: 3  sec: 1\n",
      "epoch: 0  batch: 673 / 721  loss: 0.10721952385887681  hr: 1  min: 2  sec: 59\n",
      "epoch: 0  batch: 674 / 721  loss: 0.1070858336762644  hr: 1  min: 2  sec: 55\n",
      "epoch: 0  batch: 675 / 721  loss: 0.1070157150393007  hr: 1  min: 2  sec: 52\n",
      "epoch: 0  batch: 676 / 721  loss: 0.10686495815632457  hr: 1  min: 2  sec: 49\n",
      "epoch: 0  batch: 677 / 721  loss: 0.10679774113794571  hr: 1  min: 2  sec: 46\n",
      "epoch: 0  batch: 678 / 721  loss: 0.10668679661732881  hr: 1  min: 2  sec: 43\n",
      "epoch: 0  batch: 679 / 721  loss: 0.106553587037247  hr: 1  min: 2  sec: 40\n",
      "epoch: 0  batch: 680 / 721  loss: 0.10642182359211695  hr: 1  min: 2  sec: 38\n",
      "epoch: 0  batch: 681 / 721  loss: 0.10635981185870483  hr: 1  min: 2  sec: 34\n",
      "epoch: 0  batch: 682 / 721  loss: 0.10622555589715778  hr: 1  min: 2  sec: 32\n",
      "epoch: 0  batch: 683 / 721  loss: 0.10607945299086925  hr: 1  min: 2  sec: 32\n",
      "epoch: 0  batch: 684 / 721  loss: 0.10604035535933483  hr: 1  min: 2  sec: 29\n",
      "epoch: 0  batch: 685 / 721  loss: 0.10589025032631781  hr: 1  min: 2  sec: 27\n",
      "epoch: 0  batch: 686 / 721  loss: 0.10576471224028085  hr: 1  min: 2  sec: 24\n",
      "epoch: 0  batch: 687 / 721  loss: 0.105673677089395  hr: 1  min: 2  sec: 22\n",
      "epoch: 0  batch: 688 / 721  loss: 0.10577802490889701  hr: 1  min: 2  sec: 19\n",
      "epoch: 0  batch: 689 / 721  loss: 0.10564997721752706  hr: 1  min: 2  sec: 17\n",
      "epoch: 0  batch: 690 / 721  loss: 0.10555695910614146  hr: 1  min: 2  sec: 14\n",
      "epoch: 0  batch: 691 / 721  loss: 0.10543170177840053  hr: 1  min: 2  sec: 12\n",
      "epoch: 0  batch: 692 / 721  loss: 0.10531268391362526  hr: 1  min: 2  sec: 10\n",
      "epoch: 0  batch: 693 / 721  loss: 0.10517462684932832  hr: 1  min: 2  sec: 7\n",
      "epoch: 0  batch: 694 / 721  loss: 0.10509553786316184  hr: 1  min: 2  sec: 4\n",
      "epoch: 0  batch: 695 / 721  loss: 0.10498582395999659  hr: 1  min: 2  sec: 0\n",
      "epoch: 0  batch: 696 / 721  loss: 0.104907938060431  hr: 1  min: 1  sec: 57\n",
      "epoch: 0  batch: 697 / 721  loss: 0.1047681151271946  hr: 1  min: 1  sec: 58\n",
      "epoch: 0  batch: 698 / 721  loss: 0.10471525040380443  hr: 1  min: 1  sec: 55\n",
      "epoch: 0  batch: 699 / 721  loss: 0.10457344080663908  hr: 1  min: 1  sec: 52\n",
      "epoch: 0  batch: 700 / 721  loss: 0.10455020544052657  hr: 1  min: 1  sec: 50\n",
      "epoch: 0  batch: 701 / 721  loss: 0.10441750363139875  hr: 1  min: 1  sec: 47\n",
      "epoch: 0  batch: 702 / 721  loss: 0.10429203543650183  hr: 1  min: 1  sec: 47\n",
      "epoch: 0  batch: 703 / 721  loss: 0.10419216733439103  hr: 1  min: 1  sec: 44\n",
      "epoch: 0  batch: 704 / 721  loss: 0.10424239976286613  hr: 1  min: 1  sec: 41\n",
      "epoch: 0  batch: 705 / 721  loss: 0.10412963931745989  hr: 1  min: 1  sec: 38\n",
      "epoch: 0  batch: 706 / 721  loss: 0.10399430947940237  hr: 1  min: 1  sec: 35\n",
      "epoch: 0  batch: 707 / 721  loss: 0.1038562896545539  hr: 1  min: 1  sec: 33\n",
      "epoch: 0  batch: 708 / 721  loss: 0.10373241630432822  hr: 1  min: 1  sec: 30\n",
      "epoch: 0  batch: 709 / 721  loss: 0.10369325454750103  hr: 1  min: 1  sec: 28\n",
      "epoch: 0  batch: 710 / 721  loss: 0.10367115470843101  hr: 1  min: 1  sec: 25\n",
      "epoch: 0  batch: 711 / 721  loss: 0.10353976522628663  hr: 1  min: 1  sec: 23\n",
      "epoch: 0  batch: 712 / 721  loss: 0.10343081368266846  hr: 1  min: 1  sec: 20\n",
      "epoch: 0  batch: 713 / 721  loss: 0.10346874941811801  hr: 1  min: 1  sec: 16\n",
      "epoch: 0  batch: 714 / 721  loss: 0.10347432041272041  hr: 1  min: 1  sec: 13\n",
      "epoch: 0  batch: 715 / 721  loss: 0.10335466868954  hr: 1  min: 1  sec: 10\n",
      "epoch: 0  batch: 716 / 721  loss: 0.10322706568817082  hr: 1  min: 1  sec: 9\n",
      "epoch: 0  batch: 717 / 721  loss: 0.10322551351271808  hr: 1  min: 1  sec: 6\n",
      "epoch: 0  batch: 718 / 721  loss: 0.10308667765391996  hr: 1  min: 1  sec: 3\n",
      "epoch: 0  batch: 719 / 721  loss: 0.10345086162250557  hr: 1  min: 1  sec: 1\n",
      "epoch: 0  batch: 720 / 721  loss: 0.10332926672061957  hr: 1  min: 0  sec: 58\n",
      "epoch: 0  batch: 721 / 721  loss: 0.10330055915394051  hr: 1  min: 0  sec: 55\n",
      "epoch: 1  batch: 1 / 721  loss: 0.07762669771909714  hr: 0  min: 49  sec: 29\n",
      "epoch: 1  batch: 2 / 721  loss: 0.060626646503806114  hr: 0  min: 55  sec: 30\n",
      "epoch: 1  batch: 3 / 721  loss: 0.04611341841518879  hr: 0  min: 54  sec: 30\n",
      "epoch: 1  batch: 4 / 721  loss: 0.04408193798735738  hr: 0  min: 55  sec: 59\n",
      "epoch: 1  batch: 5 / 721  loss: 0.04435662515461445  hr: 0  min: 54  sec: 41\n",
      "epoch: 1  batch: 6 / 721  loss: 0.041641429687539734  hr: 0  min: 54  sec: 16\n",
      "epoch: 1  batch: 7 / 721  loss: 0.03875915014318058  hr: 0  min: 53  sec: 59\n",
      "epoch: 1  batch: 8 / 721  loss: 0.03445678675780073  hr: 0  min: 59  sec: 28\n",
      "epoch: 1  batch: 9 / 721  loss: 0.03143962762422032  hr: 1  min: 0  sec: 0\n",
      "epoch: 1  batch: 10 / 721  loss: 0.028699506539851427  hr: 0  min: 59  sec: 51\n",
      "epoch: 1  batch: 11 / 721  loss: 0.0295817849480293  hr: 0  min: 59  sec: 42\n",
      "epoch: 1  batch: 12 / 721  loss: 0.02800695295445621  hr: 0  min: 59  sec: 42\n",
      "epoch: 1  batch: 13 / 721  loss: 0.026598033137046374  hr: 0  min: 59  sec: 53\n",
      "epoch: 1  batch: 14 / 721  loss: 0.02538353716954589  hr: 0  min: 59  sec: 57\n",
      "epoch: 1  batch: 15 / 721  loss: 0.024770092157026132  hr: 1  min: 0  sec: 3\n",
      "epoch: 1  batch: 16 / 721  loss: 0.04494944884208962  hr: 0  min: 59  sec: 51\n",
      "epoch: 1  batch: 17 / 721  loss: 0.042893994051743954  hr: 0  min: 59  sec: 32\n",
      "epoch: 1  batch: 18 / 721  loss: 0.040777197392243475  hr: 1  min: 0  sec: 27\n",
      "epoch: 1  batch: 19 / 721  loss: 0.04071082750727471  hr: 1  min: 0  sec: 53\n",
      "epoch: 1  batch: 20 / 721  loss: 0.03978101832326501  hr: 1  min: 0  sec: 29\n",
      "epoch: 1  batch: 21 / 721  loss: 0.041353160759345406  hr: 1  min: 0  sec: 1\n",
      "epoch: 1  batch: 22 / 721  loss: 0.03961625130085105  hr: 0  min: 59  sec: 38\n",
      "epoch: 1  batch: 23 / 721  loss: 0.03930473370153619  hr: 0  min: 59  sec: 15\n",
      "epoch: 1  batch: 24 / 721  loss: 0.03793372958898544  hr: 0  min: 59  sec: 21\n",
      "epoch: 1  batch: 25 / 721  loss: 0.036543814400210976  hr: 0  min: 59  sec: 39\n",
      "epoch: 1  batch: 26 / 721  loss: 0.0353520525386557  hr: 0  min: 59  sec: 57\n",
      "epoch: 1  batch: 27 / 721  loss: 0.03432707027187226  hr: 0  min: 59  sec: 49\n",
      "epoch: 1  batch: 28 / 721  loss: 0.03400516870065725  hr: 0  min: 59  sec: 31\n",
      "epoch: 1  batch: 29 / 721  loss: 0.03385076826791568  hr: 0  min: 59  sec: 27\n",
      "epoch: 1  batch: 30 / 721  loss: 0.033131716408145925  hr: 0  min: 59  sec: 19\n",
      "epoch: 1  batch: 31 / 721  loss: 0.03966175717481923  hr: 0  min: 59  sec: 14\n",
      "epoch: 1  batch: 32 / 721  loss: 0.03937642556411447  hr: 0  min: 59  sec: 13\n",
      "epoch: 1  batch: 33 / 721  loss: 0.03841349477597484  hr: 1  min: 0  sec: 6\n",
      "epoch: 1  batch: 34 / 721  loss: 0.037784869132070416  hr: 1  min: 0  sec: 2\n",
      "epoch: 1  batch: 35 / 721  loss: 0.037470367238191624  hr: 0  min: 59  sec: 53\n",
      "epoch: 1  batch: 36 / 721  loss: 0.03715096611348498  hr: 0  min: 59  sec: 43\n",
      "epoch: 1  batch: 37 / 721  loss: 0.037542896502575765  hr: 0  min: 59  sec: 25\n",
      "epoch: 1  batch: 38 / 721  loss: 0.03668150305135274  hr: 0  min: 59  sec: 15\n",
      "epoch: 1  batch: 39 / 721  loss: 0.0358535724465186  hr: 0  min: 59  sec: 3\n",
      "epoch: 1  batch: 40 / 721  loss: 0.03499334461230319  hr: 0  min: 59  sec: 59\n",
      "epoch: 1  batch: 41 / 721  loss: 0.03420342730710328  hr: 0  min: 59  sec: 55\n",
      "epoch: 1  batch: 42 / 721  loss: 0.033737955667588505  hr: 0  min: 59  sec: 53\n",
      "epoch: 1  batch: 43 / 721  loss: 0.04118127424302403  hr: 0  min: 59  sec: 53\n",
      "epoch: 1  batch: 44 / 721  loss: 0.04028600579476915  hr: 1  min: 0  sec: 5\n",
      "epoch: 1  batch: 45 / 721  loss: 0.040951561330196756  hr: 1  min: 0  sec: 7\n",
      "epoch: 1  batch: 46 / 721  loss: 0.04039953566287928  hr: 1  min: 0  sec: 5\n",
      "epoch: 1  batch: 47 / 721  loss: 0.03980463559174553  hr: 1  min: 0  sec: 7\n",
      "epoch: 1  batch: 48 / 721  loss: 0.03921459646517178  hr: 1  min: 0  sec: 26\n",
      "epoch: 1  batch: 49 / 721  loss: 0.038910382448657584  hr: 1  min: 0  sec: 37\n",
      "epoch: 1  batch: 50 / 721  loss: 0.03858158692950383  hr: 1  min: 0  sec: 53\n",
      "epoch: 1  batch: 51 / 721  loss: 0.038080132495630165  hr: 1  min: 1  sec: 10\n",
      "epoch: 1  batch: 52 / 721  loss: 0.0377650921291206  hr: 1  min: 1  sec: 24\n",
      "epoch: 1  batch: 53 / 721  loss: 0.03774469920636137  hr: 1  min: 1  sec: 20\n",
      "epoch: 1  batch: 54 / 721  loss: 0.03755605774629792  hr: 1  min: 1  sec: 34\n",
      "epoch: 1  batch: 55 / 721  loss: 0.0369085139086978  hr: 1  min: 1  sec: 47\n",
      "epoch: 1  batch: 56 / 721  loss: 0.0362776083056815  hr: 1  min: 2  sec: 34\n",
      "epoch: 1  batch: 57 / 721  loss: 0.036252737396576425  hr: 1  min: 2  sec: 46\n",
      "epoch: 1  batch: 58 / 721  loss: 0.03668348711979543  hr: 1  min: 2  sec: 46\n",
      "epoch: 1  batch: 59 / 721  loss: 0.03634633047316792  hr: 1  min: 2  sec: 49\n",
      "epoch: 1  batch: 60 / 721  loss: 0.035785760683938864  hr: 1  min: 2  sec: 41\n",
      "epoch: 1  batch: 61 / 721  loss: 0.035250879583697096  hr: 1  min: 2  sec: 32\n",
      "epoch: 1  batch: 62 / 721  loss: 0.03481193573679775  hr: 1  min: 2  sec: 31\n",
      "epoch: 1  batch: 63 / 721  loss: 0.03427234100314626  hr: 1  min: 2  sec: 46\n",
      "epoch: 1  batch: 64 / 721  loss: 0.03383408286481426  hr: 1  min: 2  sec: 41\n",
      "epoch: 1  batch: 65 / 721  loss: 0.03333974721429583  hr: 1  min: 2  sec: 31\n",
      "epoch: 1  batch: 66 / 721  loss: 0.0329976563322513  hr: 1  min: 2  sec: 31\n",
      "epoch: 1  batch: 67 / 721  loss: 0.03345483802901859  hr: 1  min: 2  sec: 20\n",
      "epoch: 1  batch: 68 / 721  loss: 0.03304602672869805  hr: 1  min: 2  sec: 11\n",
      "epoch: 1  batch: 69 / 721  loss: 0.0328012899625574  hr: 1  min: 2  sec: 1\n",
      "epoch: 1  batch: 70 / 721  loss: 0.032428770346866385  hr: 1  min: 1  sec: 56\n",
      "epoch: 1  batch: 71 / 721  loss: 0.0321154062591926  hr: 1  min: 1  sec: 57\n",
      "epoch: 1  batch: 72 / 721  loss: 0.03217204636328259  hr: 1  min: 1  sec: 46\n",
      "epoch: 1  batch: 73 / 721  loss: 0.03208341801057455  hr: 1  min: 1  sec: 35\n",
      "epoch: 1  batch: 74 / 721  loss: 0.032592086720034934  hr: 1  min: 1  sec: 28\n",
      "epoch: 1  batch: 75 / 721  loss: 0.032325690023135394  hr: 1  min: 1  sec: 25\n",
      "epoch: 1  batch: 76 / 721  loss: 0.03219373446451133  hr: 1  min: 1  sec: 17\n",
      "epoch: 1  batch: 77 / 721  loss: 0.031846683418722946  hr: 1  min: 1  sec: 13\n",
      "epoch: 1  batch: 78 / 721  loss: 0.031613787392136425  hr: 1  min: 1  sec: 1\n",
      "epoch: 1  batch: 79 / 721  loss: 0.03125313951271362  hr: 1  min: 0  sec: 58\n",
      "epoch: 1  batch: 80 / 721  loss: 0.030988941470423016  hr: 1  min: 0  sec: 51\n",
      "epoch: 1  batch: 81 / 721  loss: 0.030967379667951416  hr: 1  min: 0  sec: 44\n",
      "epoch: 1  batch: 82 / 721  loss: 0.031220602383411195  hr: 1  min: 0  sec: 37\n",
      "epoch: 1  batch: 83 / 721  loss: 0.030875689151601483  hr: 1  min: 0  sec: 30\n",
      "epoch: 1  batch: 84 / 721  loss: 0.030541879413898902  hr: 1  min: 0  sec: 18\n",
      "epoch: 1  batch: 85 / 721  loss: 0.030210738503785035  hr: 1  min: 0  sec: 16\n",
      "epoch: 1  batch: 86 / 721  loss: 0.029901477002652447  hr: 1  min: 0  sec: 7\n",
      "epoch: 1  batch: 87 / 721  loss: 0.029692129460136652  hr: 1  min: 0  sec: 1\n",
      "epoch: 1  batch: 88 / 721  loss: 0.029469277713029773  hr: 0  min: 59  sec: 53\n",
      "epoch: 1  batch: 89 / 721  loss: 0.02922221505295046  hr: 0  min: 59  sec: 46\n",
      "epoch: 1  batch: 90 / 721  loss: 0.029396844632639033  hr: 0  min: 59  sec: 41\n",
      "epoch: 1  batch: 91 / 721  loss: 0.029162135792021118  hr: 0  min: 59  sec: 28\n",
      "epoch: 1  batch: 92 / 721  loss: 0.02902481364625324  hr: 0  min: 59  sec: 22\n",
      "epoch: 1  batch: 93 / 721  loss: 0.028745316775761025  hr: 0  min: 59  sec: 24\n",
      "epoch: 1  batch: 94 / 721  loss: 0.028542184821414227  hr: 0  min: 59  sec: 12\n",
      "epoch: 1  batch: 95 / 721  loss: 0.02826697209568106  hr: 0  min: 59  sec: 4\n",
      "epoch: 1  batch: 96 / 721  loss: 0.028827624267554103  hr: 0  min: 58  sec: 57\n",
      "epoch: 1  batch: 97 / 721  loss: 0.028668097765833025  hr: 0  min: 58  sec: 48\n",
      "epoch: 1  batch: 98 / 721  loss: 0.028480196569461793  hr: 0  min: 58  sec: 39\n",
      "epoch: 1  batch: 99 / 721  loss: 0.02850322196591702  hr: 0  min: 58  sec: 35\n",
      "epoch: 1  batch: 100 / 721  loss: 0.028733131706831047  hr: 0  min: 58  sec: 36\n",
      "epoch: 1  batch: 101 / 721  loss: 0.028504194888300124  hr: 0  min: 58  sec: 31\n",
      "epoch: 1  batch: 102 / 721  loss: 0.02861613019965315  hr: 0  min: 58  sec: 31\n",
      "epoch: 1  batch: 103 / 721  loss: 0.02836230153599935  hr: 0  min: 58  sec: 27\n",
      "epoch: 1  batch: 104 / 721  loss: 0.028107412489099752  hr: 0  min: 58  sec: 18\n",
      "epoch: 1  batch: 105 / 721  loss: 0.027885230136702636  hr: 0  min: 58  sec: 10\n",
      "epoch: 1  batch: 106 / 721  loss: 0.027644361982688763  hr: 0  min: 58  sec: 8\n",
      "epoch: 1  batch: 107 / 721  loss: 0.027461988788868397  hr: 0  min: 57  sec: 59\n",
      "epoch: 1  batch: 108 / 721  loss: 0.027239453255013493  hr: 0  min: 57  sec: 55\n",
      "epoch: 1  batch: 109 / 721  loss: 0.02706288740331512  hr: 0  min: 57  sec: 50\n",
      "epoch: 1  batch: 110 / 721  loss: 0.02687893821487457  hr: 0  min: 57  sec: 45\n",
      "epoch: 1  batch: 111 / 721  loss: 0.026685898742315504  hr: 0  min: 57  sec: 42\n",
      "epoch: 1  batch: 112 / 721  loss: 0.026563283343421062  hr: 0  min: 57  sec: 36\n",
      "epoch: 1  batch: 113 / 721  loss: 0.026344288047300074  hr: 0  min: 57  sec: 30\n",
      "epoch: 1  batch: 114 / 721  loss: 0.026163637300589727  hr: 0  min: 57  sec: 24\n",
      "epoch: 1  batch: 115 / 721  loss: 0.02608093998911183  hr: 0  min: 57  sec: 21\n",
      "epoch: 1  batch: 116 / 721  loss: 0.025884351349367504  hr: 0  min: 57  sec: 16\n",
      "epoch: 1  batch: 117 / 721  loss: 0.025691903912179712  hr: 0  min: 57  sec: 11\n",
      "epoch: 1  batch: 118 / 721  loss: 0.0255990381647588  hr: 0  min: 57  sec: 8\n",
      "epoch: 1  batch: 119 / 721  loss: 0.025581394814780497  hr: 0  min: 57  sec: 3\n",
      "epoch: 1  batch: 120 / 721  loss: 0.025601541141804775  hr: 0  min: 57  sec: 1\n",
      "epoch: 1  batch: 121 / 721  loss: 0.02540136097347333  hr: 0  min: 56  sec: 58\n",
      "epoch: 1  batch: 122 / 721  loss: 0.025401658785517985  hr: 0  min: 56  sec: 58\n",
      "epoch: 1  batch: 123 / 721  loss: 0.02521087639402916  hr: 0  min: 56  sec: 54\n",
      "epoch: 1  batch: 124 / 721  loss: 0.02503094837330507  hr: 0  min: 56  sec: 53\n",
      "epoch: 1  batch: 125 / 721  loss: 0.024940997333731504  hr: 0  min: 56  sec: 49\n",
      "epoch: 1  batch: 126 / 721  loss: 0.024778245805507703  hr: 0  min: 56  sec: 44\n",
      "epoch: 1  batch: 127 / 721  loss: 0.024602113765990728  hr: 0  min: 56  sec: 43\n",
      "epoch: 1  batch: 128 / 721  loss: 0.024445840744647285  hr: 0  min: 56  sec: 37\n",
      "epoch: 1  batch: 129 / 721  loss: 0.024366188055723763  hr: 0  min: 56  sec: 31\n",
      "epoch: 1  batch: 130 / 721  loss: 0.02441512036558169  hr: 0  min: 56  sec: 29\n",
      "epoch: 1  batch: 131 / 721  loss: 0.024364543379771432  hr: 0  min: 56  sec: 26\n",
      "epoch: 1  batch: 132 / 721  loss: 0.024205028204243827  hr: 0  min: 56  sec: 27\n",
      "epoch: 1  batch: 133 / 721  loss: 0.02402644635320823  hr: 0  min: 56  sec: 21\n",
      "epoch: 1  batch: 134 / 721  loss: 0.02385429055069455  hr: 0  min: 56  sec: 26\n",
      "epoch: 1  batch: 135 / 721  loss: 0.023794160271279032  hr: 0  min: 56  sec: 32\n",
      "epoch: 1  batch: 136 / 721  loss: 0.023680337319734356  hr: 0  min: 56  sec: 25\n",
      "epoch: 1  batch: 137 / 721  loss: 0.023576953943120316  hr: 0  min: 56  sec: 20\n",
      "epoch: 1  batch: 138 / 721  loss: 0.02347484851054395  hr: 0  min: 56  sec: 18\n",
      "epoch: 1  batch: 139 / 721  loss: 0.02370122966725922  hr: 0  min: 56  sec: 16\n",
      "epoch: 1  batch: 140 / 721  loss: 0.02356637131410285  hr: 0  min: 56  sec: 11\n",
      "epoch: 1  batch: 141 / 721  loss: 0.02365323550299847  hr: 0  min: 56  sec: 4\n",
      "epoch: 1  batch: 142 / 721  loss: 0.02350412254425874  hr: 0  min: 55  sec: 55\n",
      "epoch: 1  batch: 143 / 721  loss: 0.02338601589561896  hr: 0  min: 55  sec: 48\n",
      "epoch: 1  batch: 144 / 721  loss: 0.02379112647375021  hr: 0  min: 55  sec: 42\n",
      "epoch: 1  batch: 145 / 721  loss: 0.024026183739248343  hr: 0  min: 55  sec: 37\n",
      "epoch: 1  batch: 146 / 721  loss: 0.023884308722375715  hr: 0  min: 55  sec: 35\n",
      "epoch: 1  batch: 147 / 721  loss: 0.023763116199062302  hr: 0  min: 55  sec: 30\n",
      "epoch: 1  batch: 148 / 721  loss: 0.023652103446570313  hr: 0  min: 55  sec: 23\n",
      "epoch: 1  batch: 149 / 721  loss: 0.023521689795177967  hr: 0  min: 55  sec: 19\n",
      "epoch: 1  batch: 150 / 721  loss: 0.023499494043062442  hr: 0  min: 55  sec: 15\n",
      "epoch: 1  batch: 151 / 721  loss: 0.023381457584085164  hr: 0  min: 55  sec: 12\n",
      "epoch: 1  batch: 152 / 721  loss: 0.023272133466219345  hr: 0  min: 55  sec: 6\n",
      "epoch: 1  batch: 153 / 721  loss: 0.02325286702545865  hr: 0  min: 55  sec: 5\n",
      "epoch: 1  batch: 154 / 721  loss: 0.02313695598243246  hr: 0  min: 55  sec: 0\n",
      "epoch: 1  batch: 155 / 721  loss: 0.022994542785266775  hr: 0  min: 54  sec: 57\n",
      "epoch: 1  batch: 156 / 721  loss: 0.02286239927996529  hr: 0  min: 54  sec: 52\n",
      "epoch: 1  batch: 157 / 721  loss: 0.0228393802823051  hr: 0  min: 54  sec: 49\n",
      "epoch: 1  batch: 158 / 721  loss: 0.022847189929939015  hr: 0  min: 54  sec: 43\n",
      "epoch: 1  batch: 159 / 721  loss: 0.023486069206817593  hr: 0  min: 54  sec: 39\n",
      "epoch: 1  batch: 160 / 721  loss: 0.023389398768813408  hr: 0  min: 54  sec: 34\n",
      "epoch: 1  batch: 161 / 721  loss: 0.023270104745126717  hr: 0  min: 54  sec: 28\n",
      "epoch: 1  batch: 162 / 721  loss: 0.023176682365082354  hr: 0  min: 54  sec: 26\n",
      "epoch: 1  batch: 163 / 721  loss: 0.023061338137368173  hr: 0  min: 54  sec: 23\n",
      "epoch: 1  batch: 164 / 721  loss: 0.022946577666294703  hr: 0  min: 54  sec: 22\n",
      "epoch: 1  batch: 165 / 721  loss: 0.02286198338948783  hr: 0  min: 54  sec: 21\n",
      "epoch: 1  batch: 166 / 721  loss: 0.023148219684084193  hr: 0  min: 54  sec: 15\n",
      "epoch: 1  batch: 167 / 721  loss: 0.02306048598779717  hr: 0  min: 54  sec: 13\n",
      "epoch: 1  batch: 168 / 721  loss: 0.02294491946927987  hr: 0  min: 54  sec: 13\n",
      "epoch: 1  batch: 169 / 721  loss: 0.022839648864878142  hr: 0  min: 54  sec: 11\n",
      "epoch: 1  batch: 170 / 721  loss: 0.022934787595295346  hr: 0  min: 54  sec: 5\n",
      "epoch: 1  batch: 171 / 721  loss: 0.02281174257588954  hr: 0  min: 54  sec: 3\n",
      "epoch: 1  batch: 172 / 721  loss: 0.022724678323145273  hr: 0  min: 53  sec: 58\n",
      "epoch: 1  batch: 173 / 721  loss: 0.022836236008799585  hr: 0  min: 53  sec: 56\n",
      "epoch: 1  batch: 174 / 721  loss: 0.022908077752063768  hr: 0  min: 53  sec: 51\n",
      "epoch: 1  batch: 175 / 721  loss: 0.022876943493694332  hr: 0  min: 53  sec: 54\n",
      "epoch: 1  batch: 176 / 721  loss: 0.022812409284266654  hr: 0  min: 53  sec: 54\n",
      "epoch: 1  batch: 177 / 721  loss: 0.02269881449151116  hr: 0  min: 53  sec: 52\n",
      "epoch: 1  batch: 178 / 721  loss: 0.02266196157339191  hr: 0  min: 53  sec: 47\n",
      "epoch: 1  batch: 179 / 721  loss: 0.02256305328997596  hr: 0  min: 53  sec: 44\n",
      "epoch: 1  batch: 180 / 721  loss: 0.02244583220211401  hr: 0  min: 53  sec: 40\n",
      "epoch: 1  batch: 181 / 721  loss: 0.022338556106625516  hr: 0  min: 53  sec: 36\n",
      "epoch: 1  batch: 182 / 721  loss: 0.02242362211796757  hr: 0  min: 53  sec: 33\n",
      "epoch: 1  batch: 183 / 721  loss: 0.02290220968975543  hr: 0  min: 53  sec: 28\n",
      "epoch: 1  batch: 184 / 721  loss: 0.02282669650958269  hr: 0  min: 53  sec: 25\n",
      "epoch: 1  batch: 185 / 721  loss: 0.02276906135155366  hr: 0  min: 53  sec: 21\n",
      "epoch: 1  batch: 186 / 721  loss: 0.022665485650988207  hr: 0  min: 53  sec: 17\n",
      "epoch: 1  batch: 187 / 721  loss: 0.02264871183464697  hr: 0  min: 53  sec: 20\n",
      "epoch: 1  batch: 188 / 721  loss: 0.022703352980123725  hr: 0  min: 53  sec: 21\n",
      "epoch: 1  batch: 189 / 721  loss: 0.022624781056062106  hr: 0  min: 53  sec: 17\n",
      "epoch: 1  batch: 190 / 721  loss: 0.022508631046021993  hr: 0  min: 53  sec: 13\n",
      "epoch: 1  batch: 191 / 721  loss: 0.02243254630425969  hr: 0  min: 53  sec: 10\n",
      "epoch: 1  batch: 192 / 721  loss: 0.022339194042767  hr: 0  min: 53  sec: 4\n",
      "epoch: 1  batch: 193 / 721  loss: 0.02228838944107347  hr: 0  min: 53  sec: 1\n",
      "epoch: 1  batch: 194 / 721  loss: 0.022301070041535663  hr: 0  min: 52  sec: 58\n",
      "epoch: 1  batch: 195 / 721  loss: 0.02219869540511774  hr: 0  min: 52  sec: 53\n",
      "epoch: 1  batch: 196 / 721  loss: 0.022090154589653938  hr: 0  min: 52  sec: 49\n",
      "epoch: 1  batch: 197 / 721  loss: 0.022008370947439064  hr: 0  min: 52  sec: 50\n",
      "epoch: 1  batch: 198 / 721  loss: 0.02193368998055718  hr: 0  min: 52  sec: 51\n",
      "epoch: 1  batch: 199 / 721  loss: 0.02183821414092476  hr: 0  min: 52  sec: 45\n",
      "epoch: 1  batch: 200 / 721  loss: 0.021794750462431692  hr: 0  min: 52  sec: 44\n",
      "epoch: 1  batch: 201 / 721  loss: 0.02180034757620164  hr: 0  min: 52  sec: 40\n",
      "epoch: 1  batch: 202 / 721  loss: 0.02170059594655949  hr: 0  min: 52  sec: 39\n",
      "epoch: 1  batch: 203 / 721  loss: 0.021866871794861204  hr: 0  min: 52  sec: 34\n",
      "epoch: 1  batch: 204 / 721  loss: 0.02180123730752658  hr: 0  min: 52  sec: 31\n",
      "epoch: 1  batch: 205 / 721  loss: 0.021699415148582264  hr: 0  min: 52  sec: 27\n",
      "epoch: 1  batch: 206 / 721  loss: 0.021952845085128573  hr: 0  min: 52  sec: 23\n",
      "epoch: 1  batch: 207 / 721  loss: 0.02185304277390354  hr: 0  min: 52  sec: 20\n",
      "epoch: 1  batch: 208 / 721  loss: 0.021926051863864322  hr: 0  min: 52  sec: 18\n",
      "epoch: 1  batch: 209 / 721  loss: 0.02183025622805558  hr: 0  min: 52  sec: 15\n",
      "epoch: 1  batch: 210 / 721  loss: 0.0217281946736399  hr: 0  min: 52  sec: 12\n",
      "epoch: 1  batch: 211 / 721  loss: 0.021677311439363956  hr: 0  min: 52  sec: 18\n",
      "epoch: 1  batch: 212 / 721  loss: 0.021597421126366582  hr: 0  min: 52  sec: 15\n",
      "epoch: 1  batch: 213 / 721  loss: 0.021503884293507355  hr: 0  min: 52  sec: 21\n",
      "epoch: 1  batch: 214 / 721  loss: 0.021521815334508743  hr: 0  min: 52  sec: 17\n",
      "epoch: 1  batch: 215 / 721  loss: 0.02143778670213705  hr: 0  min: 52  sec: 18\n",
      "epoch: 1  batch: 216 / 721  loss: 0.02134168804722894  hr: 0  min: 52  sec: 15\n",
      "epoch: 1  batch: 217 / 721  loss: 0.021556959358877654  hr: 0  min: 52  sec: 11\n",
      "epoch: 1  batch: 218 / 721  loss: 0.021487020968738304  hr: 0  min: 52  sec: 7\n",
      "epoch: 1  batch: 219 / 721  loss: 0.021425570289154653  hr: 0  min: 52  sec: 1\n",
      "epoch: 1  batch: 220 / 721  loss: 0.02151954463611632  hr: 0  min: 51  sec: 56\n",
      "epoch: 1  batch: 221 / 721  loss: 0.02145747630764747  hr: 0  min: 51  sec: 55\n",
      "epoch: 1  batch: 222 / 721  loss: 0.021399013171741227  hr: 0  min: 51  sec: 53\n",
      "epoch: 1  batch: 223 / 721  loss: 0.02131441133966014  hr: 0  min: 51  sec: 51\n",
      "epoch: 1  batch: 224 / 721  loss: 0.021231399095605803  hr: 0  min: 51  sec: 46\n",
      "epoch: 1  batch: 225 / 721  loss: 0.021141831461055617  hr: 0  min: 51  sec: 42\n",
      "epoch: 1  batch: 226 / 721  loss: 0.021230118497675574  hr: 0  min: 51  sec: 39\n",
      "epoch: 1  batch: 227 / 721  loss: 0.021151725736283596  hr: 0  min: 51  sec: 38\n",
      "epoch: 1  batch: 228 / 721  loss: 0.02107663891748464  hr: 0  min: 51  sec: 35\n",
      "epoch: 1  batch: 229 / 721  loss: 0.020992830106058243  hr: 0  min: 51  sec: 30\n",
      "epoch: 1  batch: 230 / 721  loss: 0.02099651463808107  hr: 0  min: 51  sec: 29\n",
      "epoch: 1  batch: 231 / 721  loss: 0.020933304983014805  hr: 0  min: 51  sec: 27\n",
      "epoch: 1  batch: 232 / 721  loss: 0.02086282666315473  hr: 0  min: 51  sec: 23\n",
      "epoch: 1  batch: 233 / 721  loss: 0.02078847777482638  hr: 0  min: 51  sec: 19\n",
      "epoch: 1  batch: 234 / 721  loss: 0.020709298086540703  hr: 0  min: 51  sec: 16\n",
      "epoch: 1  batch: 235 / 721  loss: 0.020720907717948146  hr: 0  min: 51  sec: 17\n",
      "epoch: 1  batch: 236 / 721  loss: 0.020730606064331615  hr: 0  min: 51  sec: 14\n",
      "epoch: 1  batch: 237 / 721  loss: 0.020676537229358277  hr: 0  min: 51  sec: 14\n",
      "epoch: 1  batch: 238 / 721  loss: 0.02060264596892149  hr: 0  min: 51  sec: 14\n",
      "epoch: 1  batch: 239 / 721  loss: 0.020824373709588315  hr: 0  min: 51  sec: 14\n",
      "epoch: 1  batch: 240 / 721  loss: 0.020753346160563523  hr: 0  min: 51  sec: 15\n",
      "epoch: 1  batch: 241 / 721  loss: 0.020725633939501106  hr: 0  min: 51  sec: 12\n",
      "epoch: 1  batch: 242 / 721  loss: 0.020648654869854767  hr: 0  min: 51  sec: 8\n",
      "epoch: 1  batch: 243 / 721  loss: 0.02057239173352431  hr: 0  min: 51  sec: 5\n",
      "epoch: 1  batch: 244 / 721  loss: 0.02062327928517155  hr: 0  min: 51  sec: 2\n",
      "epoch: 1  batch: 245 / 721  loss: 0.02055802084517437  hr: 0  min: 51  sec: 1\n",
      "epoch: 1  batch: 246 / 721  loss: 0.020548138601021136  hr: 0  min: 50  sec: 59\n",
      "epoch: 1  batch: 247 / 721  loss: 0.02051655332822266  hr: 0  min: 50  sec: 57\n",
      "epoch: 1  batch: 248 / 721  loss: 0.020615557764563898  hr: 0  min: 50  sec: 54\n",
      "epoch: 1  batch: 249 / 721  loss: 0.020655229972066716  hr: 0  min: 50  sec: 51\n",
      "epoch: 1  batch: 250 / 721  loss: 0.020633626897004435  hr: 0  min: 50  sec: 51\n",
      "epoch: 1  batch: 251 / 721  loss: 0.02055967788676271  hr: 0  min: 50  sec: 48\n",
      "epoch: 1  batch: 252 / 721  loss: 0.020761230216839253  hr: 0  min: 50  sec: 45\n",
      "epoch: 1  batch: 253 / 721  loss: 0.02069539626015317  hr: 0  min: 50  sec: 41\n",
      "epoch: 1  batch: 254 / 721  loss: 0.02062154733853169  hr: 0  min: 50  sec: 39\n",
      "epoch: 1  batch: 255 / 721  loss: 0.02054860650929257  hr: 0  min: 50  sec: 36\n",
      "epoch: 1  batch: 256 / 721  loss: 0.02049637001857718  hr: 0  min: 50  sec: 37\n",
      "epoch: 1  batch: 257 / 721  loss: 0.020426441104163084  hr: 0  min: 50  sec: 34\n",
      "epoch: 1  batch: 258 / 721  loss: 0.021002717681302213  hr: 0  min: 50  sec: 31\n",
      "epoch: 1  batch: 259 / 721  loss: 0.02093251097129755  hr: 0  min: 50  sec: 28\n",
      "epoch: 1  batch: 260 / 721  loss: 0.02086548990751348  hr: 0  min: 50  sec: 24\n",
      "epoch: 1  batch: 261 / 721  loss: 0.02078909968359171  hr: 0  min: 50  sec: 23\n",
      "epoch: 1  batch: 262 / 721  loss: 0.020714899480501935  hr: 0  min: 50  sec: 21\n",
      "epoch: 1  batch: 263 / 721  loss: 0.020652397964109875  hr: 0  min: 50  sec: 22\n",
      "epoch: 1  batch: 264 / 721  loss: 0.02059687219485623  hr: 0  min: 50  sec: 18\n",
      "epoch: 1  batch: 265 / 721  loss: 0.020586904171603856  hr: 0  min: 50  sec: 16\n",
      "epoch: 1  batch: 266 / 721  loss: 0.020540695302989298  hr: 0  min: 50  sec: 13\n",
      "epoch: 1  batch: 267 / 721  loss: 0.02068479384427754  hr: 0  min: 50  sec: 12\n",
      "epoch: 1  batch: 268 / 721  loss: 0.020650597725219072  hr: 0  min: 50  sec: 11\n",
      "epoch: 1  batch: 269 / 721  loss: 0.02058934324780621  hr: 0  min: 50  sec: 8\n",
      "epoch: 1  batch: 270 / 721  loss: 0.020730964922134904  hr: 0  min: 50  sec: 5\n",
      "epoch: 1  batch: 271 / 721  loss: 0.02065911174507389  hr: 0  min: 50  sec: 5\n",
      "epoch: 1  batch: 272 / 721  loss: 0.020606595153902375  hr: 0  min: 50  sec: 3\n",
      "epoch: 1  batch: 273 / 721  loss: 0.020580094171949788  hr: 0  min: 50  sec: 6\n",
      "epoch: 1  batch: 274 / 721  loss: 0.020606137044709958  hr: 0  min: 50  sec: 4\n",
      "epoch: 1  batch: 275 / 721  loss: 0.02108407258384184  hr: 0  min: 50  sec: 1\n",
      "epoch: 1  batch: 276 / 721  loss: 0.021135282453779717  hr: 0  min: 49  sec: 56\n",
      "epoch: 1  batch: 277 / 721  loss: 0.021070833595209865  hr: 0  min: 49  sec: 53\n",
      "epoch: 1  batch: 278 / 721  loss: 0.021007758997302842  hr: 0  min: 49  sec: 48\n",
      "epoch: 1  batch: 279 / 721  loss: 0.021335333662410517  hr: 0  min: 49  sec: 46\n",
      "epoch: 1  batch: 280 / 721  loss: 0.021268340560137794  hr: 0  min: 49  sec: 42\n",
      "epoch: 1  batch: 281 / 721  loss: 0.02120149314469406  hr: 0  min: 49  sec: 40\n",
      "epoch: 1  batch: 282 / 721  loss: 0.021214804346966293  hr: 0  min: 49  sec: 38\n",
      "epoch: 1  batch: 283 / 721  loss: 0.021144956980018247  hr: 0  min: 49  sec: 35\n",
      "epoch: 1  batch: 284 / 721  loss: 0.021091802458382953  hr: 0  min: 49  sec: 34\n",
      "epoch: 1  batch: 285 / 721  loss: 0.021034626623006994  hr: 0  min: 49  sec: 30\n",
      "epoch: 1  batch: 286 / 721  loss: 0.020989139902489292  hr: 0  min: 49  sec: 27\n",
      "epoch: 1  batch: 287 / 721  loss: 0.020994060084962803  hr: 0  min: 49  sec: 25\n",
      "epoch: 1  batch: 288 / 721  loss: 0.020930800581582944  hr: 0  min: 49  sec: 24\n",
      "epoch: 1  batch: 289 / 721  loss: 0.020861683915200834  hr: 0  min: 49  sec: 20\n",
      "epoch: 1  batch: 290 / 721  loss: 0.020823432247310973  hr: 0  min: 49  sec: 17\n",
      "epoch: 1  batch: 291 / 721  loss: 0.02077493645941688  hr: 0  min: 49  sec: 15\n",
      "epoch: 1  batch: 292 / 721  loss: 0.02079790315424548  hr: 0  min: 49  sec: 14\n",
      "epoch: 1  batch: 293 / 721  loss: 0.020858400271559427  hr: 0  min: 49  sec: 14\n",
      "epoch: 1  batch: 294 / 721  loss: 0.020790077379740757  hr: 0  min: 49  sec: 11\n",
      "epoch: 1  batch: 295 / 721  loss: 0.020747784611678255  hr: 0  min: 49  sec: 10\n",
      "epoch: 1  batch: 296 / 721  loss: 0.02098957008520547  hr: 0  min: 49  sec: 8\n",
      "epoch: 1  batch: 297 / 721  loss: 0.020948050250177763  hr: 0  min: 49  sec: 6\n",
      "epoch: 1  batch: 298 / 721  loss: 0.020889677839129445  hr: 0  min: 49  sec: 5\n",
      "epoch: 1  batch: 299 / 721  loss: 0.020956572201776547  hr: 0  min: 49  sec: 3\n",
      "epoch: 1  batch: 300 / 721  loss: 0.0210427054084721  hr: 0  min: 49  sec: 2\n",
      "epoch: 1  batch: 301 / 721  loss: 0.020985179915393785  hr: 0  min: 49  sec: 1\n",
      "epoch: 1  batch: 302 / 721  loss: 0.02092075522031885  hr: 0  min: 48  sec: 57\n",
      "epoch: 1  batch: 303 / 721  loss: 0.020878361506259265  hr: 0  min: 48  sec: 55\n",
      "epoch: 1  batch: 304 / 721  loss: 0.020811984081247875  hr: 0  min: 48  sec: 53\n",
      "epoch: 1  batch: 305 / 721  loss: 0.02081401277129294  hr: 0  min: 48  sec: 51\n",
      "epoch: 1  batch: 306 / 721  loss: 0.02083345010027889  hr: 0  min: 48  sec: 50\n",
      "epoch: 1  batch: 307 / 721  loss: 0.020779576877694036  hr: 0  min: 48  sec: 48\n",
      "epoch: 1  batch: 308 / 721  loss: 0.020727872993746416  hr: 0  min: 48  sec: 46\n",
      "epoch: 1  batch: 309 / 721  loss: 0.02130086093089501  hr: 0  min: 48  sec: 44\n",
      "epoch: 1  batch: 310 / 721  loss: 0.021243585927145286  hr: 0  min: 48  sec: 40\n",
      "epoch: 1  batch: 311 / 721  loss: 0.021244288573488503  hr: 0  min: 48  sec: 39\n",
      "epoch: 1  batch: 312 / 721  loss: 0.021185990911106227  hr: 0  min: 48  sec: 36\n",
      "epoch: 1  batch: 313 / 721  loss: 0.021131131234270083  hr: 0  min: 48  sec: 34\n",
      "epoch: 1  batch: 314 / 721  loss: 0.021139433609034752  hr: 0  min: 48  sec: 31\n",
      "epoch: 1  batch: 315 / 721  loss: 0.02110852608170789  hr: 0  min: 48  sec: 27\n",
      "epoch: 1  batch: 316 / 721  loss: 0.021062243072691084  hr: 0  min: 48  sec: 24\n",
      "epoch: 1  batch: 317 / 721  loss: 0.021056181222456727  hr: 0  min: 48  sec: 21\n",
      "epoch: 1  batch: 318 / 721  loss: 0.02114573795556709  hr: 0  min: 48  sec: 21\n",
      "epoch: 1  batch: 319 / 721  loss: 0.02111364819036817  hr: 0  min: 48  sec: 17\n",
      "epoch: 1  batch: 320 / 721  loss: 0.021181642994724824  hr: 0  min: 48  sec: 13\n",
      "epoch: 1  batch: 321 / 721  loss: 0.021163280191704357  hr: 0  min: 48  sec: 10\n",
      "epoch: 1  batch: 322 / 721  loss: 0.021107176701362557  hr: 0  min: 48  sec: 8\n",
      "epoch: 1  batch: 323 / 721  loss: 0.021097639749412665  hr: 0  min: 48  sec: 4\n",
      "epoch: 1  batch: 324 / 721  loss: 0.02107964359580634  hr: 0  min: 48  sec: 1\n",
      "epoch: 1  batch: 325 / 721  loss: 0.021027824591504984  hr: 0  min: 47  sec: 58\n",
      "epoch: 1  batch: 326 / 721  loss: 0.02108481141213296  hr: 0  min: 47  sec: 55\n",
      "epoch: 1  batch: 327 / 721  loss: 0.02144153474195325  hr: 0  min: 47  sec: 50\n",
      "epoch: 1  batch: 328 / 721  loss: 0.02153992468837958  hr: 0  min: 47  sec: 46\n",
      "epoch: 1  batch: 329 / 721  loss: 0.021626974141177802  hr: 0  min: 47  sec: 42\n",
      "epoch: 1  batch: 330 / 721  loss: 0.02156712581892145  hr: 0  min: 47  sec: 42\n",
      "epoch: 1  batch: 331 / 721  loss: 0.021524340297068043  hr: 0  min: 47  sec: 39\n",
      "epoch: 1  batch: 332 / 721  loss: 0.022114913439443364  hr: 0  min: 47  sec: 35\n",
      "epoch: 1  batch: 333 / 721  loss: 0.022068736877648282  hr: 0  min: 47  sec: 32\n",
      "epoch: 1  batch: 334 / 721  loss: 0.022020472817399685  hr: 0  min: 47  sec: 33\n",
      "epoch: 1  batch: 335 / 721  loss: 0.021960460480194843  hr: 0  min: 47  sec: 31\n",
      "epoch: 1  batch: 336 / 721  loss: 0.021934470266517434  hr: 0  min: 47  sec: 27\n",
      "epoch: 1  batch: 337 / 721  loss: 0.021951175545696693  hr: 0  min: 47  sec: 24\n",
      "epoch: 1  batch: 338 / 721  loss: 0.021955720423917097  hr: 0  min: 47  sec: 20\n",
      "epoch: 1  batch: 339 / 721  loss: 0.02191545800479324  hr: 0  min: 47  sec: 17\n",
      "epoch: 1  batch: 340 / 721  loss: 0.021952423228118707  hr: 0  min: 47  sec: 14\n",
      "epoch: 1  batch: 341 / 721  loss: 0.021942605179221756  hr: 0  min: 47  sec: 11\n",
      "epoch: 1  batch: 342 / 721  loss: 0.02217353656501659  hr: 0  min: 47  sec: 7\n",
      "epoch: 1  batch: 343 / 721  loss: 0.022116033122185807  hr: 0  min: 47  sec: 5\n",
      "epoch: 1  batch: 344 / 721  loss: 0.02224732578678265  hr: 0  min: 47  sec: 1\n",
      "epoch: 1  batch: 345 / 721  loss: 0.02240567002791331  hr: 0  min: 46  sec: 58\n",
      "epoch: 1  batch: 346 / 721  loss: 0.0223790101816836  hr: 0  min: 46  sec: 55\n",
      "epoch: 1  batch: 347 / 721  loss: 0.0223812034082034  hr: 0  min: 46  sec: 51\n",
      "epoch: 1  batch: 348 / 721  loss: 0.02237377067749862  hr: 0  min: 46  sec: 47\n",
      "epoch: 1  batch: 349 / 721  loss: 0.02231876307140761  hr: 0  min: 46  sec: 43\n",
      "epoch: 1  batch: 350 / 721  loss: 0.022300988515656043  hr: 0  min: 46  sec: 39\n",
      "epoch: 1  batch: 351 / 721  loss: 0.022482166703650462  hr: 0  min: 46  sec: 37\n",
      "epoch: 1  batch: 352 / 721  loss: 0.022504979104351976  hr: 0  min: 46  sec: 34\n",
      "epoch: 1  batch: 353 / 721  loss: 0.022449589163680343  hr: 0  min: 46  sec: 35\n",
      "epoch: 1  batch: 354 / 721  loss: 0.022393683791847894  hr: 0  min: 46  sec: 32\n",
      "epoch: 1  batch: 355 / 721  loss: 0.022334499559840713  hr: 0  min: 46  sec: 30\n",
      "epoch: 1  batch: 356 / 721  loss: 0.02227633202579618  hr: 0  min: 46  sec: 27\n",
      "epoch: 1  batch: 357 / 721  loss: 0.02233973628567748  hr: 0  min: 46  sec: 24\n",
      "epoch: 1  batch: 358 / 721  loss: 0.022283680551095513  hr: 0  min: 46  sec: 19\n",
      "epoch: 1  batch: 359 / 721  loss: 0.022227849828907544  hr: 0  min: 46  sec: 15\n",
      "epoch: 1  batch: 360 / 721  loss: 0.022272274764206183  hr: 0  min: 46  sec: 12\n",
      "epoch: 1  batch: 361 / 721  loss: 0.022302724407560776  hr: 0  min: 46  sec: 9\n",
      "epoch: 1  batch: 362 / 721  loss: 0.02226506875133597  hr: 0  min: 46  sec: 5\n",
      "epoch: 1  batch: 363 / 721  loss: 0.02220653411241174  hr: 0  min: 46  sec: 2\n",
      "epoch: 1  batch: 364 / 721  loss: 0.02227424700390407  hr: 0  min: 45  sec: 58\n",
      "epoch: 1  batch: 365 / 721  loss: 0.022251560619780283  hr: 0  min: 45  sec: 56\n",
      "epoch: 1  batch: 366 / 721  loss: 0.02222372239235791  hr: 0  min: 45  sec: 51\n",
      "epoch: 1  batch: 367 / 721  loss: 0.022205483487236874  hr: 0  min: 45  sec: 48\n",
      "epoch: 1  batch: 368 / 721  loss: 0.022158572648075515  hr: 0  min: 45  sec: 44\n",
      "epoch: 1  batch: 369 / 721  loss: 0.02210447639468262  hr: 0  min: 45  sec: 41\n",
      "epoch: 1  batch: 370 / 721  loss: 0.02204877952643909  hr: 0  min: 45  sec: 38\n",
      "epoch: 1  batch: 371 / 721  loss: 0.022000901508750646  hr: 0  min: 45  sec: 35\n",
      "epoch: 1  batch: 372 / 721  loss: 0.022027676081130286  hr: 0  min: 45  sec: 31\n",
      "epoch: 1  batch: 373 / 721  loss: 0.022015267206326593  hr: 0  min: 45  sec: 30\n",
      "epoch: 1  batch: 374 / 721  loss: 0.02196086920247809  hr: 0  min: 45  sec: 26\n",
      "epoch: 1  batch: 375 / 721  loss: 0.0221984258791587  hr: 0  min: 45  sec: 24\n",
      "epoch: 1  batch: 376 / 721  loss: 0.022194816646778564  hr: 0  min: 45  sec: 21\n",
      "epoch: 1  batch: 377 / 721  loss: 0.022150269532974547  hr: 0  min: 45  sec: 18\n",
      "epoch: 1  batch: 378 / 721  loss: 0.02210904352088821  hr: 0  min: 45  sec: 14\n",
      "epoch: 1  batch: 379 / 721  loss: 0.02206459937570801  hr: 0  min: 45  sec: 12\n",
      "epoch: 1  batch: 380 / 721  loss: 0.022010343104652986  hr: 0  min: 45  sec: 9\n",
      "epoch: 1  batch: 381 / 721  loss: 0.021957706387556255  hr: 0  min: 45  sec: 6\n",
      "epoch: 1  batch: 382 / 721  loss: 0.021984052470186116  hr: 0  min: 45  sec: 3\n",
      "epoch: 1  batch: 383 / 721  loss: 0.021944269178117266  hr: 0  min: 45  sec: 0\n",
      "epoch: 1  batch: 384 / 721  loss: 0.0219842469281654  hr: 0  min: 44  sec: 56\n",
      "epoch: 1  batch: 385 / 721  loss: 0.02193790676273321  hr: 0  min: 44  sec: 54\n",
      "epoch: 1  batch: 386 / 721  loss: 0.021912342995490247  hr: 0  min: 44  sec: 51\n",
      "epoch: 1  batch: 387 / 721  loss: 0.02186477278638691  hr: 0  min: 44  sec: 48\n",
      "epoch: 1  batch: 388 / 721  loss: 0.02181501473012421  hr: 0  min: 44  sec: 46\n",
      "epoch: 1  batch: 389 / 721  loss: 0.021865511380790213  hr: 0  min: 44  sec: 44\n",
      "epoch: 1  batch: 390 / 721  loss: 0.021816474704433066  hr: 0  min: 44  sec: 41\n",
      "epoch: 1  batch: 391 / 721  loss: 0.02181057964847304  hr: 0  min: 44  sec: 37\n",
      "epoch: 1  batch: 392 / 721  loss: 0.021785194827650546  hr: 0  min: 44  sec: 34\n",
      "epoch: 1  batch: 393 / 721  loss: 0.021733667240931318  hr: 0  min: 44  sec: 32\n",
      "epoch: 1  batch: 394 / 721  loss: 0.021728685938030467  hr: 0  min: 44  sec: 29\n",
      "epoch: 1  batch: 395 / 721  loss: 0.021688776878607638  hr: 0  min: 44  sec: 26\n",
      "epoch: 1  batch: 396 / 721  loss: 0.021722440824581128  hr: 0  min: 44  sec: 23\n",
      "epoch: 1  batch: 397 / 721  loss: 0.021694143033326636  hr: 0  min: 44  sec: 19\n",
      "epoch: 1  batch: 398 / 721  loss: 0.021661907582249534  hr: 0  min: 44  sec: 17\n",
      "epoch: 1  batch: 399 / 721  loss: 0.021632477979920923  hr: 0  min: 44  sec: 15\n",
      "epoch: 1  batch: 400 / 721  loss: 0.022449733245084643  hr: 0  min: 44  sec: 14\n",
      "epoch: 1  batch: 401 / 721  loss: 0.022438094556750266  hr: 0  min: 44  sec: 11\n",
      "epoch: 1  batch: 402 / 721  loss: 0.022494304311633764  hr: 0  min: 44  sec: 8\n",
      "epoch: 1  batch: 403 / 721  loss: 0.02245261268402801  hr: 0  min: 44  sec: 5\n",
      "epoch: 1  batch: 404 / 721  loss: 0.022434914324765146  hr: 0  min: 44  sec: 2\n",
      "epoch: 1  batch: 405 / 721  loss: 0.022397352440389057  hr: 0  min: 44  sec: 0\n",
      "epoch: 1  batch: 406 / 721  loss: 0.02241241810603923  hr: 0  min: 43  sec: 56\n",
      "epoch: 1  batch: 407 / 721  loss: 0.02238462557388339  hr: 0  min: 43  sec: 52\n",
      "epoch: 1  batch: 408 / 721  loss: 0.022369782016147498  hr: 0  min: 43  sec: 50\n",
      "epoch: 1  batch: 409 / 721  loss: 0.022368429789179026  hr: 0  min: 43  sec: 47\n",
      "epoch: 1  batch: 410 / 721  loss: 0.022315233181693546  hr: 0  min: 43  sec: 44\n",
      "epoch: 1  batch: 411 / 721  loss: 0.022267574527900815  hr: 0  min: 43  sec: 42\n",
      "epoch: 1  batch: 412 / 721  loss: 0.02221746138375856  hr: 0  min: 43  sec: 39\n",
      "epoch: 1  batch: 413 / 721  loss: 0.022212447739444724  hr: 0  min: 43  sec: 36\n",
      "epoch: 1  batch: 414 / 721  loss: 0.022168101103915067  hr: 0  min: 43  sec: 32\n",
      "epoch: 1  batch: 415 / 721  loss: 0.02212668278370984  hr: 0  min: 43  sec: 29\n",
      "epoch: 1  batch: 416 / 721  loss: 0.022139248154906872  hr: 0  min: 43  sec: 28\n",
      "epoch: 1  batch: 417 / 721  loss: 0.022090189883580913  hr: 0  min: 43  sec: 25\n",
      "epoch: 1  batch: 418 / 721  loss: 0.022039268386194317  hr: 0  min: 43  sec: 22\n",
      "epoch: 1  batch: 419 / 721  loss: 0.022017753740613124  hr: 0  min: 43  sec: 19\n",
      "epoch: 1  batch: 420 / 721  loss: 0.021968648891543992  hr: 0  min: 43  sec: 16\n",
      "epoch: 1  batch: 421 / 721  loss: 0.021980222866048088  hr: 0  min: 43  sec: 13\n",
      "epoch: 1  batch: 422 / 721  loss: 0.02193292089462362  hr: 0  min: 43  sec: 10\n",
      "epoch: 1  batch: 423 / 721  loss: 0.02192972028793395  hr: 0  min: 43  sec: 8\n",
      "epoch: 1  batch: 424 / 721  loss: 0.021906015881678235  hr: 0  min: 43  sec: 5\n",
      "epoch: 1  batch: 425 / 721  loss: 0.021909870322423933  hr: 0  min: 43  sec: 3\n",
      "epoch: 1  batch: 426 / 721  loss: 0.021884471548684576  hr: 0  min: 43  sec: 0\n",
      "epoch: 1  batch: 427 / 721  loss: 0.0218370320446232  hr: 0  min: 42  sec: 57\n",
      "epoch: 1  batch: 428 / 721  loss: 0.021788596151743157  hr: 0  min: 42  sec: 54\n",
      "epoch: 1  batch: 429 / 721  loss: 0.021749665939028207  hr: 0  min: 42  sec: 51\n",
      "epoch: 1  batch: 430 / 721  loss: 0.02184992440398187  hr: 0  min: 42  sec: 47\n",
      "epoch: 1  batch: 431 / 721  loss: 0.021801083393596446  hr: 0  min: 42  sec: 44\n",
      "epoch: 1  batch: 432 / 721  loss: 0.0217655313474636  hr: 0  min: 42  sec: 41\n",
      "epoch: 1  batch: 433 / 721  loss: 0.021802237309586994  hr: 0  min: 42  sec: 38\n",
      "epoch: 1  batch: 434 / 721  loss: 0.0217535840574741  hr: 0  min: 42  sec: 35\n",
      "epoch: 1  batch: 435 / 721  loss: 0.021714414189631204  hr: 0  min: 42  sec: 31\n",
      "epoch: 1  batch: 436 / 721  loss: 0.021670129723350813  hr: 0  min: 42  sec: 29\n",
      "epoch: 1  batch: 437 / 721  loss: 0.022004928372390632  hr: 0  min: 42  sec: 26\n",
      "epoch: 1  batch: 438 / 721  loss: 0.021969958182653418  hr: 0  min: 42  sec: 23\n",
      "epoch: 1  batch: 439 / 721  loss: 0.022023750120837026  hr: 0  min: 42  sec: 19\n",
      "epoch: 1  batch: 440 / 721  loss: 0.0219874706232407  hr: 0  min: 42  sec: 17\n",
      "epoch: 1  batch: 441 / 721  loss: 0.02203450024479318  hr: 0  min: 42  sec: 14\n",
      "epoch: 1  batch: 442 / 721  loss: 0.021996017254357503  hr: 0  min: 42  sec: 11\n",
      "epoch: 1  batch: 443 / 721  loss: 0.02208235450728868  hr: 0  min: 42  sec: 11\n",
      "epoch: 1  batch: 444 / 721  loss: 0.02204080444186672  hr: 0  min: 42  sec: 9\n",
      "epoch: 1  batch: 445 / 721  loss: 0.022033094355949003  hr: 0  min: 42  sec: 6\n",
      "epoch: 1  batch: 446 / 721  loss: 0.02201438153593544  hr: 0  min: 42  sec: 3\n",
      "epoch: 1  batch: 447 / 721  loss: 0.02196837786080626  hr: 0  min: 42  sec: 0\n",
      "epoch: 1  batch: 448 / 721  loss: 0.0219388494946153  hr: 0  min: 41  sec: 56\n",
      "epoch: 1  batch: 449 / 721  loss: 0.021912141514769373  hr: 0  min: 41  sec: 54\n",
      "epoch: 1  batch: 450 / 721  loss: 0.021866709941467787  hr: 0  min: 41  sec: 51\n",
      "epoch: 1  batch: 451 / 721  loss: 0.021831183018719884  hr: 0  min: 41  sec: 48\n",
      "epoch: 1  batch: 452 / 721  loss: 0.02178754958351693  hr: 0  min: 41  sec: 45\n",
      "epoch: 1  batch: 453 / 721  loss: 0.021747898637503694  hr: 0  min: 41  sec: 42\n",
      "epoch: 1  batch: 454 / 721  loss: 0.021707995782597585  hr: 0  min: 41  sec: 39\n",
      "epoch: 1  batch: 455 / 721  loss: 0.02168324954090077  hr: 0  min: 41  sec: 36\n",
      "epoch: 1  batch: 456 / 721  loss: 0.021802896037562483  hr: 0  min: 41  sec: 34\n",
      "epoch: 1  batch: 457 / 721  loss: 0.021757556845602648  hr: 0  min: 41  sec: 31\n",
      "epoch: 1  batch: 458 / 721  loss: 0.021730676684495544  hr: 0  min: 41  sec: 28\n",
      "epoch: 1  batch: 459 / 721  loss: 0.021711924714622167  hr: 0  min: 41  sec: 28\n",
      "epoch: 1  batch: 460 / 721  loss: 0.021668096201977714  hr: 0  min: 41  sec: 26\n",
      "epoch: 1  batch: 461 / 721  loss: 0.021625701764256565  hr: 0  min: 41  sec: 23\n",
      "epoch: 1  batch: 462 / 721  loss: 0.02159212533180709  hr: 0  min: 41  sec: 22\n",
      "epoch: 1  batch: 463 / 721  loss: 0.021561781537795005  hr: 0  min: 41  sec: 19\n",
      "epoch: 1  batch: 464 / 721  loss: 0.021539533681350115  hr: 0  min: 41  sec: 16\n",
      "epoch: 1  batch: 465 / 721  loss: 0.021606944262998938  hr: 0  min: 41  sec: 15\n",
      "epoch: 1  batch: 466 / 721  loss: 0.02157138233954165  hr: 0  min: 41  sec: 12\n",
      "epoch: 1  batch: 467 / 721  loss: 0.021546619873415634  hr: 0  min: 41  sec: 9\n",
      "epoch: 1  batch: 468 / 721  loss: 0.021526257992007185  hr: 0  min: 41  sec: 7\n",
      "epoch: 1  batch: 469 / 721  loss: 0.021483168942912884  hr: 0  min: 41  sec: 4\n",
      "epoch: 1  batch: 470 / 721  loss: 0.02145436580678042  hr: 0  min: 41  sec: 2\n",
      "epoch: 1  batch: 471 / 721  loss: 0.021411199083800413  hr: 0  min: 40  sec: 59\n",
      "epoch: 1  batch: 472 / 721  loss: 0.021376447772527788  hr: 0  min: 40  sec: 58\n",
      "epoch: 1  batch: 473 / 721  loss: 0.021340058942905766  hr: 0  min: 40  sec: 56\n",
      "epoch: 1  batch: 474 / 721  loss: 0.02130638884707356  hr: 0  min: 40  sec: 53\n",
      "epoch: 1  batch: 475 / 721  loss: 0.021296301198522806  hr: 0  min: 40  sec: 50\n",
      "epoch: 1  batch: 476 / 721  loss: 0.02125579466525526  hr: 0  min: 40  sec: 48\n",
      "epoch: 1  batch: 477 / 721  loss: 0.021214150653727865  hr: 0  min: 40  sec: 47\n",
      "epoch: 1  batch: 478 / 721  loss: 0.021182810224212267  hr: 0  min: 40  sec: 45\n",
      "epoch: 1  batch: 479 / 721  loss: 0.021191255369265943  hr: 0  min: 40  sec: 42\n",
      "epoch: 1  batch: 480 / 721  loss: 0.02129165866153926  hr: 0  min: 40  sec: 39\n",
      "epoch: 1  batch: 481 / 721  loss: 0.02128920282701683  hr: 0  min: 40  sec: 36\n",
      "epoch: 1  batch: 482 / 721  loss: 0.021249026072120265  hr: 0  min: 40  sec: 33\n",
      "epoch: 1  batch: 483 / 721  loss: 0.021209027268140487  hr: 0  min: 40  sec: 30\n",
      "epoch: 1  batch: 484 / 721  loss: 0.021178490176259574  hr: 0  min: 40  sec: 27\n",
      "epoch: 1  batch: 485 / 721  loss: 0.02117189998665258  hr: 0  min: 40  sec: 24\n",
      "epoch: 1  batch: 486 / 721  loss: 0.02113635180925964  hr: 0  min: 40  sec: 21\n",
      "epoch: 1  batch: 487 / 721  loss: 0.021387560463219296  hr: 0  min: 40  sec: 18\n",
      "epoch: 1  batch: 488 / 721  loss: 0.021409370201641263  hr: 0  min: 40  sec: 16\n",
      "epoch: 1  batch: 489 / 721  loss: 0.02137461964488325  hr: 0  min: 40  sec: 13\n",
      "epoch: 1  batch: 490 / 721  loss: 0.021352370709539582  hr: 0  min: 40  sec: 10\n",
      "epoch: 1  batch: 491 / 721  loss: 0.021312456173941306  hr: 0  min: 40  sec: 7\n",
      "epoch: 1  batch: 492 / 721  loss: 0.021272040928590464  hr: 0  min: 40  sec: 4\n",
      "epoch: 1  batch: 493 / 721  loss: 0.021248616204910174  hr: 0  min: 40  sec: 1\n",
      "epoch: 1  batch: 494 / 721  loss: 0.021207927189084423  hr: 0  min: 39  sec: 58\n",
      "epoch: 1  batch: 495 / 721  loss: 0.021591334280292175  hr: 0  min: 39  sec: 55\n",
      "epoch: 1  batch: 496 / 721  loss: 0.021608649139213208  hr: 0  min: 39  sec: 52\n",
      "epoch: 1  batch: 497 / 721  loss: 0.02159692077039951  hr: 0  min: 39  sec: 49\n",
      "epoch: 1  batch: 498 / 721  loss: 0.0216515603791207  hr: 0  min: 39  sec: 47\n",
      "epoch: 1  batch: 499 / 721  loss: 0.02161475413688645  hr: 0  min: 39  sec: 44\n",
      "epoch: 1  batch: 500 / 721  loss: 0.02158118989242939  hr: 0  min: 39  sec: 41\n",
      "epoch: 1  batch: 501 / 721  loss: 0.021557149242323  hr: 0  min: 39  sec: 39\n",
      "epoch: 1  batch: 502 / 721  loss: 0.021558056004051827  hr: 0  min: 39  sec: 36\n",
      "epoch: 1  batch: 503 / 721  loss: 0.021553857875217186  hr: 0  min: 39  sec: 33\n",
      "epoch: 1  batch: 504 / 721  loss: 0.021545484703806107  hr: 0  min: 39  sec: 31\n",
      "epoch: 1  batch: 505 / 721  loss: 0.02174036723883168  hr: 0  min: 39  sec: 27\n",
      "epoch: 1  batch: 506 / 721  loss: 0.02174937198776706  hr: 0  min: 39  sec: 26\n",
      "epoch: 1  batch: 507 / 721  loss: 0.02174431780054458  hr: 0  min: 39  sec: 26\n",
      "epoch: 1  batch: 508 / 721  loss: 0.021759995770093885  hr: 0  min: 39  sec: 23\n",
      "epoch: 1  batch: 509 / 721  loss: 0.02178867487436982  hr: 0  min: 39  sec: 20\n",
      "epoch: 1  batch: 510 / 721  loss: 0.021834628493239756  hr: 0  min: 39  sec: 17\n",
      "epoch: 1  batch: 511 / 721  loss: 0.021870090774888787  hr: 0  min: 39  sec: 14\n",
      "epoch: 1  batch: 512 / 721  loss: 0.021890642802816274  hr: 0  min: 39  sec: 13\n",
      "epoch: 1  batch: 513 / 721  loss: 0.02188736157959053  hr: 0  min: 39  sec: 10\n",
      "epoch: 1  batch: 514 / 721  loss: 0.021856885394505008  hr: 0  min: 39  sec: 7\n",
      "epoch: 1  batch: 515 / 721  loss: 0.021821963896656194  hr: 0  min: 39  sec: 5\n",
      "epoch: 1  batch: 516 / 721  loss: 0.021785375502584556  hr: 0  min: 39  sec: 2\n",
      "epoch: 1  batch: 517 / 721  loss: 0.021916065494044876  hr: 0  min: 38  sec: 59\n",
      "epoch: 1  batch: 518 / 721  loss: 0.021892749917642645  hr: 0  min: 38  sec: 56\n",
      "epoch: 1  batch: 519 / 721  loss: 0.0218534727117315  hr: 0  min: 38  sec: 52\n",
      "epoch: 1  batch: 520 / 721  loss: 0.021850646008645596  hr: 0  min: 38  sec: 50\n",
      "epoch: 1  batch: 521 / 721  loss: 0.02201018599079852  hr: 0  min: 38  sec: 48\n",
      "epoch: 1  batch: 522 / 721  loss: 0.022065699215515846  hr: 0  min: 38  sec: 44\n",
      "epoch: 1  batch: 523 / 721  loss: 0.022296131541273585  hr: 0  min: 38  sec: 42\n",
      "epoch: 1  batch: 524 / 721  loss: 0.022276879802738576  hr: 0  min: 38  sec: 40\n",
      "epoch: 1  batch: 525 / 721  loss: 0.022256184315164795  hr: 0  min: 38  sec: 36\n",
      "epoch: 1  batch: 526 / 721  loss: 0.0222885324415541  hr: 0  min: 38  sec: 34\n",
      "epoch: 1  batch: 527 / 721  loss: 0.02225422866343595  hr: 0  min: 38  sec: 31\n",
      "epoch: 1  batch: 528 / 721  loss: 0.022242947429483385  hr: 0  min: 38  sec: 29\n",
      "epoch: 1  batch: 529 / 721  loss: 0.022265441079229197  hr: 0  min: 38  sec: 26\n",
      "epoch: 1  batch: 530 / 721  loss: 0.022228084201430288  hr: 0  min: 38  sec: 22\n",
      "epoch: 1  batch: 531 / 721  loss: 0.02222081006756938  hr: 0  min: 38  sec: 19\n",
      "epoch: 1  batch: 532 / 721  loss: 0.022208708600100407  hr: 0  min: 38  sec: 16\n",
      "epoch: 1  batch: 533 / 721  loss: 0.02218321950115241  hr: 0  min: 38  sec: 13\n",
      "epoch: 1  batch: 534 / 721  loss: 0.022159421290582734  hr: 0  min: 38  sec: 10\n",
      "epoch: 1  batch: 535 / 721  loss: 0.022143139562158298  hr: 0  min: 38  sec: 7\n",
      "epoch: 1  batch: 536 / 721  loss: 0.02210324402463513  hr: 0  min: 38  sec: 5\n",
      "epoch: 1  batch: 537 / 721  loss: 0.02206435233613197  hr: 0  min: 38  sec: 2\n",
      "epoch: 1  batch: 538 / 721  loss: 0.022046638681299267  hr: 0  min: 37  sec: 59\n",
      "epoch: 1  batch: 539 / 721  loss: 0.02202417487836899  hr: 0  min: 37  sec: 56\n",
      "epoch: 1  batch: 540 / 721  loss: 0.02201651475414918  hr: 0  min: 37  sec: 53\n",
      "epoch: 1  batch: 541 / 721  loss: 0.02256082113951233  hr: 0  min: 37  sec: 50\n",
      "epoch: 1  batch: 542 / 721  loss: 0.022572103642991306  hr: 0  min: 37  sec: 48\n",
      "epoch: 1  batch: 543 / 721  loss: 0.02253552921795763  hr: 0  min: 37  sec: 45\n",
      "epoch: 1  batch: 544 / 721  loss: 0.022522395533676045  hr: 0  min: 37  sec: 42\n",
      "epoch: 1  batch: 545 / 721  loss: 0.022521688145373888  hr: 0  min: 37  sec: 40\n",
      "epoch: 1  batch: 546 / 721  loss: 0.022721779002731705  hr: 0  min: 37  sec: 37\n",
      "epoch: 1  batch: 547 / 721  loss: 0.022923772857140094  hr: 0  min: 37  sec: 35\n",
      "epoch: 1  batch: 548 / 721  loss: 0.022981527341790174  hr: 0  min: 37  sec: 32\n",
      "epoch: 1  batch: 549 / 721  loss: 0.023013968589448052  hr: 0  min: 37  sec: 29\n",
      "epoch: 1  batch: 550 / 721  loss: 0.022989481645689175  hr: 0  min: 37  sec: 27\n",
      "epoch: 1  batch: 551 / 721  loss: 0.022964173419616134  hr: 0  min: 37  sec: 23\n",
      "epoch: 1  batch: 552 / 721  loss: 0.02295009714288281  hr: 0  min: 37  sec: 21\n",
      "epoch: 1  batch: 553 / 721  loss: 0.022931596663855032  hr: 0  min: 37  sec: 19\n",
      "epoch: 1  batch: 554 / 721  loss: 0.022908247456373564  hr: 0  min: 37  sec: 16\n",
      "epoch: 1  batch: 555 / 721  loss: 0.022906767701581204  hr: 0  min: 37  sec: 14\n",
      "epoch: 1  batch: 556 / 721  loss: 0.022920889696644423  hr: 0  min: 37  sec: 11\n",
      "epoch: 1  batch: 557 / 721  loss: 0.023428170198185497  hr: 0  min: 37  sec: 8\n",
      "epoch: 1  batch: 558 / 721  loss: 0.02364016592375956  hr: 0  min: 37  sec: 6\n",
      "epoch: 1  batch: 559 / 721  loss: 0.02363124577465387  hr: 0  min: 37  sec: 3\n",
      "epoch: 1  batch: 560 / 721  loss: 0.023633086435698454  hr: 0  min: 37  sec: 1\n",
      "epoch: 1  batch: 561 / 721  loss: 0.023625211986564115  hr: 0  min: 36  sec: 58\n",
      "epoch: 1  batch: 562 / 721  loss: 0.02359394655937662  hr: 0  min: 36  sec: 55\n",
      "epoch: 1  batch: 563 / 721  loss: 0.023567318640532284  hr: 0  min: 36  sec: 52\n",
      "epoch: 1  batch: 564 / 721  loss: 0.02365210998671481  hr: 0  min: 36  sec: 49\n",
      "epoch: 1  batch: 565 / 721  loss: 0.023722630266596736  hr: 0  min: 36  sec: 46\n",
      "epoch: 1  batch: 566 / 721  loss: 0.023709993498935034  hr: 0  min: 36  sec: 44\n",
      "epoch: 1  batch: 567 / 721  loss: 0.023687940605473006  hr: 0  min: 36  sec: 42\n",
      "epoch: 1  batch: 568 / 721  loss: 0.023707761214916925  hr: 0  min: 36  sec: 39\n",
      "epoch: 1  batch: 569 / 721  loss: 0.023711604796653213  hr: 0  min: 36  sec: 36\n",
      "epoch: 1  batch: 570 / 721  loss: 0.02369998248601373  hr: 0  min: 36  sec: 35\n",
      "epoch: 1  batch: 571 / 721  loss: 0.023682926395378317  hr: 0  min: 36  sec: 32\n",
      "epoch: 1  batch: 572 / 721  loss: 0.02397665651430664  hr: 0  min: 36  sec: 29\n",
      "epoch: 1  batch: 573 / 721  loss: 0.02394411424675714  hr: 0  min: 36  sec: 26\n",
      "epoch: 1  batch: 574 / 721  loss: 0.023930146717127714  hr: 0  min: 36  sec: 23\n",
      "epoch: 1  batch: 575 / 721  loss: 0.023908315621286064  hr: 0  min: 36  sec: 20\n",
      "epoch: 1  batch: 576 / 721  loss: 0.024398487199960073  hr: 0  min: 36  sec: 18\n",
      "epoch: 1  batch: 577 / 721  loss: 0.024368981045981113  hr: 0  min: 36  sec: 15\n",
      "epoch: 1  batch: 578 / 721  loss: 0.024832920949218493  hr: 0  min: 36  sec: 12\n",
      "epoch: 1  batch: 579 / 721  loss: 0.024804909473547666  hr: 0  min: 36  sec: 9\n",
      "epoch: 1  batch: 580 / 721  loss: 0.02481252978809764  hr: 0  min: 36  sec: 7\n",
      "epoch: 1  batch: 581 / 721  loss: 0.024802662794113164  hr: 0  min: 36  sec: 4\n",
      "epoch: 1  batch: 582 / 721  loss: 0.024799840223603032  hr: 0  min: 36  sec: 2\n",
      "epoch: 1  batch: 583 / 721  loss: 0.0250505441301051  hr: 0  min: 35  sec: 58\n",
      "epoch: 1  batch: 584 / 721  loss: 0.0251325158500898  hr: 0  min: 35  sec: 56\n",
      "epoch: 1  batch: 585 / 721  loss: 0.025229704838184416  hr: 0  min: 35  sec: 53\n",
      "epoch: 1  batch: 586 / 721  loss: 0.025281129970341213  hr: 0  min: 35  sec: 52\n",
      "epoch: 1  batch: 587 / 721  loss: 0.025400544184799905  hr: 0  min: 35  sec: 50\n",
      "epoch: 1  batch: 588 / 721  loss: 0.025779426084852345  hr: 0  min: 35  sec: 47\n",
      "epoch: 1  batch: 589 / 721  loss: 0.025797951371649735  hr: 0  min: 35  sec: 44\n",
      "epoch: 1  batch: 590 / 721  loss: 0.02580582845163871  hr: 0  min: 35  sec: 42\n",
      "epoch: 1  batch: 591 / 721  loss: 0.0259424155376014  hr: 0  min: 35  sec: 39\n",
      "epoch: 1  batch: 592 / 721  loss: 0.026257478666298698  hr: 0  min: 35  sec: 36\n",
      "epoch: 1  batch: 593 / 721  loss: 0.026274564228042988  hr: 0  min: 35  sec: 34\n",
      "epoch: 1  batch: 594 / 721  loss: 0.026463094367757393  hr: 0  min: 35  sec: 31\n",
      "epoch: 1  batch: 595 / 721  loss: 0.026742606111968468  hr: 0  min: 35  sec: 28\n",
      "epoch: 1  batch: 596 / 721  loss: 0.026810260548620818  hr: 0  min: 35  sec: 26\n",
      "epoch: 1  batch: 597 / 721  loss: 0.02693699760456301  hr: 0  min: 35  sec: 23\n",
      "epoch: 1  batch: 598 / 721  loss: 0.027603487390372668  hr: 0  min: 35  sec: 20\n",
      "epoch: 1  batch: 599 / 721  loss: 0.02781610184304225  hr: 0  min: 35  sec: 17\n",
      "epoch: 1  batch: 600 / 721  loss: 0.027802858659658036  hr: 0  min: 35  sec: 14\n",
      "epoch: 1  batch: 601 / 721  loss: 0.027838450907305357  hr: 0  min: 35  sec: 12\n",
      "epoch: 1  batch: 602 / 721  loss: 0.027870318121820198  hr: 0  min: 35  sec: 10\n",
      "epoch: 1  batch: 603 / 721  loss: 0.027979449879898956  hr: 0  min: 35  sec: 9\n",
      "epoch: 1  batch: 604 / 721  loss: 0.028343505426188575  hr: 0  min: 35  sec: 6\n",
      "epoch: 1  batch: 605 / 721  loss: 0.02840094945305951  hr: 0  min: 35  sec: 3\n",
      "epoch: 1  batch: 606 / 721  loss: 0.02843373422800039  hr: 0  min: 35  sec: 1\n",
      "epoch: 1  batch: 607 / 721  loss: 0.028488721627608952  hr: 0  min: 34  sec: 59\n",
      "epoch: 1  batch: 608 / 721  loss: 0.028538838785272292  hr: 0  min: 34  sec: 57\n",
      "epoch: 1  batch: 609 / 721  loss: 0.029085652749461302  hr: 0  min: 34  sec: 54\n",
      "epoch: 1  batch: 610 / 721  loss: 0.029307293986231775  hr: 0  min: 34  sec: 51\n",
      "epoch: 1  batch: 611 / 721  loss: 0.029550276827434864  hr: 0  min: 34  sec: 48\n",
      "epoch: 1  batch: 612 / 721  loss: 0.0297354328734941  hr: 0  min: 34  sec: 46\n",
      "epoch: 1  batch: 613 / 721  loss: 0.030294965371935056  hr: 0  min: 34  sec: 43\n",
      "epoch: 1  batch: 614 / 721  loss: 0.0305175541681393  hr: 0  min: 34  sec: 41\n",
      "epoch: 1  batch: 615 / 721  loss: 0.031084787188054297  hr: 0  min: 34  sec: 38\n",
      "epoch: 1  batch: 616 / 721  loss: 0.03154868978139371  hr: 0  min: 34  sec: 35\n",
      "epoch: 1  batch: 617 / 721  loss: 0.03157368451746511  hr: 0  min: 34  sec: 32\n",
      "epoch: 1  batch: 618 / 721  loss: 0.03171988022947891  hr: 0  min: 34  sec: 29\n",
      "epoch: 1  batch: 619 / 721  loss: 0.03180835904860651  hr: 0  min: 34  sec: 26\n",
      "epoch: 1  batch: 620 / 721  loss: 0.03194389088166645  hr: 0  min: 34  sec: 24\n",
      "epoch: 1  batch: 621 / 721  loss: 0.03207607856122499  hr: 0  min: 34  sec: 21\n",
      "epoch: 1  batch: 622 / 721  loss: 0.032228949329700884  hr: 0  min: 34  sec: 18\n",
      "epoch: 1  batch: 623 / 721  loss: 0.03235880124916541  hr: 0  min: 34  sec: 15\n",
      "epoch: 1  batch: 624 / 721  loss: 0.0324132169969697  hr: 0  min: 34  sec: 13\n",
      "epoch: 1  batch: 625 / 721  loss: 0.03244750063684769  hr: 0  min: 34  sec: 10\n",
      "epoch: 1  batch: 626 / 721  loss: 0.03248360942564377  hr: 0  min: 34  sec: 7\n",
      "epoch: 1  batch: 627 / 721  loss: 0.03273910554048852  hr: 0  min: 34  sec: 5\n",
      "epoch: 1  batch: 628 / 721  loss: 0.03279351767203155  hr: 0  min: 34  sec: 2\n",
      "epoch: 1  batch: 629 / 721  loss: 0.03282167261140828  hr: 0  min: 33  sec: 59\n",
      "epoch: 1  batch: 630 / 721  loss: 0.03295793486874558  hr: 0  min: 33  sec: 57\n",
      "epoch: 1  batch: 631 / 721  loss: 0.033167462822217005  hr: 0  min: 33  sec: 54\n",
      "epoch: 1  batch: 632 / 721  loss: 0.03319154651154936  hr: 0  min: 33  sec: 51\n",
      "epoch: 1  batch: 633 / 721  loss: 0.03321332175776217  hr: 0  min: 33  sec: 49\n",
      "epoch: 1  batch: 634 / 721  loss: 0.03320402645823444  hr: 0  min: 33  sec: 47\n",
      "epoch: 1  batch: 635 / 721  loss: 0.03319512212572905  hr: 0  min: 33  sec: 44\n",
      "epoch: 1  batch: 636 / 721  loss: 0.03322933847345478  hr: 0  min: 33  sec: 41\n",
      "epoch: 1  batch: 637 / 721  loss: 0.0332435844302067  hr: 0  min: 33  sec: 39\n",
      "epoch: 1  batch: 638 / 721  loss: 0.03329547877073307  hr: 0  min: 33  sec: 36\n",
      "epoch: 1  batch: 639 / 721  loss: 0.033266948841788026  hr: 0  min: 33  sec: 35\n",
      "epoch: 1  batch: 640 / 721  loss: 0.033311197877310406  hr: 0  min: 33  sec: 33\n",
      "epoch: 1  batch: 641 / 721  loss: 0.03343121669631685  hr: 0  min: 33  sec: 30\n",
      "epoch: 1  batch: 642 / 721  loss: 0.03355254720853144  hr: 0  min: 33  sec: 28\n",
      "epoch: 1  batch: 643 / 721  loss: 0.03354875194413036  hr: 0  min: 33  sec: 25\n",
      "epoch: 1  batch: 644 / 721  loss: 0.03365271150027669  hr: 0  min: 33  sec: 23\n",
      "epoch: 1  batch: 645 / 721  loss: 0.033648264298058485  hr: 0  min: 33  sec: 20\n",
      "epoch: 1  batch: 646 / 721  loss: 0.033614742716360946  hr: 0  min: 33  sec: 18\n",
      "epoch: 1  batch: 647 / 721  loss: 0.03360191237443585  hr: 0  min: 33  sec: 15\n",
      "epoch: 1  batch: 648 / 721  loss: 0.033603891856470045  hr: 0  min: 33  sec: 13\n",
      "epoch: 1  batch: 649 / 721  loss: 0.033720106046866746  hr: 0  min: 33  sec: 9\n",
      "epoch: 1  batch: 650 / 721  loss: 0.033769353249584896  hr: 0  min: 33  sec: 7\n",
      "epoch: 1  batch: 651 / 721  loss: 0.03378310210731191  hr: 0  min: 33  sec: 4\n",
      "epoch: 1  batch: 652 / 721  loss: 0.03381853340950865  hr: 0  min: 33  sec: 3\n",
      "epoch: 1  batch: 653 / 721  loss: 0.03397958248160718  hr: 0  min: 33  sec: 0\n",
      "epoch: 1  batch: 654 / 721  loss: 0.03396151814327984  hr: 0  min: 32  sec: 57\n",
      "epoch: 1  batch: 655 / 721  loss: 0.03398336364593506  hr: 0  min: 32  sec: 55\n",
      "epoch: 1  batch: 656 / 721  loss: 0.0340052876624058  hr: 0  min: 32  sec: 52\n",
      "epoch: 1  batch: 657 / 721  loss: 0.03415269472944065  hr: 0  min: 32  sec: 49\n",
      "epoch: 1  batch: 658 / 721  loss: 0.034136709080286126  hr: 0  min: 32  sec: 47\n",
      "epoch: 1  batch: 659 / 721  loss: 0.03425246519493243  hr: 0  min: 32  sec: 44\n",
      "epoch: 1  batch: 660 / 721  loss: 0.03427981906962955  hr: 0  min: 32  sec: 41\n",
      "epoch: 1  batch: 661 / 721  loss: 0.03425547357127472  hr: 0  min: 32  sec: 39\n",
      "epoch: 1  batch: 662 / 721  loss: 0.03429742453425871  hr: 0  min: 32  sec: 36\n",
      "epoch: 1  batch: 663 / 721  loss: 0.03435218369004072  hr: 0  min: 32  sec: 33\n",
      "epoch: 1  batch: 664 / 721  loss: 0.034335089319763236  hr: 0  min: 32  sec: 31\n",
      "epoch: 1  batch: 665 / 721  loss: 0.034401521063978695  hr: 0  min: 32  sec: 28\n",
      "epoch: 1  batch: 666 / 721  loss: 0.03436677166378418  hr: 0  min: 32  sec: 26\n",
      "epoch: 1  batch: 667 / 721  loss: 0.03435610566883225  hr: 0  min: 32  sec: 23\n",
      "epoch: 1  batch: 668 / 721  loss: 0.03439295104908524  hr: 0  min: 32  sec: 21\n",
      "epoch: 1  batch: 669 / 721  loss: 0.034430373725643164  hr: 0  min: 32  sec: 18\n",
      "epoch: 1  batch: 670 / 721  loss: 0.03441488597261434  hr: 0  min: 32  sec: 15\n",
      "epoch: 1  batch: 671 / 721  loss: 0.03450540388902565  hr: 0  min: 32  sec: 12\n",
      "epoch: 1  batch: 672 / 721  loss: 0.03455145337860207  hr: 0  min: 32  sec: 10\n",
      "epoch: 1  batch: 673 / 721  loss: 0.0345109551027988  hr: 0  min: 32  sec: 8\n",
      "epoch: 1  batch: 674 / 721  loss: 0.03451069665956829  hr: 0  min: 32  sec: 5\n",
      "epoch: 1  batch: 675 / 721  loss: 0.03455797078885586  hr: 0  min: 32  sec: 2\n",
      "epoch: 1  batch: 676 / 721  loss: 0.034575737829944574  hr: 0  min: 32  sec: 0\n",
      "epoch: 1  batch: 677 / 721  loss: 0.03461802903150258  hr: 0  min: 31  sec: 58\n",
      "epoch: 1  batch: 678 / 721  loss: 0.03458979469556588  hr: 0  min: 31  sec: 55\n",
      "epoch: 1  batch: 679 / 721  loss: 0.03458224081737606  hr: 0  min: 31  sec: 53\n",
      "epoch: 1  batch: 680 / 721  loss: 0.03458911463218529  hr: 0  min: 31  sec: 50\n",
      "epoch: 1  batch: 681 / 721  loss: 0.034688444762012376  hr: 0  min: 31  sec: 47\n",
      "epoch: 1  batch: 682 / 721  loss: 0.034825526658949835  hr: 0  min: 31  sec: 45\n",
      "epoch: 1  batch: 683 / 721  loss: 0.0348241916407424  hr: 0  min: 31  sec: 42\n",
      "epoch: 1  batch: 684 / 721  loss: 0.03480219507181632  hr: 0  min: 31  sec: 39\n",
      "epoch: 1  batch: 685 / 721  loss: 0.03481226480828537  hr: 0  min: 31  sec: 38\n",
      "epoch: 1  batch: 686 / 721  loss: 0.03477083663725119  hr: 0  min: 31  sec: 37\n",
      "epoch: 1  batch: 687 / 721  loss: 0.03476591449095515  hr: 0  min: 31  sec: 34\n",
      "epoch: 1  batch: 688 / 721  loss: 0.034727006513453805  hr: 0  min: 31  sec: 32\n",
      "epoch: 1  batch: 689 / 721  loss: 0.034730822747177544  hr: 0  min: 31  sec: 29\n",
      "epoch: 1  batch: 690 / 721  loss: 0.03484600848434797  hr: 0  min: 31  sec: 27\n",
      "epoch: 1  batch: 691 / 721  loss: 0.034822597389802534  hr: 0  min: 31  sec: 24\n",
      "epoch: 1  batch: 692 / 721  loss: 0.03479419890263776  hr: 0  min: 31  sec: 22\n",
      "epoch: 1  batch: 693 / 721  loss: 0.03486883118222024  hr: 0  min: 31  sec: 19\n",
      "epoch: 1  batch: 694 / 721  loss: 0.03493175586261646  hr: 0  min: 31  sec: 16\n",
      "epoch: 1  batch: 695 / 721  loss: 0.03500261991154972  hr: 0  min: 31  sec: 13\n",
      "epoch: 1  batch: 696 / 721  loss: 0.03496028710898158  hr: 0  min: 31  sec: 11\n",
      "epoch: 1  batch: 697 / 721  loss: 0.035202177056758446  hr: 0  min: 31  sec: 9\n",
      "epoch: 1  batch: 698 / 721  loss: 0.035166686883486106  hr: 0  min: 31  sec: 6\n",
      "epoch: 1  batch: 699 / 721  loss: 0.03518014926386255  hr: 0  min: 31  sec: 3\n",
      "epoch: 1  batch: 700 / 721  loss: 0.035241396104891985  hr: 0  min: 31  sec: 0\n",
      "epoch: 1  batch: 701 / 721  loss: 0.03520249066375011  hr: 0  min: 30  sec: 57\n",
      "epoch: 1  batch: 702 / 721  loss: 0.03516399743075402  hr: 0  min: 30  sec: 55\n",
      "epoch: 1  batch: 703 / 721  loss: 0.035161317353659134  hr: 0  min: 30  sec: 53\n",
      "epoch: 1  batch: 704 / 721  loss: 0.035139380916875365  hr: 0  min: 30  sec: 51\n",
      "epoch: 1  batch: 705 / 721  loss: 0.035130166594997535  hr: 0  min: 30  sec: 48\n",
      "epoch: 1  batch: 706 / 721  loss: 0.03510970184577018  hr: 0  min: 30  sec: 45\n",
      "epoch: 1  batch: 707 / 721  loss: 0.035076654367018796  hr: 0  min: 30  sec: 43\n",
      "epoch: 1  batch: 708 / 721  loss: 0.035063410645831274  hr: 0  min: 30  sec: 41\n",
      "epoch: 1  batch: 709 / 721  loss: 0.03508640402749513  hr: 0  min: 30  sec: 38\n",
      "epoch: 1  batch: 710 / 721  loss: 0.03504478147382107  hr: 0  min: 30  sec: 35\n",
      "epoch: 1  batch: 711 / 721  loss: 0.0350615973299865  hr: 0  min: 30  sec: 33\n",
      "epoch: 1  batch: 712 / 721  loss: 0.03504380978107762  hr: 0  min: 30  sec: 30\n",
      "epoch: 1  batch: 713 / 721  loss: 0.035215424254595735  hr: 0  min: 30  sec: 27\n",
      "epoch: 1  batch: 714 / 721  loss: 0.03539805851863855  hr: 0  min: 30  sec: 24\n",
      "epoch: 1  batch: 715 / 721  loss: 0.035356496534696163  hr: 0  min: 30  sec: 22\n",
      "epoch: 1  batch: 716 / 721  loss: 0.035359708758504534  hr: 0  min: 30  sec: 19\n",
      "epoch: 1  batch: 717 / 721  loss: 0.03533222929986468  hr: 0  min: 30  sec: 17\n",
      "epoch: 1  batch: 718 / 721  loss: 0.03532093509868427  hr: 0  min: 30  sec: 14\n",
      "epoch: 1  batch: 719 / 721  loss: 0.03529864524997756  hr: 0  min: 30  sec: 12\n",
      "epoch: 1  batch: 720 / 721  loss: 0.03542947639010284  hr: 0  min: 30  sec: 9\n",
      "epoch: 1  batch: 721 / 721  loss: 0.035390179312083  hr: 0  min: 30  sec: 6\n",
      "epoch: 2  batch: 1 / 721  loss: 0.009479590691626072  hr: 0  min: 26  sec: 11\n",
      "epoch: 2  batch: 2 / 721  loss: 0.02603165665641427  hr: 0  min: 23  sec: 36\n",
      "epoch: 2  batch: 3 / 721  loss: 0.02004331722855568  hr: 0  min: 26  sec: 36\n",
      "epoch: 2  batch: 4 / 721  loss: 0.016457918216474354  hr: 0  min: 27  sec: 29\n",
      "epoch: 2  batch: 5 / 721  loss: 0.01972129875794053  hr: 0  min: 27  sec: 42\n",
      "epoch: 2  batch: 6 / 721  loss: 0.017625162610784173  hr: 0  min: 28  sec: 5\n",
      "epoch: 2  batch: 7 / 721  loss: 0.015778549747275456  hr: 0  min: 28  sec: 35\n",
      "epoch: 2  batch: 8 / 721  loss: 0.017613174335565418  hr: 0  min: 28  sec: 10\n",
      "epoch: 2  batch: 9 / 721  loss: 0.01815983627198471  hr: 0  min: 29  sec: 4\n",
      "epoch: 2  batch: 10 / 721  loss: 0.0169828409794718  hr: 0  min: 29  sec: 2\n",
      "epoch: 2  batch: 11 / 721  loss: 0.017642808612436056  hr: 0  min: 29  sec: 25\n",
      "epoch: 2  batch: 12 / 721  loss: 0.01828453957568854  hr: 0  min: 29  sec: 11\n",
      "epoch: 2  batch: 13 / 721  loss: 0.019456774175453644  hr: 0  min: 29  sec: 4\n",
      "epoch: 2  batch: 14 / 721  loss: 0.021437913345705186  hr: 0  min: 29  sec: 25\n",
      "epoch: 2  batch: 15 / 721  loss: 0.020619672381629546  hr: 0  min: 29  sec: 18\n",
      "epoch: 2  batch: 16 / 721  loss: 0.019510577258188277  hr: 0  min: 29  sec: 17\n",
      "epoch: 2  batch: 17 / 721  loss: 0.02330435883692082  hr: 0  min: 29  sec: 6\n",
      "epoch: 2  batch: 18 / 721  loss: 0.02231029459896187  hr: 0  min: 29  sec: 18\n",
      "epoch: 2  batch: 19 / 721  loss: 0.022201839613875275  hr: 0  min: 28  sec: 53\n",
      "epoch: 2  batch: 20 / 721  loss: 0.021294856956228615  hr: 0  min: 28  sec: 43\n",
      "epoch: 2  batch: 21 / 721  loss: 0.020485315338841507  hr: 0  min: 28  sec: 45\n",
      "epoch: 2  batch: 22 / 721  loss: 0.020049054048616777  hr: 0  min: 28  sec: 47\n",
      "epoch: 2  batch: 23 / 721  loss: 0.021022062789162865  hr: 0  min: 28  sec: 38\n",
      "epoch: 2  batch: 24 / 721  loss: 0.02036185492761433  hr: 0  min: 28  sec: 37\n",
      "epoch: 2  batch: 25 / 721  loss: 0.020228469520807268  hr: 0  min: 28  sec: 26\n",
      "epoch: 2  batch: 26 / 721  loss: 0.022253840158765133  hr: 0  min: 28  sec: 22\n",
      "epoch: 2  batch: 27 / 721  loss: 0.02156058200462549  hr: 0  min: 28  sec: 18\n",
      "epoch: 2  batch: 28 / 721  loss: 0.020893242933587835  hr: 0  min: 28  sec: 21\n",
      "epoch: 2  batch: 29 / 721  loss: 0.020268015892662365  hr: 0  min: 28  sec: 11\n",
      "epoch: 2  batch: 30 / 721  loss: 0.019927100379330417  hr: 0  min: 28  sec: 7\n",
      "epoch: 2  batch: 31 / 721  loss: 0.019832711644290436  hr: 0  min: 28  sec: 11\n",
      "epoch: 2  batch: 32 / 721  loss: 0.019367340333701577  hr: 0  min: 28  sec: 10\n",
      "epoch: 2  batch: 33 / 721  loss: 0.01883397116255241  hr: 0  min: 28  sec: 18\n",
      "epoch: 2  batch: 34 / 721  loss: 0.018413120569140816  hr: 0  min: 28  sec: 13\n",
      "epoch: 2  batch: 35 / 721  loss: 0.01817630214417087  hr: 0  min: 28  sec: 7\n",
      "epoch: 2  batch: 36 / 721  loss: 0.02388147082658381  hr: 0  min: 28  sec: 3\n",
      "epoch: 2  batch: 37 / 721  loss: 0.0232874866184854  hr: 0  min: 28  sec: 23\n",
      "epoch: 2  batch: 38 / 721  loss: 0.02298392588885403  hr: 0  min: 28  sec: 20\n",
      "epoch: 2  batch: 39 / 721  loss: 0.023109561626393445  hr: 0  min: 28  sec: 16\n",
      "epoch: 2  batch: 40 / 721  loss: 0.022558128577657044  hr: 0  min: 28  sec: 20\n",
      "epoch: 2  batch: 41 / 721  loss: 0.022881380055190588  hr: 0  min: 28  sec: 14\n",
      "epoch: 2  batch: 42 / 721  loss: 0.022424127147089513  hr: 0  min: 28  sec: 10\n",
      "epoch: 2  batch: 43 / 721  loss: 0.02202653071063376  hr: 0  min: 28  sec: 2\n",
      "epoch: 2  batch: 44 / 721  loss: 0.021559281922898  hr: 0  min: 28  sec: 1\n",
      "epoch: 2  batch: 45 / 721  loss: 0.021161207807664242  hr: 0  min: 27  sec: 56\n",
      "epoch: 2  batch: 46 / 721  loss: 0.023337200043581263  hr: 0  min: 27  sec: 48\n",
      "epoch: 2  batch: 47 / 721  loss: 0.02315511986702443  hr: 0  min: 27  sec: 42\n",
      "epoch: 2  batch: 48 / 721  loss: 0.02678191790134103  hr: 0  min: 27  sec: 45\n",
      "epoch: 2  batch: 49 / 721  loss: 0.026294052736282502  hr: 0  min: 27  sec: 42\n",
      "epoch: 2  batch: 50 / 721  loss: 0.025830643533263354  hr: 0  min: 27  sec: 35\n",
      "epoch: 2  batch: 51 / 721  loss: 0.025454787795395388  hr: 0  min: 27  sec: 37\n",
      "epoch: 2  batch: 52 / 721  loss: 0.025214324241880186  hr: 0  min: 27  sec: 38\n",
      "epoch: 2  batch: 53 / 721  loss: 0.024819255940493126  hr: 0  min: 27  sec: 37\n",
      "epoch: 2  batch: 54 / 721  loss: 0.02446111002980076  hr: 0  min: 27  sec: 38\n",
      "epoch: 2  batch: 55 / 721  loss: 0.024076724706471642  hr: 0  min: 27  sec: 46\n",
      "epoch: 2  batch: 56 / 721  loss: 0.023786860977582234  hr: 0  min: 27  sec: 43\n",
      "epoch: 2  batch: 57 / 721  loss: 0.02372774428875888  hr: 0  min: 27  sec: 39\n",
      "epoch: 2  batch: 58 / 721  loss: 0.023765309707759398  hr: 0  min: 27  sec: 35\n",
      "epoch: 2  batch: 59 / 721  loss: 0.023399376340005232  hr: 0  min: 27  sec: 33\n",
      "epoch: 2  batch: 60 / 721  loss: 0.023191427282290532  hr: 0  min: 27  sec: 26\n",
      "epoch: 2  batch: 61 / 721  loss: 0.022914986101315035  hr: 0  min: 27  sec: 22\n",
      "epoch: 2  batch: 62 / 721  loss: 0.022583186211470034  hr: 0  min: 27  sec: 19\n",
      "epoch: 2  batch: 63 / 721  loss: 0.02224654302422312  hr: 0  min: 27  sec: 15\n",
      "epoch: 2  batch: 64 / 721  loss: 0.021956183705697185  hr: 0  min: 27  sec: 12\n",
      "epoch: 2  batch: 65 / 721  loss: 0.02171205144483023  hr: 0  min: 27  sec: 9\n",
      "epoch: 2  batch: 66 / 721  loss: 0.021414981761622723  hr: 0  min: 27  sec: 8\n",
      "epoch: 2  batch: 67 / 721  loss: 0.021185667909084084  hr: 0  min: 27  sec: 10\n",
      "epoch: 2  batch: 68 / 721  loss: 0.02149000936632921  hr: 0  min: 27  sec: 7\n",
      "epoch: 2  batch: 69 / 721  loss: 0.021280112637517352  hr: 0  min: 27  sec: 4\n",
      "epoch: 2  batch: 70 / 721  loss: 0.021129298145284078  hr: 0  min: 27  sec: 0\n",
      "epoch: 2  batch: 71 / 721  loss: 0.02088649331060776  hr: 0  min: 26  sec: 56\n",
      "epoch: 2  batch: 72 / 721  loss: 0.02062595550442994  hr: 0  min: 26  sec: 52\n",
      "epoch: 2  batch: 73 / 721  loss: 0.021778459292326174  hr: 0  min: 26  sec: 47\n",
      "epoch: 2  batch: 74 / 721  loss: 0.021503834635950625  hr: 0  min: 26  sec: 47\n",
      "epoch: 2  batch: 75 / 721  loss: 0.02159427779726684  hr: 0  min: 26  sec: 44\n",
      "epoch: 2  batch: 76 / 721  loss: 0.0213223973834446  hr: 0  min: 26  sec: 41\n",
      "epoch: 2  batch: 77 / 721  loss: 0.02117569873097365  hr: 0  min: 26  sec: 35\n",
      "epoch: 2  batch: 78 / 721  loss: 0.020913754968205467  hr: 0  min: 26  sec: 31\n",
      "epoch: 2  batch: 79 / 721  loss: 0.02097042956127184  hr: 0  min: 26  sec: 28\n",
      "epoch: 2  batch: 80 / 721  loss: 0.02078466059974744  hr: 0  min: 26  sec: 24\n",
      "epoch: 2  batch: 81 / 721  loss: 0.020560322725357787  hr: 0  min: 26  sec: 19\n",
      "epoch: 2  batch: 82 / 721  loss: 0.020453710148037162  hr: 0  min: 26  sec: 18\n",
      "epoch: 2  batch: 83 / 721  loss: 0.020999585058826237  hr: 0  min: 26  sec: 13\n",
      "epoch: 2  batch: 84 / 721  loss: 0.021503312462647  hr: 0  min: 26  sec: 9\n",
      "epoch: 2  batch: 85 / 721  loss: 0.021873680627493956  hr: 0  min: 26  sec: 8\n",
      "epoch: 2  batch: 86 / 721  loss: 0.021628780350045756  hr: 0  min: 26  sec: 5\n",
      "epoch: 2  batch: 87 / 721  loss: 0.021640129617533123  hr: 0  min: 26  sec: 2\n",
      "epoch: 2  batch: 88 / 721  loss: 0.021430656456769528  hr: 0  min: 26  sec: 0\n",
      "epoch: 2  batch: 89 / 721  loss: 0.02125634943668762  hr: 0  min: 25  sec: 55\n",
      "epoch: 2  batch: 90 / 721  loss: 0.02135184384468529  hr: 0  min: 25  sec: 55\n",
      "epoch: 2  batch: 91 / 721  loss: 0.021269137725479656  hr: 0  min: 25  sec: 51\n",
      "epoch: 2  batch: 92 / 721  loss: 0.02104747139800684  hr: 0  min: 25  sec: 58\n",
      "epoch: 2  batch: 93 / 721  loss: 0.021035381025128988  hr: 0  min: 25  sec: 55\n",
      "epoch: 2  batch: 94 / 721  loss: 0.020837086352564274  hr: 0  min: 25  sec: 52\n",
      "epoch: 2  batch: 95 / 721  loss: 0.02064068031460537  hr: 0  min: 25  sec: 48\n",
      "epoch: 2  batch: 96 / 721  loss: 0.020478046191783505  hr: 0  min: 25  sec: 44\n",
      "epoch: 2  batch: 97 / 721  loss: 0.020752264055322624  hr: 0  min: 25  sec: 43\n",
      "epoch: 2  batch: 98 / 721  loss: 0.02119653406184718  hr: 0  min: 25  sec: 40\n",
      "epoch: 2  batch: 99 / 721  loss: 0.020992835090528572  hr: 0  min: 25  sec: 37\n",
      "epoch: 2  batch: 100 / 721  loss: 0.02144595379999373  hr: 0  min: 25  sec: 36\n",
      "epoch: 2  batch: 101 / 721  loss: 0.021296882582943665  hr: 0  min: 25  sec: 34\n",
      "epoch: 2  batch: 102 / 721  loss: 0.021228233174827204  hr: 0  min: 25  sec: 29\n",
      "epoch: 2  batch: 103 / 721  loss: 0.022599564382051417  hr: 0  min: 25  sec: 26\n",
      "epoch: 2  batch: 104 / 721  loss: 0.022409240297117952  hr: 0  min: 25  sec: 23\n",
      "epoch: 2  batch: 105 / 721  loss: 0.022238091666007504  hr: 0  min: 25  sec: 19\n",
      "epoch: 2  batch: 106 / 721  loss: 0.02204792037494217  hr: 0  min: 25  sec: 15\n",
      "epoch: 2  batch: 107 / 721  loss: 0.02185130484508803  hr: 0  min: 25  sec: 21\n",
      "epoch: 2  batch: 108 / 721  loss: 0.02171661882473725  hr: 0  min: 25  sec: 18\n",
      "epoch: 2  batch: 109 / 721  loss: 0.021540598038673708  hr: 0  min: 25  sec: 16\n",
      "epoch: 2  batch: 110 / 721  loss: 0.021404695261629636  hr: 0  min: 25  sec: 12\n",
      "epoch: 2  batch: 111 / 721  loss: 0.02130770504208248  hr: 0  min: 25  sec: 9\n",
      "epoch: 2  batch: 112 / 721  loss: 0.021127754085942536  hr: 0  min: 25  sec: 6\n",
      "epoch: 2  batch: 113 / 721  loss: 0.021132529403631105  hr: 0  min: 25  sec: 2\n",
      "epoch: 2  batch: 114 / 721  loss: 0.021456789122710592  hr: 0  min: 24  sec: 59\n",
      "epoch: 2  batch: 115 / 721  loss: 0.021313227672109622  hr: 0  min: 24  sec: 55\n",
      "epoch: 2  batch: 116 / 721  loss: 0.021534920276186816  hr: 0  min: 24  sec: 52\n",
      "epoch: 2  batch: 117 / 721  loss: 0.021614034611902908  hr: 0  min: 24  sec: 47\n",
      "epoch: 2  batch: 118 / 721  loss: 0.021455327413435553  hr: 0  min: 24  sec: 46\n",
      "epoch: 2  batch: 119 / 721  loss: 0.02133044012491552  hr: 0  min: 24  sec: 43\n",
      "epoch: 2  batch: 120 / 721  loss: 0.021216636920871678  hr: 0  min: 24  sec: 39\n",
      "epoch: 2  batch: 121 / 721  loss: 0.021116408413133683  hr: 0  min: 24  sec: 40\n",
      "epoch: 2  batch: 122 / 721  loss: 0.02096091384654025  hr: 0  min: 24  sec: 37\n",
      "epoch: 2  batch: 123 / 721  loss: 0.02125574233212955  hr: 0  min: 24  sec: 34\n",
      "epoch: 2  batch: 124 / 721  loss: 0.021143441919834475  hr: 0  min: 24  sec: 30\n",
      "epoch: 2  batch: 125 / 721  loss: 0.02103091556718573  hr: 0  min: 24  sec: 27\n",
      "epoch: 2  batch: 126 / 721  loss: 0.020871291757054954  hr: 0  min: 24  sec: 27\n",
      "epoch: 2  batch: 127 / 721  loss: 0.02105551839972971  hr: 0  min: 24  sec: 24\n",
      "epoch: 2  batch: 128 / 721  loss: 0.021069918125704135  hr: 0  min: 24  sec: 21\n",
      "epoch: 2  batch: 129 / 721  loss: 0.020917253631488383  hr: 0  min: 24  sec: 17\n",
      "epoch: 2  batch: 130 / 721  loss: 0.020814533651215383  hr: 0  min: 24  sec: 14\n",
      "epoch: 2  batch: 131 / 721  loss: 0.02082283852243341  hr: 0  min: 24  sec: 9\n",
      "epoch: 2  batch: 132 / 721  loss: 0.020741973182973168  hr: 0  min: 24  sec: 6\n",
      "epoch: 2  batch: 133 / 721  loss: 0.02059064323915855  hr: 0  min: 24  sec: 8\n",
      "epoch: 2  batch: 134 / 721  loss: 0.0209309026171495  hr: 0  min: 24  sec: 4\n",
      "epoch: 2  batch: 135 / 721  loss: 0.021435896998823242  hr: 0  min: 24  sec: 1\n",
      "epoch: 2  batch: 136 / 721  loss: 0.02134959342348499  hr: 0  min: 23  sec: 59\n",
      "epoch: 2  batch: 137 / 721  loss: 0.02160214494240817  hr: 0  min: 23  sec: 56\n",
      "epoch: 2  batch: 138 / 721  loss: 0.021461754968133417  hr: 0  min: 23  sec: 54\n",
      "epoch: 2  batch: 139 / 721  loss: 0.021435304683894454  hr: 0  min: 23  sec: 51\n",
      "epoch: 2  batch: 140 / 721  loss: 0.021338068938348442  hr: 0  min: 23  sec: 47\n",
      "epoch: 2  batch: 141 / 721  loss: 0.021192517395359167  hr: 0  min: 23  sec: 44\n",
      "epoch: 2  batch: 142 / 721  loss: 0.021076211275805026  hr: 0  min: 23  sec: 40\n",
      "epoch: 2  batch: 143 / 721  loss: 0.020994859235931085  hr: 0  min: 23  sec: 38\n",
      "epoch: 2  batch: 144 / 721  loss: 0.02091174775422486  hr: 0  min: 23  sec: 35\n",
      "epoch: 2  batch: 145 / 721  loss: 0.02080983544563361  hr: 0  min: 23  sec: 32\n",
      "epoch: 2  batch: 146 / 721  loss: 0.020750708877641633  hr: 0  min: 23  sec: 30\n",
      "epoch: 2  batch: 147 / 721  loss: 0.021141027511797566  hr: 0  min: 23  sec: 27\n",
      "epoch: 2  batch: 148 / 721  loss: 0.02100945075988027  hr: 0  min: 23  sec: 24\n",
      "epoch: 2  batch: 149 / 721  loss: 0.020879427048037042  hr: 0  min: 23  sec: 22\n",
      "epoch: 2  batch: 150 / 721  loss: 0.021006268004033095  hr: 0  min: 23  sec: 19\n",
      "epoch: 2  batch: 151 / 721  loss: 0.02089150526926279  hr: 0  min: 23  sec: 16\n",
      "epoch: 2  batch: 152 / 721  loss: 0.020930833471586658  hr: 0  min: 23  sec: 13\n",
      "epoch: 2  batch: 153 / 721  loss: 0.02090311250717872  hr: 0  min: 23  sec: 10\n",
      "epoch: 2  batch: 154 / 721  loss: 0.02077631238135872  hr: 0  min: 23  sec: 9\n",
      "epoch: 2  batch: 155 / 721  loss: 0.020709279882946924  hr: 0  min: 23  sec: 6\n",
      "epoch: 2  batch: 156 / 721  loss: 0.02066680058301128  hr: 0  min: 23  sec: 3\n",
      "epoch: 2  batch: 157 / 721  loss: 0.020592163661331722  hr: 0  min: 22  sec: 59\n",
      "epoch: 2  batch: 158 / 721  loss: 0.020478762446422296  hr: 0  min: 22  sec: 56\n",
      "epoch: 2  batch: 159 / 721  loss: 0.020363492215031746  hr: 0  min: 22  sec: 53\n",
      "epoch: 2  batch: 160 / 721  loss: 0.020247313016079717  hr: 0  min: 22  sec: 51\n",
      "epoch: 2  batch: 161 / 721  loss: 0.020186318700297256  hr: 0  min: 22  sec: 48\n",
      "epoch: 2  batch: 162 / 721  loss: 0.020104608498154392  hr: 0  min: 22  sec: 44\n",
      "epoch: 2  batch: 163 / 721  loss: 0.01998363166209739  hr: 0  min: 22  sec: 43\n",
      "epoch: 2  batch: 164 / 721  loss: 0.01989632419920271  hr: 0  min: 22  sec: 39\n",
      "epoch: 2  batch: 165 / 721  loss: 0.019901184645079246  hr: 0  min: 22  sec: 36\n",
      "epoch: 2  batch: 166 / 721  loss: 0.019793676285890873  hr: 0  min: 22  sec: 33\n",
      "epoch: 2  batch: 167 / 721  loss: 0.0196786560011891  hr: 0  min: 22  sec: 31\n",
      "epoch: 2  batch: 168 / 721  loss: 0.019579172198670374  hr: 0  min: 22  sec: 29\n",
      "epoch: 2  batch: 169 / 721  loss: 0.019492343041085578  hr: 0  min: 22  sec: 24\n",
      "epoch: 2  batch: 170 / 721  loss: 0.019521915294086176  hr: 0  min: 22  sec: 22\n",
      "epoch: 2  batch: 171 / 721  loss: 0.019413323862762708  hr: 0  min: 22  sec: 18\n",
      "epoch: 2  batch: 172 / 721  loss: 0.019303980190543794  hr: 0  min: 22  sec: 17\n",
      "epoch: 2  batch: 173 / 721  loss: 0.019195827736076494  hr: 0  min: 22  sec: 14\n",
      "epoch: 2  batch: 174 / 721  loss: 0.01909385626080537  hr: 0  min: 22  sec: 12\n",
      "epoch: 2  batch: 175 / 721  loss: 0.01902226231975614  hr: 0  min: 22  sec: 10\n",
      "epoch: 2  batch: 176 / 721  loss: 0.018920578839573533  hr: 0  min: 22  sec: 8\n",
      "epoch: 2  batch: 177 / 721  loss: 0.01886270846036989  hr: 0  min: 22  sec: 7\n",
      "epoch: 2  batch: 178 / 721  loss: 0.018938801726659897  hr: 0  min: 22  sec: 4\n",
      "epoch: 2  batch: 179 / 721  loss: 0.01885487454180481  hr: 0  min: 22  sec: 2\n",
      "epoch: 2  batch: 180 / 721  loss: 0.018773533858378263  hr: 0  min: 21  sec: 59\n",
      "epoch: 2  batch: 181 / 721  loss: 0.018677326155156257  hr: 0  min: 21  sec: 56\n",
      "epoch: 2  batch: 182 / 721  loss: 0.018623857599507843  hr: 0  min: 21  sec: 53\n",
      "epoch: 2  batch: 183 / 721  loss: 0.01876672039166617  hr: 0  min: 21  sec: 49\n",
      "epoch: 2  batch: 184 / 721  loss: 0.018670336208426463  hr: 0  min: 21  sec: 47\n",
      "epoch: 2  batch: 185 / 721  loss: 0.019113926092836048  hr: 0  min: 21  sec: 44\n",
      "epoch: 2  batch: 186 / 721  loss: 0.01902648317299017  hr: 0  min: 21  sec: 42\n",
      "epoch: 2  batch: 187 / 721  loss: 0.01903599388520781  hr: 0  min: 21  sec: 40\n",
      "epoch: 2  batch: 188 / 721  loss: 0.018937355660532472  hr: 0  min: 21  sec: 37\n",
      "epoch: 2  batch: 189 / 721  loss: 0.018978140085458846  hr: 0  min: 21  sec: 37\n",
      "epoch: 2  batch: 190 / 721  loss: 0.019013555250038686  hr: 0  min: 21  sec: 34\n",
      "epoch: 2  batch: 191 / 721  loss: 0.019030563748004013  hr: 0  min: 21  sec: 32\n",
      "epoch: 2  batch: 192 / 721  loss: 0.01893507583417886  hr: 0  min: 21  sec: 29\n",
      "epoch: 2  batch: 193 / 721  loss: 0.019033886288827132  hr: 0  min: 21  sec: 26\n",
      "epoch: 2  batch: 194 / 721  loss: 0.01894732428274775  hr: 0  min: 21  sec: 23\n",
      "epoch: 2  batch: 195 / 721  loss: 0.01890107710317422  hr: 0  min: 21  sec: 21\n",
      "epoch: 2  batch: 196 / 721  loss: 0.019005419134503296  hr: 0  min: 21  sec: 18\n",
      "epoch: 2  batch: 197 / 721  loss: 0.01932895351789282  hr: 0  min: 21  sec: 16\n",
      "epoch: 2  batch: 198 / 721  loss: 0.01924458171303897  hr: 0  min: 21  sec: 13\n",
      "epoch: 2  batch: 199 / 721  loss: 0.019159402201465805  hr: 0  min: 21  sec: 11\n",
      "epoch: 2  batch: 200 / 721  loss: 0.019105105608905434  hr: 0  min: 21  sec: 9\n",
      "epoch: 2  batch: 201 / 721  loss: 0.01921434139306379  hr: 0  min: 21  sec: 6\n",
      "epoch: 2  batch: 202 / 721  loss: 0.019172499753220128  hr: 0  min: 21  sec: 3\n",
      "epoch: 2  batch: 203 / 721  loss: 0.019101621848479456  hr: 0  min: 21  sec: 0\n",
      "epoch: 2  batch: 204 / 721  loss: 0.019023546316020656  hr: 0  min: 20  sec: 57\n",
      "epoch: 2  batch: 205 / 721  loss: 0.01894056155479786  hr: 0  min: 20  sec: 55\n",
      "epoch: 2  batch: 206 / 721  loss: 0.0188886434085909  hr: 0  min: 20  sec: 52\n",
      "epoch: 2  batch: 207 / 721  loss: 0.018844029739479972  hr: 0  min: 20  sec: 49\n",
      "epoch: 2  batch: 208 / 721  loss: 0.018862893916145998  hr: 0  min: 20  sec: 46\n",
      "epoch: 2  batch: 209 / 721  loss: 0.018957615080685022  hr: 0  min: 20  sec: 44\n",
      "epoch: 2  batch: 210 / 721  loss: 0.018891088803537147  hr: 0  min: 20  sec: 42\n",
      "epoch: 2  batch: 211 / 721  loss: 0.018893103328642715  hr: 0  min: 20  sec: 39\n",
      "epoch: 2  batch: 212 / 721  loss: 0.018810066980291112  hr: 0  min: 20  sec: 36\n",
      "epoch: 2  batch: 213 / 721  loss: 0.018750707152547716  hr: 0  min: 20  sec: 35\n",
      "epoch: 2  batch: 214 / 721  loss: 0.018714678462210685  hr: 0  min: 20  sec: 32\n",
      "epoch: 2  batch: 215 / 721  loss: 0.018849409316790963  hr: 0  min: 20  sec: 29\n",
      "epoch: 2  batch: 216 / 721  loss: 0.01888896254712125  hr: 0  min: 20  sec: 27\n",
      "epoch: 2  batch: 217 / 721  loss: 0.018812178027218483  hr: 0  min: 20  sec: 24\n",
      "epoch: 2  batch: 218 / 721  loss: 0.018762993257158488  hr: 0  min: 20  sec: 21\n",
      "epoch: 2  batch: 219 / 721  loss: 0.018731070995372273  hr: 0  min: 20  sec: 19\n",
      "epoch: 2  batch: 220 / 721  loss: 0.018654422351259695  hr: 0  min: 20  sec: 20\n",
      "epoch: 2  batch: 221 / 721  loss: 0.01858971926330471  hr: 0  min: 20  sec: 17\n",
      "epoch: 2  batch: 222 / 721  loss: 0.0185088789136923  hr: 0  min: 20  sec: 15\n",
      "epoch: 2  batch: 223 / 721  loss: 0.018478533879132324  hr: 0  min: 20  sec: 12\n",
      "epoch: 2  batch: 224 / 721  loss: 0.018411288225641847  hr: 0  min: 20  sec: 10\n",
      "epoch: 2  batch: 225 / 721  loss: 0.018417555222727564  hr: 0  min: 20  sec: 7\n",
      "epoch: 2  batch: 226 / 721  loss: 0.018345724576615433  hr: 0  min: 20  sec: 5\n",
      "epoch: 2  batch: 227 / 721  loss: 0.01828281651930535  hr: 0  min: 20  sec: 2\n",
      "epoch: 2  batch: 228 / 721  loss: 0.018214020999214865  hr: 0  min: 19  sec: 59\n",
      "epoch: 2  batch: 229 / 721  loss: 0.01814074898619046  hr: 0  min: 19  sec: 57\n",
      "epoch: 2  batch: 230 / 721  loss: 0.018066320295632897  hr: 0  min: 19  sec: 54\n",
      "epoch: 2  batch: 231 / 721  loss: 0.018291122681845295  hr: 0  min: 19  sec: 52\n",
      "epoch: 2  batch: 232 / 721  loss: 0.01821805955553608  hr: 0  min: 19  sec: 49\n",
      "epoch: 2  batch: 233 / 721  loss: 0.018143981453725797  hr: 0  min: 19  sec: 46\n",
      "epoch: 2  batch: 234 / 721  loss: 0.01806977078128053  hr: 0  min: 19  sec: 44\n",
      "epoch: 2  batch: 235 / 721  loss: 0.018000395985523318  hr: 0  min: 19  sec: 41\n",
      "epoch: 2  batch: 236 / 721  loss: 0.017927989977440537  hr: 0  min: 19  sec: 40\n",
      "epoch: 2  batch: 237 / 721  loss: 0.017858392793910167  hr: 0  min: 19  sec: 37\n",
      "epoch: 2  batch: 238 / 721  loss: 0.017788902162442163  hr: 0  min: 19  sec: 34\n",
      "epoch: 2  batch: 239 / 721  loss: 0.017904364946809748  hr: 0  min: 19  sec: 33\n",
      "epoch: 2  batch: 240 / 721  loss: 0.01784970957924088  hr: 0  min: 19  sec: 30\n",
      "epoch: 2  batch: 241 / 721  loss: 0.01778775599412717  hr: 0  min: 19  sec: 29\n",
      "epoch: 2  batch: 242 / 721  loss: 0.01771945126842003  hr: 0  min: 19  sec: 27\n",
      "epoch: 2  batch: 243 / 721  loss: 0.017648934297921873  hr: 0  min: 19  sec: 25\n",
      "epoch: 2  batch: 244 / 721  loss: 0.01764588777801751  hr: 0  min: 19  sec: 22\n",
      "epoch: 2  batch: 245 / 721  loss: 0.017692724409470412  hr: 0  min: 19  sec: 19\n",
      "epoch: 2  batch: 246 / 721  loss: 0.01762280929220814  hr: 0  min: 19  sec: 17\n",
      "epoch: 2  batch: 247 / 721  loss: 0.017556796210128928  hr: 0  min: 19  sec: 15\n",
      "epoch: 2  batch: 248 / 721  loss: 0.01748919285514163  hr: 0  min: 19  sec: 14\n",
      "epoch: 2  batch: 249 / 721  loss: 0.017424258422064427  hr: 0  min: 19  sec: 11\n",
      "epoch: 2  batch: 250 / 721  loss: 0.017378851074608972  hr: 0  min: 19  sec: 9\n",
      "epoch: 2  batch: 251 / 721  loss: 0.017318372650742642  hr: 0  min: 19  sec: 7\n",
      "epoch: 2  batch: 252 / 721  loss: 0.017252404848275345  hr: 0  min: 19  sec: 6\n",
      "epoch: 2  batch: 253 / 721  loss: 0.018330995935239007  hr: 0  min: 19  sec: 3\n",
      "epoch: 2  batch: 254 / 721  loss: 0.0184589094058638  hr: 0  min: 19  sec: 1\n",
      "epoch: 2  batch: 255 / 721  loss: 0.018406503920913583  hr: 0  min: 18  sec: 58\n",
      "epoch: 2  batch: 256 / 721  loss: 0.018352680235125263  hr: 0  min: 18  sec: 55\n",
      "epoch: 2  batch: 257 / 721  loss: 0.01829750613698551  hr: 0  min: 18  sec: 52\n",
      "epoch: 2  batch: 258 / 721  loss: 0.01827913934539538  hr: 0  min: 18  sec: 50\n",
      "epoch: 2  batch: 259 / 721  loss: 0.018215764628909347  hr: 0  min: 18  sec: 47\n",
      "epoch: 2  batch: 260 / 721  loss: 0.018168851561607042  hr: 0  min: 18  sec: 45\n",
      "epoch: 2  batch: 261 / 721  loss: 0.018112995915477954  hr: 0  min: 18  sec: 42\n",
      "epoch: 2  batch: 262 / 721  loss: 0.01807428146425887  hr: 0  min: 18  sec: 41\n",
      "epoch: 2  batch: 263 / 721  loss: 0.018100957198846666  hr: 0  min: 18  sec: 38\n",
      "epoch: 2  batch: 264 / 721  loss: 0.01804552487815134  hr: 0  min: 18  sec: 35\n",
      "epoch: 2  batch: 265 / 721  loss: 0.01799450080242131  hr: 0  min: 18  sec: 33\n",
      "epoch: 2  batch: 266 / 721  loss: 0.017930898751824555  hr: 0  min: 18  sec: 31\n",
      "epoch: 2  batch: 267 / 721  loss: 0.01788644525359824  hr: 0  min: 18  sec: 28\n",
      "epoch: 2  batch: 268 / 721  loss: 0.017829213213543027  hr: 0  min: 18  sec: 25\n",
      "epoch: 2  batch: 269 / 721  loss: 0.017780307287737194  hr: 0  min: 18  sec: 23\n",
      "epoch: 2  batch: 270 / 721  loss: 0.017760929253482674  hr: 0  min: 18  sec: 22\n",
      "epoch: 2  batch: 271 / 721  loss: 0.017854735057958232  hr: 0  min: 18  sec: 19\n",
      "epoch: 2  batch: 272 / 721  loss: 0.01782497155738169  hr: 0  min: 18  sec: 17\n",
      "epoch: 2  batch: 273 / 721  loss: 0.017770058415201576  hr: 0  min: 18  sec: 14\n",
      "epoch: 2  batch: 274 / 721  loss: 0.01771244800674651  hr: 0  min: 18  sec: 11\n",
      "epoch: 2  batch: 275 / 721  loss: 0.01765157915344885  hr: 0  min: 18  sec: 9\n",
      "epoch: 2  batch: 276 / 721  loss: 0.017883207234262954  hr: 0  min: 18  sec: 6\n",
      "epoch: 2  batch: 277 / 721  loss: 0.017827766721657163  hr: 0  min: 18  sec: 3\n",
      "epoch: 2  batch: 278 / 721  loss: 0.017771952768277692  hr: 0  min: 18  sec: 2\n",
      "epoch: 2  batch: 279 / 721  loss: 0.01771418275977118  hr: 0  min: 17  sec: 59\n",
      "epoch: 2  batch: 280 / 721  loss: 0.01786448927294779  hr: 0  min: 17  sec: 57\n",
      "epoch: 2  batch: 281 / 721  loss: 0.017811873217102543  hr: 0  min: 17  sec: 54\n",
      "epoch: 2  batch: 282 / 721  loss: 0.01785423009396706  hr: 0  min: 17  sec: 51\n",
      "epoch: 2  batch: 283 / 721  loss: 0.017834671399808676  hr: 0  min: 17  sec: 48\n",
      "epoch: 2  batch: 284 / 721  loss: 0.01784847425426025  hr: 0  min: 17  sec: 45\n",
      "epoch: 2  batch: 285 / 721  loss: 0.017790989660180025  hr: 0  min: 17  sec: 43\n",
      "epoch: 2  batch: 286 / 721  loss: 0.017752154403707254  hr: 0  min: 17  sec: 41\n",
      "epoch: 2  batch: 287 / 721  loss: 0.017705325847584916  hr: 0  min: 17  sec: 39\n",
      "epoch: 2  batch: 288 / 721  loss: 0.017654868953488605  hr: 0  min: 17  sec: 36\n",
      "epoch: 2  batch: 289 / 721  loss: 0.017604417247261857  hr: 0  min: 17  sec: 34\n",
      "epoch: 2  batch: 290 / 721  loss: 0.017578846469003675  hr: 0  min: 17  sec: 31\n",
      "epoch: 2  batch: 291 / 721  loss: 0.017524975796347753  hr: 0  min: 17  sec: 29\n",
      "epoch: 2  batch: 292 / 721  loss: 0.017472808455313998  hr: 0  min: 17  sec: 26\n",
      "epoch: 2  batch: 293 / 721  loss: 0.017532312615084027  hr: 0  min: 17  sec: 24\n",
      "epoch: 2  batch: 294 / 721  loss: 0.01749927670167059  hr: 0  min: 17  sec: 21\n",
      "epoch: 2  batch: 295 / 721  loss: 0.01744713952194631  hr: 0  min: 17  sec: 19\n",
      "epoch: 2  batch: 296 / 721  loss: 0.01739575787999186  hr: 0  min: 17  sec: 17\n",
      "epoch: 2  batch: 297 / 721  loss: 0.01735721517741125  hr: 0  min: 17  sec: 15\n",
      "epoch: 2  batch: 298 / 721  loss: 0.01732130640140663  hr: 0  min: 17  sec: 12\n",
      "epoch: 2  batch: 299 / 721  loss: 0.0172724942368164  hr: 0  min: 17  sec: 10\n",
      "epoch: 2  batch: 300 / 721  loss: 0.017219029987754767  hr: 0  min: 17  sec: 7\n",
      "epoch: 2  batch: 301 / 721  loss: 0.01761501921065062  hr: 0  min: 17  sec: 5\n",
      "epoch: 2  batch: 302 / 721  loss: 0.017559595330212025  hr: 0  min: 17  sec: 3\n",
      "epoch: 2  batch: 303 / 721  loss: 0.0175305123979006  hr: 0  min: 17  sec: 0\n",
      "epoch: 2  batch: 304 / 721  loss: 0.017479581743540813  hr: 0  min: 16  sec: 57\n",
      "epoch: 2  batch: 305 / 721  loss: 0.0174294743271827  hr: 0  min: 16  sec: 55\n",
      "epoch: 2  batch: 306 / 721  loss: 0.01739916634364312  hr: 0  min: 16  sec: 52\n",
      "epoch: 2  batch: 307 / 721  loss: 0.017347925391631408  hr: 0  min: 16  sec: 50\n",
      "epoch: 2  batch: 308 / 721  loss: 0.01729736260341423  hr: 0  min: 16  sec: 50\n",
      "epoch: 2  batch: 309 / 721  loss: 0.017262218077083096  hr: 0  min: 16  sec: 47\n",
      "epoch: 2  batch: 310 / 721  loss: 0.017214568510685386  hr: 0  min: 16  sec: 44\n",
      "epoch: 2  batch: 311 / 721  loss: 0.01717344645743552  hr: 0  min: 16  sec: 42\n",
      "epoch: 2  batch: 312 / 721  loss: 0.01712431028182693  hr: 0  min: 16  sec: 40\n",
      "epoch: 2  batch: 313 / 721  loss: 0.01708385812763211  hr: 0  min: 16  sec: 37\n",
      "epoch: 2  batch: 314 / 721  loss: 0.01703256627948507  hr: 0  min: 16  sec: 34\n",
      "epoch: 2  batch: 315 / 721  loss: 0.017329447498519182  hr: 0  min: 16  sec: 32\n",
      "epoch: 2  batch: 316 / 721  loss: 0.017276211217052414  hr: 0  min: 16  sec: 30\n",
      "epoch: 2  batch: 317 / 721  loss: 0.017259939044603066  hr: 0  min: 16  sec: 28\n",
      "epoch: 2  batch: 318 / 721  loss: 0.01722610548972196  hr: 0  min: 16  sec: 26\n",
      "epoch: 2  batch: 319 / 721  loss: 0.017240973824192114  hr: 0  min: 16  sec: 24\n",
      "epoch: 2  batch: 320 / 721  loss: 0.01719892830997196  hr: 0  min: 16  sec: 22\n",
      "epoch: 2  batch: 321 / 721  loss: 0.017150034714650472  hr: 0  min: 16  sec: 19\n",
      "epoch: 2  batch: 322 / 721  loss: 0.01714773287409873  hr: 0  min: 16  sec: 16\n",
      "epoch: 2  batch: 323 / 721  loss: 0.017123332747489634  hr: 0  min: 16  sec: 15\n",
      "epoch: 2  batch: 324 / 721  loss: 0.017073190386495466  hr: 0  min: 16  sec: 13\n",
      "epoch: 2  batch: 325 / 721  loss: 0.017110523926004623  hr: 0  min: 16  sec: 10\n",
      "epoch: 2  batch: 326 / 721  loss: 0.01706106287805418  hr: 0  min: 16  sec: 8\n",
      "epoch: 2  batch: 327 / 721  loss: 0.017010424161434532  hr: 0  min: 16  sec: 6\n",
      "epoch: 2  batch: 328 / 721  loss: 0.016971712662868923  hr: 0  min: 16  sec: 3\n",
      "epoch: 2  batch: 329 / 721  loss: 0.016921355977592888  hr: 0  min: 16  sec: 1\n",
      "epoch: 2  batch: 330 / 721  loss: 0.016923747575492597  hr: 0  min: 15  sec: 59\n",
      "epoch: 2  batch: 331 / 721  loss: 0.01699193494137323  hr: 0  min: 15  sec: 56\n",
      "epoch: 2  batch: 332 / 721  loss: 0.01698267239355272  hr: 0  min: 15  sec: 53\n",
      "epoch: 2  batch: 333 / 721  loss: 0.016935223075243092  hr: 0  min: 15  sec: 51\n",
      "epoch: 2  batch: 334 / 721  loss: 0.016886164100082944  hr: 0  min: 15  sec: 49\n",
      "epoch: 2  batch: 335 / 721  loss: 0.016840107403017942  hr: 0  min: 15  sec: 46\n",
      "epoch: 2  batch: 336 / 721  loss: 0.01679166426064122  hr: 0  min: 15  sec: 43\n",
      "epoch: 2  batch: 337 / 721  loss: 0.01674340822112481  hr: 0  min: 15  sec: 42\n",
      "epoch: 2  batch: 338 / 721  loss: 0.016698302076416524  hr: 0  min: 15  sec: 39\n",
      "epoch: 2  batch: 339 / 721  loss: 0.016657022112423477  hr: 0  min: 15  sec: 37\n",
      "epoch: 2  batch: 340 / 721  loss: 0.01660897027091671  hr: 0  min: 15  sec: 35\n",
      "epoch: 2  batch: 341 / 721  loss: 0.01658196537516454  hr: 0  min: 15  sec: 33\n",
      "epoch: 2  batch: 342 / 721  loss: 0.016673389102988576  hr: 0  min: 15  sec: 30\n",
      "epoch: 2  batch: 343 / 721  loss: 0.016625709450479906  hr: 0  min: 15  sec: 28\n",
      "epoch: 2  batch: 344 / 721  loss: 0.016580576053668264  hr: 0  min: 15  sec: 25\n",
      "epoch: 2  batch: 345 / 721  loss: 0.01657564663353538  hr: 0  min: 15  sec: 23\n",
      "epoch: 2  batch: 346 / 721  loss: 0.016536985790727772  hr: 0  min: 15  sec: 20\n",
      "epoch: 2  batch: 347 / 721  loss: 0.016502901887831812  hr: 0  min: 15  sec: 18\n",
      "epoch: 2  batch: 348 / 721  loss: 0.01645715172637064  hr: 0  min: 15  sec: 15\n",
      "epoch: 2  batch: 349 / 721  loss: 0.01641187546376131  hr: 0  min: 15  sec: 13\n",
      "epoch: 2  batch: 350 / 721  loss: 0.01636705518425775  hr: 0  min: 15  sec: 10\n",
      "epoch: 2  batch: 351 / 721  loss: 0.01632420831428578  hr: 0  min: 15  sec: 7\n",
      "epoch: 2  batch: 352 / 721  loss: 0.01627978037578776  hr: 0  min: 15  sec: 5\n",
      "epoch: 2  batch: 353 / 721  loss: 0.01625176022205536  hr: 0  min: 15  sec: 2\n",
      "epoch: 2  batch: 354 / 721  loss: 0.016209289451714442  hr: 0  min: 15  sec: 0\n",
      "epoch: 2  batch: 355 / 721  loss: 0.016173411967826377  hr: 0  min: 14  sec: 57\n",
      "epoch: 2  batch: 356 / 721  loss: 0.01614418023259685  hr: 0  min: 14  sec: 54\n",
      "epoch: 2  batch: 357 / 721  loss: 0.016148189773162857  hr: 0  min: 14  sec: 52\n",
      "epoch: 2  batch: 358 / 721  loss: 0.016105179672403255  hr: 0  min: 14  sec: 49\n",
      "epoch: 2  batch: 359 / 721  loss: 0.01685237360757926  hr: 0  min: 14  sec: 46\n",
      "epoch: 2  batch: 360 / 721  loss: 0.016807296329271696  hr: 0  min: 14  sec: 44\n",
      "epoch: 2  batch: 361 / 721  loss: 0.016788518928662795  hr: 0  min: 14  sec: 41\n",
      "epoch: 2  batch: 362 / 721  loss: 0.016859975576967397  hr: 0  min: 14  sec: 39\n",
      "epoch: 2  batch: 363 / 721  loss: 0.01697903831552563  hr: 0  min: 14  sec: 36\n",
      "epoch: 2  batch: 364 / 721  loss: 0.016942477918496728  hr: 0  min: 14  sec: 34\n",
      "epoch: 2  batch: 365 / 721  loss: 0.016899215554808944  hr: 0  min: 14  sec: 31\n",
      "epoch: 2  batch: 366 / 721  loss: 0.017265238307808944  hr: 0  min: 14  sec: 29\n",
      "epoch: 2  batch: 367 / 721  loss: 0.017531184040340507  hr: 0  min: 14  sec: 26\n",
      "epoch: 2  batch: 368 / 721  loss: 0.017495364183322756  hr: 0  min: 14  sec: 23\n",
      "epoch: 2  batch: 369 / 721  loss: 0.01745346801011283  hr: 0  min: 14  sec: 21\n",
      "epoch: 2  batch: 370 / 721  loss: 0.01740985624688816  hr: 0  min: 14  sec: 19\n",
      "epoch: 2  batch: 371 / 721  loss: 0.01749185375523166  hr: 0  min: 14  sec: 16\n",
      "epoch: 2  batch: 372 / 721  loss: 0.017454596717109007  hr: 0  min: 14  sec: 14\n",
      "epoch: 2  batch: 373 / 721  loss: 0.017421520442527722  hr: 0  min: 14  sec: 11\n",
      "epoch: 2  batch: 374 / 721  loss: 0.01738116636514019  hr: 0  min: 14  sec: 9\n",
      "epoch: 2  batch: 375 / 721  loss: 0.017655684325300777  hr: 0  min: 14  sec: 6\n",
      "epoch: 2  batch: 376 / 721  loss: 0.017615906223657843  hr: 0  min: 14  sec: 5\n",
      "epoch: 2  batch: 377 / 721  loss: 0.017594482137748124  hr: 0  min: 14  sec: 2\n",
      "epoch: 2  batch: 378 / 721  loss: 0.017556609784295442  hr: 0  min: 14  sec: 0\n",
      "epoch: 2  batch: 379 / 721  loss: 0.017512356713835008  hr: 0  min: 13  sec: 58\n",
      "epoch: 2  batch: 380 / 721  loss: 0.017492544198926464  hr: 0  min: 13  sec: 55\n",
      "epoch: 2  batch: 381 / 721  loss: 0.01745087620712086  hr: 0  min: 13  sec: 53\n",
      "epoch: 2  batch: 382 / 721  loss: 0.017418240675539952  hr: 0  min: 13  sec: 50\n",
      "epoch: 2  batch: 383 / 721  loss: 0.017382315288351935  hr: 0  min: 13  sec: 48\n",
      "epoch: 2  batch: 384 / 721  loss: 0.017365425414103203  hr: 0  min: 13  sec: 45\n",
      "epoch: 2  batch: 385 / 721  loss: 0.017331977302356708  hr: 0  min: 13  sec: 42\n",
      "epoch: 2  batch: 386 / 721  loss: 0.01736816208710993  hr: 0  min: 13  sec: 40\n",
      "epoch: 2  batch: 387 / 721  loss: 0.01735218195613168  hr: 0  min: 13  sec: 37\n",
      "epoch: 2  batch: 388 / 721  loss: 0.01738030603643058  hr: 0  min: 13  sec: 35\n",
      "epoch: 2  batch: 389 / 721  loss: 0.017555246565441284  hr: 0  min: 13  sec: 33\n",
      "epoch: 2  batch: 390 / 721  loss: 0.01751344299417001  hr: 0  min: 13  sec: 30\n",
      "epoch: 2  batch: 391 / 721  loss: 0.01747579524262875  hr: 0  min: 13  sec: 28\n",
      "epoch: 2  batch: 392 / 721  loss: 0.01743467492314248  hr: 0  min: 13  sec: 27\n",
      "epoch: 2  batch: 393 / 721  loss: 0.017407699686942536  hr: 0  min: 13  sec: 25\n",
      "epoch: 2  batch: 394 / 721  loss: 0.017499508910359184  hr: 0  min: 13  sec: 22\n",
      "epoch: 2  batch: 395 / 721  loss: 0.01746137841122779  hr: 0  min: 13  sec: 20\n",
      "epoch: 2  batch: 396 / 721  loss: 0.017429323576292555  hr: 0  min: 13  sec: 18\n",
      "epoch: 2  batch: 397 / 721  loss: 0.01745936432737512  hr: 0  min: 13  sec: 15\n",
      "epoch: 2  batch: 398 / 721  loss: 0.017466612746158086  hr: 0  min: 13  sec: 12\n",
      "epoch: 2  batch: 399 / 721  loss: 0.017433779395636485  hr: 0  min: 13  sec: 9\n",
      "epoch: 2  batch: 400 / 721  loss: 0.017415728952983045  hr: 0  min: 13  sec: 7\n",
      "epoch: 2  batch: 401 / 721  loss: 0.017378565989811544  hr: 0  min: 13  sec: 4\n",
      "epoch: 2  batch: 402 / 721  loss: 0.01733882588385639  hr: 0  min: 13  sec: 2\n",
      "epoch: 2  batch: 403 / 721  loss: 0.017386296586721105  hr: 0  min: 12  sec: 59\n",
      "epoch: 2  batch: 404 / 721  loss: 0.017360521097264672  hr: 0  min: 12  sec: 57\n",
      "epoch: 2  batch: 405 / 721  loss: 0.01732165101192673  hr: 0  min: 12  sec: 55\n",
      "epoch: 2  batch: 406 / 721  loss: 0.017514388840040536  hr: 0  min: 12  sec: 52\n",
      "epoch: 2  batch: 407 / 721  loss: 0.01747555310012148  hr: 0  min: 12  sec: 50\n",
      "epoch: 2  batch: 408 / 721  loss: 0.01743610567784487  hr: 0  min: 12  sec: 47\n",
      "epoch: 2  batch: 409 / 721  loss: 0.01740445490691112  hr: 0  min: 12  sec: 46\n",
      "epoch: 2  batch: 410 / 721  loss: 0.01738411064420134  hr: 0  min: 12  sec: 43\n",
      "epoch: 2  batch: 411 / 721  loss: 0.017359243507382015  hr: 0  min: 12  sec: 41\n",
      "epoch: 2  batch: 412 / 721  loss: 0.017381382813166885  hr: 0  min: 12  sec: 39\n",
      "epoch: 2  batch: 413 / 721  loss: 0.017341375333969043  hr: 0  min: 12  sec: 36\n",
      "epoch: 2  batch: 414 / 721  loss: 0.017318127497933367  hr: 0  min: 12  sec: 34\n",
      "epoch: 2  batch: 415 / 721  loss: 0.017285467783502494  hr: 0  min: 12  sec: 32\n",
      "epoch: 2  batch: 416 / 721  loss: 0.01726422245134857  hr: 0  min: 12  sec: 29\n",
      "epoch: 2  batch: 417 / 721  loss: 0.017234850065641405  hr: 0  min: 12  sec: 26\n",
      "epoch: 2  batch: 418 / 721  loss: 0.017198094380916427  hr: 0  min: 12  sec: 24\n",
      "epoch: 2  batch: 419 / 721  loss: 0.01718695050788663  hr: 0  min: 12  sec: 22\n",
      "epoch: 2  batch: 420 / 721  loss: 0.01714891902014469  hr: 0  min: 12  sec: 19\n",
      "epoch: 2  batch: 421 / 721  loss: 0.017109354407730624  hr: 0  min: 12  sec: 17\n",
      "epoch: 2  batch: 422 / 721  loss: 0.017074082330957835  hr: 0  min: 12  sec: 14\n",
      "epoch: 2  batch: 423 / 721  loss: 0.017055881770625468  hr: 0  min: 12  sec: 11\n",
      "epoch: 2  batch: 424 / 721  loss: 0.01701742193142978  hr: 0  min: 12  sec: 9\n",
      "epoch: 2  batch: 425 / 721  loss: 0.016979589668335394  hr: 0  min: 12  sec: 7\n",
      "epoch: 2  batch: 426 / 721  loss: 0.016942219382729665  hr: 0  min: 12  sec: 4\n",
      "epoch: 2  batch: 427 / 721  loss: 0.01690817671748635  hr: 0  min: 12  sec: 1\n",
      "epoch: 2  batch: 428 / 721  loss: 0.01692566748091866  hr: 0  min: 11  sec: 59\n",
      "epoch: 2  batch: 429 / 721  loss: 0.016891524737653603  hr: 0  min: 11  sec: 57\n",
      "epoch: 2  batch: 430 / 721  loss: 0.01695564233645158  hr: 0  min: 11  sec: 55\n",
      "epoch: 2  batch: 431 / 721  loss: 0.01691702472645921  hr: 0  min: 11  sec: 52\n",
      "epoch: 2  batch: 432 / 721  loss: 0.016885096757336956  hr: 0  min: 11  sec: 49\n",
      "epoch: 2  batch: 433 / 721  loss: 0.016847181476383227  hr: 0  min: 11  sec: 47\n",
      "epoch: 2  batch: 434 / 721  loss: 0.016812106910360707  hr: 0  min: 11  sec: 44\n",
      "epoch: 2  batch: 435 / 721  loss: 0.016775615811388103  hr: 0  min: 11  sec: 42\n",
      "epoch: 2  batch: 436 / 721  loss: 0.016818938664106733  hr: 0  min: 11  sec: 40\n",
      "epoch: 2  batch: 437 / 721  loss: 0.016781399210126967  hr: 0  min: 11  sec: 38\n",
      "epoch: 2  batch: 438 / 721  loss: 0.01674713906610106  hr: 0  min: 11  sec: 35\n",
      "epoch: 2  batch: 439 / 721  loss: 0.016723552487850516  hr: 0  min: 11  sec: 33\n",
      "epoch: 2  batch: 440 / 721  loss: 0.016697371033859036  hr: 0  min: 11  sec: 30\n",
      "epoch: 2  batch: 441 / 721  loss: 0.01670371351454485  hr: 0  min: 11  sec: 28\n",
      "epoch: 2  batch: 442 / 721  loss: 0.016666978779902083  hr: 0  min: 11  sec: 25\n",
      "epoch: 2  batch: 443 / 721  loss: 0.016693140559831874  hr: 0  min: 11  sec: 23\n",
      "epoch: 2  batch: 444 / 721  loss: 0.016656041169840097  hr: 0  min: 11  sec: 21\n",
      "epoch: 2  batch: 445 / 721  loss: 0.016621338470519803  hr: 0  min: 11  sec: 18\n",
      "epoch: 2  batch: 446 / 721  loss: 0.017009233098582578  hr: 0  min: 11  sec: 16\n",
      "epoch: 2  batch: 447 / 721  loss: 0.016972634417730982  hr: 0  min: 11  sec: 13\n",
      "epoch: 2  batch: 448 / 721  loss: 0.016936133706102346  hr: 0  min: 11  sec: 10\n",
      "epoch: 2  batch: 449 / 721  loss: 0.017050867944847968  hr: 0  min: 11  sec: 8\n",
      "epoch: 2  batch: 450 / 721  loss: 0.017030826050581205  hr: 0  min: 11  sec: 5\n",
      "epoch: 2  batch: 451 / 721  loss: 0.016995496287200592  hr: 0  min: 11  sec: 3\n",
      "epoch: 2  batch: 452 / 721  loss: 0.01695968887824833  hr: 0  min: 11  sec: 0\n",
      "epoch: 2  batch: 453 / 721  loss: 0.01692560147589163  hr: 0  min: 10  sec: 58\n",
      "epoch: 2  batch: 454 / 721  loss: 0.01688947631835954  hr: 0  min: 10  sec: 55\n",
      "epoch: 2  batch: 455 / 721  loss: 0.016859645866226035  hr: 0  min: 10  sec: 53\n",
      "epoch: 2  batch: 456 / 721  loss: 0.0168326765629708  hr: 0  min: 10  sec: 50\n",
      "epoch: 2  batch: 457 / 721  loss: 0.016801655948206914  hr: 0  min: 10  sec: 48\n",
      "epoch: 2  batch: 458 / 721  loss: 0.016773338326431943  hr: 0  min: 10  sec: 45\n",
      "epoch: 2  batch: 459 / 721  loss: 0.01686582340014802  hr: 0  min: 10  sec: 43\n",
      "epoch: 2  batch: 460 / 721  loss: 0.01684439874547736  hr: 0  min: 10  sec: 40\n",
      "epoch: 2  batch: 461 / 721  loss: 0.016810695082656313  hr: 0  min: 10  sec: 38\n",
      "epoch: 2  batch: 462 / 721  loss: 0.016775557816303757  hr: 0  min: 10  sec: 35\n",
      "epoch: 2  batch: 463 / 721  loss: 0.016741658996043376  hr: 0  min: 10  sec: 33\n",
      "epoch: 2  batch: 464 / 721  loss: 0.01670811503334272  hr: 0  min: 10  sec: 30\n",
      "epoch: 2  batch: 465 / 721  loss: 0.016692252521107714  hr: 0  min: 10  sec: 28\n",
      "epoch: 2  batch: 466 / 721  loss: 0.01666124146659019  hr: 0  min: 10  sec: 25\n",
      "epoch: 2  batch: 467 / 721  loss: 0.016785302775641765  hr: 0  min: 10  sec: 23\n",
      "epoch: 2  batch: 468 / 721  loss: 0.016753079219294403  hr: 0  min: 10  sec: 20\n",
      "epoch: 2  batch: 469 / 721  loss: 0.016718123661307517  hr: 0  min: 10  sec: 18\n",
      "epoch: 2  batch: 470 / 721  loss: 0.01668846287152809  hr: 0  min: 10  sec: 16\n",
      "epoch: 2  batch: 471 / 721  loss: 0.01676236614429208  hr: 0  min: 10  sec: 13\n",
      "epoch: 2  batch: 472 / 721  loss: 0.016728533043795447  hr: 0  min: 10  sec: 10\n",
      "epoch: 2  batch: 473 / 721  loss: 0.016697979181828707  hr: 0  min: 10  sec: 8\n",
      "epoch: 2  batch: 474 / 721  loss: 0.01672322491101846  hr: 0  min: 10  sec: 5\n",
      "epoch: 2  batch: 475 / 721  loss: 0.0166972715300998  hr: 0  min: 10  sec: 3\n",
      "epoch: 2  batch: 476 / 721  loss: 0.01669484368408541  hr: 0  min: 10  sec: 0\n",
      "epoch: 2  batch: 477 / 721  loss: 0.016678312812044443  hr: 0  min: 9  sec: 58\n",
      "epoch: 2  batch: 478 / 721  loss: 0.016645372016199526  hr: 0  min: 9  sec: 55\n",
      "epoch: 2  batch: 479 / 721  loss: 0.01662111935246588  hr: 0  min: 9  sec: 53\n",
      "epoch: 2  batch: 480 / 721  loss: 0.01658799132759062  hr: 0  min: 9  sec: 51\n",
      "epoch: 2  batch: 481 / 721  loss: 0.016556006160433057  hr: 0  min: 9  sec: 48\n",
      "epoch: 2  batch: 482 / 721  loss: 0.016525756818178607  hr: 0  min: 9  sec: 46\n",
      "epoch: 2  batch: 483 / 721  loss: 0.016493361203581303  hr: 0  min: 9  sec: 43\n",
      "epoch: 2  batch: 484 / 721  loss: 0.016462461389471345  hr: 0  min: 9  sec: 40\n",
      "epoch: 2  batch: 485 / 721  loss: 0.016429767730050556  hr: 0  min: 9  sec: 38\n",
      "epoch: 2  batch: 486 / 721  loss: 0.016396624245728776  hr: 0  min: 9  sec: 35\n",
      "epoch: 2  batch: 487 / 721  loss: 0.016365510213630585  hr: 0  min: 9  sec: 33\n",
      "epoch: 2  batch: 488 / 721  loss: 0.016332412662509864  hr: 0  min: 9  sec: 31\n",
      "epoch: 2  batch: 489 / 721  loss: 0.016299796185290996  hr: 0  min: 9  sec: 28\n",
      "epoch: 2  batch: 490 / 721  loss: 0.016268962803736273  hr: 0  min: 9  sec: 26\n",
      "epoch: 2  batch: 491 / 721  loss: 0.016237133080929295  hr: 0  min: 9  sec: 23\n",
      "epoch: 2  batch: 492 / 721  loss: 0.0162070967074  hr: 0  min: 9  sec: 21\n",
      "epoch: 2  batch: 493 / 721  loss: 0.016176858193887603  hr: 0  min: 9  sec: 18\n",
      "epoch: 2  batch: 494 / 721  loss: 0.016145525438141226  hr: 0  min: 9  sec: 16\n",
      "epoch: 2  batch: 495 / 721  loss: 0.016117289802235917  hr: 0  min: 9  sec: 13\n",
      "epoch: 2  batch: 496 / 721  loss: 0.016205828648796137  hr: 0  min: 9  sec: 11\n",
      "epoch: 2  batch: 497 / 721  loss: 0.01624742041310807  hr: 0  min: 9  sec: 8\n",
      "epoch: 2  batch: 498 / 721  loss: 0.016216902501717954  hr: 0  min: 9  sec: 6\n",
      "epoch: 2  batch: 499 / 721  loss: 0.016184825188101677  hr: 0  min: 9  sec: 4\n",
      "epoch: 2  batch: 500 / 721  loss: 0.016152634364596453  hr: 0  min: 9  sec: 1\n",
      "epoch: 2  batch: 501 / 721  loss: 0.016121963960763524  hr: 0  min: 8  sec: 59\n",
      "epoch: 2  batch: 502 / 721  loss: 0.016090173288555172  hr: 0  min: 8  sec: 56\n",
      "epoch: 2  batch: 503 / 721  loss: 0.01605875803879844  hr: 0  min: 8  sec: 54\n",
      "epoch: 2  batch: 504 / 721  loss: 0.016028869238494187  hr: 0  min: 8  sec: 52\n",
      "epoch: 2  batch: 505 / 721  loss: 0.015997996892895903  hr: 0  min: 8  sec: 49\n",
      "epoch: 2  batch: 506 / 721  loss: 0.015966610874205468  hr: 0  min: 8  sec: 47\n",
      "epoch: 2  batch: 507 / 721  loss: 0.01593721321720184  hr: 0  min: 8  sec: 44\n",
      "epoch: 2  batch: 508 / 721  loss: 0.015996762847232355  hr: 0  min: 8  sec: 42\n",
      "epoch: 2  batch: 509 / 721  loss: 0.015966803372155693  hr: 0  min: 8  sec: 39\n",
      "epoch: 2  batch: 510 / 721  loss: 0.01593625107884245  hr: 0  min: 8  sec: 37\n",
      "epoch: 2  batch: 511 / 721  loss: 0.01590528819308087  hr: 0  min: 8  sec: 35\n",
      "epoch: 2  batch: 512 / 721  loss: 0.01587458949317977  hr: 0  min: 8  sec: 33\n",
      "epoch: 2  batch: 513 / 721  loss: 0.015844899008604158  hr: 0  min: 8  sec: 30\n",
      "epoch: 2  batch: 514 / 721  loss: 0.015916241929389726  hr: 0  min: 8  sec: 28\n",
      "epoch: 2  batch: 515 / 721  loss: 0.015886235220097255  hr: 0  min: 8  sec: 25\n",
      "epoch: 2  batch: 516 / 721  loss: 0.015922031875371157  hr: 0  min: 8  sec: 23\n",
      "epoch: 2  batch: 517 / 721  loss: 0.015897817554096336  hr: 0  min: 8  sec: 20\n",
      "epoch: 2  batch: 518 / 721  loss: 0.015874230200543342  hr: 0  min: 8  sec: 18\n",
      "epoch: 2  batch: 519 / 721  loss: 0.01584558214972714  hr: 0  min: 8  sec: 15\n",
      "epoch: 2  batch: 520 / 721  loss: 0.015815868196533793  hr: 0  min: 8  sec: 13\n",
      "epoch: 2  batch: 521 / 721  loss: 0.015789476110770983  hr: 0  min: 8  sec: 11\n",
      "epoch: 2  batch: 522 / 721  loss: 0.01576066421514314  hr: 0  min: 8  sec: 8\n",
      "epoch: 2  batch: 523 / 721  loss: 0.015785413344459584  hr: 0  min: 8  sec: 6\n",
      "epoch: 2  batch: 524 / 721  loss: 0.015756168564621476  hr: 0  min: 8  sec: 3\n",
      "epoch: 2  batch: 525 / 721  loss: 0.015765717457245393  hr: 0  min: 8  sec: 1\n",
      "epoch: 2  batch: 526 / 721  loss: 0.015736371237306458  hr: 0  min: 7  sec: 58\n",
      "epoch: 2  batch: 527 / 721  loss: 0.01581928613336933  hr: 0  min: 7  sec: 55\n",
      "epoch: 2  batch: 528 / 721  loss: 0.015790378209244824  hr: 0  min: 7  sec: 53\n",
      "epoch: 2  batch: 529 / 721  loss: 0.015763346158011067  hr: 0  min: 7  sec: 50\n",
      "epoch: 2  batch: 530 / 721  loss: 0.01573981390589187  hr: 0  min: 7  sec: 48\n",
      "epoch: 2  batch: 531 / 721  loss: 0.015716527398627337  hr: 0  min: 7  sec: 46\n",
      "epoch: 2  batch: 532 / 721  loss: 0.01568902447724028  hr: 0  min: 7  sec: 44\n",
      "epoch: 2  batch: 533 / 721  loss: 0.01566059597641809  hr: 0  min: 7  sec: 41\n",
      "epoch: 2  batch: 534 / 721  loss: 0.015633076885585958  hr: 0  min: 7  sec: 38\n",
      "epoch: 2  batch: 535 / 721  loss: 0.015631633792570293  hr: 0  min: 7  sec: 36\n",
      "epoch: 2  batch: 536 / 721  loss: 0.015614209833196882  hr: 0  min: 7  sec: 34\n",
      "epoch: 2  batch: 537 / 721  loss: 0.015737090070032905  hr: 0  min: 7  sec: 31\n",
      "epoch: 2  batch: 538 / 721  loss: 0.01570889502239825  hr: 0  min: 7  sec: 28\n",
      "epoch: 2  batch: 539 / 721  loss: 0.01572313813837096  hr: 0  min: 7  sec: 26\n",
      "epoch: 2  batch: 540 / 721  loss: 0.015708205776105322  hr: 0  min: 7  sec: 23\n",
      "epoch: 2  batch: 541 / 721  loss: 0.01568253240732865  hr: 0  min: 7  sec: 21\n",
      "epoch: 2  batch: 542 / 721  loss: 0.015654614275920947  hr: 0  min: 7  sec: 19\n",
      "epoch: 2  batch: 543 / 721  loss: 0.015638392875641546  hr: 0  min: 7  sec: 16\n",
      "epoch: 2  batch: 544 / 721  loss: 0.015611313518240208  hr: 0  min: 7  sec: 14\n",
      "epoch: 2  batch: 545 / 721  loss: 0.015595676157227824  hr: 0  min: 7  sec: 11\n",
      "epoch: 2  batch: 546 / 721  loss: 0.015571287363055379  hr: 0  min: 7  sec: 9\n",
      "epoch: 2  batch: 547 / 721  loss: 0.015551944015378119  hr: 0  min: 7  sec: 6\n",
      "epoch: 2  batch: 548 / 721  loss: 0.0156137052756864  hr: 0  min: 7  sec: 4\n",
      "epoch: 2  batch: 549 / 721  loss: 0.015589147448055306  hr: 0  min: 7  sec: 1\n",
      "epoch: 2  batch: 550 / 721  loss: 0.015570280491625784  hr: 0  min: 6  sec: 59\n",
      "epoch: 2  batch: 551 / 721  loss: 0.015543920571571735  hr: 0  min: 6  sec: 56\n",
      "epoch: 2  batch: 552 / 721  loss: 0.015519856026121883  hr: 0  min: 6  sec: 54\n",
      "epoch: 2  batch: 553 / 721  loss: 0.015495659056399923  hr: 0  min: 6  sec: 52\n",
      "epoch: 2  batch: 554 / 721  loss: 0.01547756768550145  hr: 0  min: 6  sec: 49\n",
      "epoch: 2  batch: 555 / 721  loss: 0.015450768842850078  hr: 0  min: 6  sec: 47\n",
      "epoch: 2  batch: 556 / 721  loss: 0.015425164666189204  hr: 0  min: 6  sec: 44\n",
      "epoch: 2  batch: 557 / 721  loss: 0.015398990856798652  hr: 0  min: 6  sec: 42\n",
      "epoch: 2  batch: 558 / 721  loss: 0.015375732098983857  hr: 0  min: 6  sec: 39\n",
      "epoch: 2  batch: 559 / 721  loss: 0.015349862726934962  hr: 0  min: 6  sec: 37\n",
      "epoch: 2  batch: 560 / 721  loss: 0.01538103906676562  hr: 0  min: 6  sec: 34\n",
      "epoch: 2  batch: 561 / 721  loss: 0.015354648620965031  hr: 0  min: 6  sec: 32\n",
      "epoch: 2  batch: 562 / 721  loss: 0.015328665786926461  hr: 0  min: 6  sec: 29\n",
      "epoch: 2  batch: 563 / 721  loss: 0.01530225257452883  hr: 0  min: 6  sec: 27\n",
      "epoch: 2  batch: 564 / 721  loss: 0.015275893260832486  hr: 0  min: 6  sec: 24\n",
      "epoch: 2  batch: 565 / 721  loss: 0.015250793432977063  hr: 0  min: 6  sec: 22\n",
      "epoch: 2  batch: 566 / 721  loss: 0.015258580617973883  hr: 0  min: 6  sec: 19\n",
      "epoch: 2  batch: 567 / 721  loss: 0.015232520429564807  hr: 0  min: 6  sec: 17\n",
      "epoch: 2  batch: 568 / 721  loss: 0.015206225932904001  hr: 0  min: 6  sec: 15\n",
      "epoch: 2  batch: 569 / 721  loss: 0.015180114784342117  hr: 0  min: 6  sec: 12\n",
      "epoch: 2  batch: 570 / 721  loss: 0.015155830173413657  hr: 0  min: 6  sec: 10\n",
      "epoch: 2  batch: 571 / 721  loss: 0.015188252717658087  hr: 0  min: 6  sec: 7\n",
      "epoch: 2  batch: 572 / 721  loss: 0.015163575714462502  hr: 0  min: 6  sec: 5\n",
      "epoch: 2  batch: 573 / 721  loss: 0.01513960567016484  hr: 0  min: 6  sec: 2\n",
      "epoch: 2  batch: 574 / 721  loss: 0.015146641329020397  hr: 0  min: 6  sec: 0\n",
      "epoch: 2  batch: 575 / 721  loss: 0.01513530582249033  hr: 0  min: 5  sec: 57\n",
      "epoch: 2  batch: 576 / 721  loss: 0.015113656204739022  hr: 0  min: 5  sec: 55\n",
      "epoch: 2  batch: 577 / 721  loss: 0.015087995217052112  hr: 0  min: 5  sec: 53\n",
      "epoch: 2  batch: 578 / 721  loss: 0.015062844009020516  hr: 0  min: 5  sec: 50\n",
      "epoch: 2  batch: 579 / 721  loss: 0.015038292108164254  hr: 0  min: 5  sec: 48\n",
      "epoch: 2  batch: 580 / 721  loss: 0.015014364094569263  hr: 0  min: 5  sec: 45\n",
      "epoch: 2  batch: 581 / 721  loss: 0.01498923134497275  hr: 0  min: 5  sec: 43\n",
      "epoch: 2  batch: 582 / 721  loss: 0.014964348434478495  hr: 0  min: 5  sec: 40\n",
      "epoch: 2  batch: 583 / 721  loss: 0.014939078587589296  hr: 0  min: 5  sec: 38\n",
      "epoch: 2  batch: 584 / 721  loss: 0.014914770139873563  hr: 0  min: 5  sec: 35\n",
      "epoch: 2  batch: 585 / 721  loss: 0.014893910715952974  hr: 0  min: 5  sec: 33\n",
      "epoch: 2  batch: 586 / 721  loss: 0.014870771137669618  hr: 0  min: 5  sec: 31\n",
      "epoch: 2  batch: 587 / 721  loss: 0.014920098993346056  hr: 0  min: 5  sec: 28\n",
      "epoch: 2  batch: 588 / 721  loss: 0.014896062776203513  hr: 0  min: 5  sec: 26\n",
      "epoch: 2  batch: 589 / 721  loss: 0.014871202014352164  hr: 0  min: 5  sec: 23\n",
      "epoch: 2  batch: 590 / 721  loss: 0.014853043123767454  hr: 0  min: 5  sec: 21\n",
      "epoch: 2  batch: 591 / 721  loss: 0.014829445727706383  hr: 0  min: 5  sec: 18\n",
      "epoch: 2  batch: 592 / 721  loss: 0.014849355359053112  hr: 0  min: 5  sec: 16\n",
      "epoch: 2  batch: 593 / 721  loss: 0.01482485069261507  hr: 0  min: 5  sec: 14\n",
      "epoch: 2  batch: 594 / 721  loss: 0.01492127395207907  hr: 0  min: 5  sec: 11\n",
      "epoch: 2  batch: 595 / 721  loss: 0.014896951383994717  hr: 0  min: 5  sec: 9\n",
      "epoch: 2  batch: 596 / 721  loss: 0.014874459063669338  hr: 0  min: 5  sec: 6\n",
      "epoch: 2  batch: 597 / 721  loss: 0.014850668254180384  hr: 0  min: 5  sec: 4\n",
      "epoch: 2  batch: 598 / 721  loss: 0.014836226985495391  hr: 0  min: 5  sec: 1\n",
      "epoch: 2  batch: 599 / 721  loss: 0.014823187753584493  hr: 0  min: 4  sec: 59\n",
      "epoch: 2  batch: 600 / 721  loss: 0.014880223312975432  hr: 0  min: 4  sec: 56\n",
      "epoch: 2  batch: 601 / 721  loss: 0.014856018083965302  hr: 0  min: 4  sec: 54\n",
      "epoch: 2  batch: 602 / 721  loss: 0.014847398849858874  hr: 0  min: 4  sec: 52\n",
      "epoch: 2  batch: 603 / 721  loss: 0.01482416637007803  hr: 0  min: 4  sec: 49\n",
      "epoch: 2  batch: 604 / 721  loss: 0.014800764278273868  hr: 0  min: 4  sec: 47\n",
      "epoch: 2  batch: 605 / 721  loss: 0.014777241876887153  hr: 0  min: 4  sec: 44\n",
      "epoch: 2  batch: 606 / 721  loss: 0.01475467688851195  hr: 0  min: 4  sec: 42\n",
      "epoch: 2  batch: 607 / 721  loss: 0.014732798283253325  hr: 0  min: 4  sec: 39\n",
      "epoch: 2  batch: 608 / 721  loss: 0.01472913013189052  hr: 0  min: 4  sec: 37\n",
      "epoch: 2  batch: 609 / 721  loss: 0.014714285402033728  hr: 0  min: 4  sec: 34\n",
      "epoch: 2  batch: 610 / 721  loss: 0.01469132069689861  hr: 0  min: 4  sec: 32\n",
      "epoch: 2  batch: 611 / 721  loss: 0.014692455030292857  hr: 0  min: 4  sec: 29\n",
      "epoch: 2  batch: 612 / 721  loss: 0.014679151418355116  hr: 0  min: 4  sec: 27\n",
      "epoch: 2  batch: 613 / 721  loss: 0.014655536676758082  hr: 0  min: 4  sec: 25\n",
      "epoch: 2  batch: 614 / 721  loss: 0.014632147113046612  hr: 0  min: 4  sec: 22\n",
      "epoch: 2  batch: 615 / 721  loss: 0.014609931540054107  hr: 0  min: 4  sec: 20\n",
      "epoch: 2  batch: 616 / 721  loss: 0.014587811424816764  hr: 0  min: 4  sec: 17\n",
      "epoch: 2  batch: 617 / 721  loss: 0.014643304877788733  hr: 0  min: 4  sec: 15\n",
      "epoch: 2  batch: 618 / 721  loss: 0.01462448812169684  hr: 0  min: 4  sec: 12\n",
      "epoch: 2  batch: 619 / 721  loss: 0.01460226523889609  hr: 0  min: 4  sec: 10\n",
      "epoch: 2  batch: 620 / 721  loss: 0.014579741820407142  hr: 0  min: 4  sec: 7\n",
      "epoch: 2  batch: 621 / 721  loss: 0.0145585789760696  hr: 0  min: 4  sec: 5\n",
      "epoch: 2  batch: 622 / 721  loss: 0.01453627314184554  hr: 0  min: 4  sec: 3\n",
      "epoch: 2  batch: 623 / 721  loss: 0.014513981282657493  hr: 0  min: 4  sec: 0\n",
      "epoch: 2  batch: 624 / 721  loss: 0.014494432699825083  hr: 0  min: 3  sec: 58\n",
      "epoch: 2  batch: 625 / 721  loss: 0.014524386437970679  hr: 0  min: 3  sec: 55\n",
      "epoch: 2  batch: 626 / 721  loss: 0.014516810140450772  hr: 0  min: 3  sec: 53\n",
      "epoch: 2  batch: 627 / 721  loss: 0.014494532519925747  hr: 0  min: 3  sec: 50\n",
      "epoch: 2  batch: 628 / 721  loss: 0.01447610557309875  hr: 0  min: 3  sec: 48\n",
      "epoch: 2  batch: 629 / 721  loss: 0.014456798415119772  hr: 0  min: 3  sec: 45\n",
      "epoch: 2  batch: 630 / 721  loss: 0.014438117257518498  hr: 0  min: 3  sec: 43\n",
      "epoch: 2  batch: 631 / 721  loss: 0.014417692952207382  hr: 0  min: 3  sec: 40\n",
      "epoch: 2  batch: 632 / 721  loss: 0.014396854695912191  hr: 0  min: 3  sec: 38\n",
      "epoch: 2  batch: 633 / 721  loss: 0.014375205288002894  hr: 0  min: 3  sec: 35\n",
      "epoch: 2  batch: 634 / 721  loss: 0.014355401927520347  hr: 0  min: 3  sec: 33\n",
      "epoch: 2  batch: 635 / 721  loss: 0.014333709226506414  hr: 0  min: 3  sec: 30\n",
      "epoch: 2  batch: 636 / 721  loss: 0.01431619590707297  hr: 0  min: 3  sec: 28\n",
      "epoch: 2  batch: 637 / 721  loss: 0.014295390813477214  hr: 0  min: 3  sec: 26\n",
      "epoch: 2  batch: 638 / 721  loss: 0.01427339241690275  hr: 0  min: 3  sec: 23\n",
      "epoch: 2  batch: 639 / 721  loss: 0.014287665705764516  hr: 0  min: 3  sec: 21\n",
      "epoch: 2  batch: 640 / 721  loss: 0.014266470898826355  hr: 0  min: 3  sec: 18\n",
      "epoch: 2  batch: 641 / 721  loss: 0.01426734861661671  hr: 0  min: 3  sec: 16\n",
      "epoch: 2  batch: 642 / 721  loss: 0.01424698801938547  hr: 0  min: 3  sec: 13\n",
      "epoch: 2  batch: 643 / 721  loss: 0.014225611194589738  hr: 0  min: 3  sec: 11\n",
      "epoch: 2  batch: 644 / 721  loss: 0.014501113682537993  hr: 0  min: 3  sec: 8\n",
      "epoch: 2  batch: 645 / 721  loss: 0.014479858841457811  hr: 0  min: 3  sec: 6\n",
      "epoch: 2  batch: 646 / 721  loss: 0.014458377548408657  hr: 0  min: 3  sec: 3\n",
      "epoch: 2  batch: 647 / 721  loss: 0.014436582230301656  hr: 0  min: 3  sec: 1\n",
      "epoch: 2  batch: 648 / 721  loss: 0.014423254801414136  hr: 0  min: 2  sec: 59\n",
      "epoch: 2  batch: 649 / 721  loss: 0.014402820589422204  hr: 0  min: 2  sec: 56\n",
      "epoch: 2  batch: 650 / 721  loss: 0.014394243080068219  hr: 0  min: 2  sec: 54\n",
      "epoch: 2  batch: 651 / 721  loss: 0.014372827597584317  hr: 0  min: 2  sec: 51\n",
      "epoch: 2  batch: 652 / 721  loss: 0.01435130928982786  hr: 0  min: 2  sec: 49\n",
      "epoch: 2  batch: 653 / 721  loss: 0.014331989843042401  hr: 0  min: 2  sec: 46\n",
      "epoch: 2  batch: 654 / 721  loss: 0.014310721744761773  hr: 0  min: 2  sec: 44\n",
      "epoch: 2  batch: 655 / 721  loss: 0.014290359184865303  hr: 0  min: 2  sec: 41\n",
      "epoch: 2  batch: 656 / 721  loss: 0.014268816339752936  hr: 0  min: 2  sec: 39\n",
      "epoch: 2  batch: 657 / 721  loss: 0.014247688279266854  hr: 0  min: 2  sec: 36\n",
      "epoch: 2  batch: 658 / 721  loss: 0.014227546171158624  hr: 0  min: 2  sec: 34\n",
      "epoch: 2  batch: 659 / 721  loss: 0.014206263534309132  hr: 0  min: 2  sec: 32\n",
      "epoch: 2  batch: 660 / 721  loss: 0.014187026551911858  hr: 0  min: 2  sec: 29\n",
      "epoch: 2  batch: 661 / 721  loss: 0.014166285304502608  hr: 0  min: 2  sec: 27\n",
      "epoch: 2  batch: 662 / 721  loss: 0.014147483600087494  hr: 0  min: 2  sec: 24\n",
      "epoch: 2  batch: 663 / 721  loss: 0.0141523459905155  hr: 0  min: 2  sec: 22\n",
      "epoch: 2  batch: 664 / 721  loss: 0.014137417680991261  hr: 0  min: 2  sec: 19\n",
      "epoch: 2  batch: 665 / 721  loss: 0.014116523248400396  hr: 0  min: 2  sec: 17\n",
      "epoch: 2  batch: 666 / 721  loss: 0.014102134460164426  hr: 0  min: 2  sec: 15\n",
      "epoch: 2  batch: 667 / 721  loss: 0.014143820503875219  hr: 0  min: 2  sec: 12\n",
      "epoch: 2  batch: 668 / 721  loss: 0.014343281988467805  hr: 0  min: 2  sec: 10\n",
      "epoch: 2  batch: 669 / 721  loss: 0.014325158497433387  hr: 0  min: 2  sec: 7\n",
      "epoch: 2  batch: 670 / 721  loss: 0.01430564032342596  hr: 0  min: 2  sec: 5\n",
      "epoch: 2  batch: 671 / 721  loss: 0.014284819275186825  hr: 0  min: 2  sec: 2\n",
      "epoch: 2  batch: 672 / 721  loss: 0.014267965168799145  hr: 0  min: 2  sec: 0\n",
      "epoch: 2  batch: 673 / 721  loss: 0.01429706873778656  hr: 0  min: 1  sec: 57\n",
      "epoch: 2  batch: 674 / 721  loss: 0.014276368629251858  hr: 0  min: 1  sec: 55\n",
      "epoch: 2  batch: 675 / 721  loss: 0.01431838184326706  hr: 0  min: 1  sec: 52\n",
      "epoch: 2  batch: 676 / 721  loss: 0.01430330621692331  hr: 0  min: 1  sec: 50\n",
      "epoch: 2  batch: 677 / 721  loss: 0.01428349401625009  hr: 0  min: 1  sec: 48\n",
      "epoch: 2  batch: 678 / 721  loss: 0.014314707557561826  hr: 0  min: 1  sec: 45\n",
      "epoch: 2  batch: 679 / 721  loss: 0.014296152445409068  hr: 0  min: 1  sec: 43\n",
      "epoch: 2  batch: 680 / 721  loss: 0.014277212501078525  hr: 0  min: 1  sec: 40\n",
      "epoch: 2  batch: 681 / 721  loss: 0.0142631898428037  hr: 0  min: 1  sec: 38\n",
      "epoch: 2  batch: 682 / 721  loss: 0.014257344271744177  hr: 0  min: 1  sec: 35\n",
      "epoch: 2  batch: 683 / 721  loss: 0.014279296860892014  hr: 0  min: 1  sec: 33\n",
      "epoch: 2  batch: 684 / 721  loss: 0.014259835602946655  hr: 0  min: 1  sec: 30\n",
      "epoch: 2  batch: 685 / 721  loss: 0.0144494406674053  hr: 0  min: 1  sec: 28\n",
      "epoch: 2  batch: 686 / 721  loss: 0.014433460118582608  hr: 0  min: 1  sec: 25\n",
      "epoch: 2  batch: 687 / 721  loss: 0.014415503850211732  hr: 0  min: 1  sec: 23\n",
      "epoch: 2  batch: 688 / 721  loss: 0.014394878870969605  hr: 0  min: 1  sec: 21\n",
      "epoch: 2  batch: 689 / 721  loss: 0.014412223574568478  hr: 0  min: 1  sec: 18\n",
      "epoch: 2  batch: 690 / 721  loss: 0.01439188423922304  hr: 0  min: 1  sec: 16\n",
      "epoch: 2  batch: 691 / 721  loss: 0.014371690481384208  hr: 0  min: 1  sec: 13\n",
      "epoch: 2  batch: 692 / 721  loss: 0.014354263292892612  hr: 0  min: 1  sec: 11\n",
      "epoch: 2  batch: 693 / 721  loss: 0.014339422281496116  hr: 0  min: 1  sec: 8\n",
      "epoch: 2  batch: 694 / 721  loss: 0.014324490822210786  hr: 0  min: 1  sec: 6\n",
      "epoch: 2  batch: 695 / 721  loss: 0.014307272355706621  hr: 0  min: 1  sec: 3\n",
      "epoch: 2  batch: 696 / 721  loss: 0.014320566018388239  hr: 0  min: 1  sec: 1\n",
      "epoch: 2  batch: 697 / 721  loss: 0.014303780292991166  hr: 0  min: 0  sec: 59\n",
      "epoch: 2  batch: 698 / 721  loss: 0.014285640447681292  hr: 0  min: 0  sec: 56\n",
      "epoch: 2  batch: 699 / 721  loss: 0.014265934076609116  hr: 0  min: 0  sec: 54\n",
      "epoch: 2  batch: 700 / 721  loss: 0.014292620185577627  hr: 0  min: 0  sec: 51\n",
      "epoch: 2  batch: 701 / 721  loss: 0.01427318911247622  hr: 0  min: 0  sec: 49\n",
      "epoch: 2  batch: 702 / 721  loss: 0.014253857696411566  hr: 0  min: 0  sec: 46\n",
      "epoch: 2  batch: 703 / 721  loss: 0.01423469252104546  hr: 0  min: 0  sec: 44\n",
      "epoch: 2  batch: 704 / 721  loss: 0.014215289402138544  hr: 0  min: 0  sec: 41\n",
      "epoch: 2  batch: 705 / 721  loss: 0.014197023970383329  hr: 0  min: 0  sec: 39\n",
      "epoch: 2  batch: 706 / 721  loss: 0.014178458903353479  hr: 0  min: 0  sec: 36\n",
      "epoch: 2  batch: 707 / 721  loss: 0.014162029162451642  hr: 0  min: 0  sec: 34\n",
      "epoch: 2  batch: 708 / 721  loss: 0.014167371406290192  hr: 0  min: 0  sec: 31\n",
      "epoch: 2  batch: 709 / 721  loss: 0.014147898046513188  hr: 0  min: 0  sec: 29\n",
      "epoch: 2  batch: 710 / 721  loss: 0.014134538014496031  hr: 0  min: 0  sec: 27\n",
      "epoch: 2  batch: 711 / 721  loss: 0.014225869132570563  hr: 0  min: 0  sec: 24\n",
      "epoch: 2  batch: 712 / 721  loss: 0.014206642351975175  hr: 0  min: 0  sec: 22\n",
      "epoch: 2  batch: 713 / 721  loss: 0.014190658232992561  hr: 0  min: 0  sec: 19\n",
      "epoch: 2  batch: 714 / 721  loss: 0.014254500255582078  hr: 0  min: 0  sec: 17\n",
      "epoch: 2  batch: 715 / 721  loss: 0.01445208466541587  hr: 0  min: 0  sec: 14\n",
      "epoch: 2  batch: 716 / 721  loss: 0.01465494788796945  hr: 0  min: 0  sec: 12\n",
      "epoch: 2  batch: 717 / 721  loss: 0.01463733985170719  hr: 0  min: 0  sec: 9\n",
      "epoch: 2  batch: 718 / 721  loss: 0.014624216713733672  hr: 0  min: 0  sec: 7\n",
      "epoch: 2  batch: 719 / 721  loss: 0.014606626852596763  hr: 0  min: 0  sec: 4\n",
      "epoch: 2  batch: 720 / 721  loss: 0.014591979564556823  hr: 0  min: 0  sec: 2\n",
      "epoch: 2  batch: 721 / 721  loss: 0.014574005959366837  hr: 0  min: 0  sec: 0\n",
      "CPU times: total: 22min 57s\n",
      "Wall time: 1h 30min 22s\n"
     ]
    }
   ],
   "source": [
    "%time train_model_ATE(train_loader, 3)  #Tree epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emink\\AppData\\Local\\Temp\\ipykernel_33692\\1419488891.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(path), strict=False)\n"
     ]
    }
   ],
   "source": [
    "model_ATE = load_model(model_ATE, 'bert_ATE.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sentence_ATE(sentence, tokenizer, model_ATE, device=DEVICE):\n",
    "    \"\"\"\n",
    "    Test the ATE model with a single sentence and print the predictions.\n",
    "\n",
    "    Args:\n",
    "        sentence (str): The input sentence.\n",
    "        tokenizer: The tokenizer used during training.\n",
    "        model_ATE: The trained ATE model.\n",
    "        device: The device to run the model on ('cpu' or 'cuda').\n",
    "\n",
    "    Returns:\n",
    "        List of predicted tags for the input sentence.\n",
    "    \"\"\"\n",
    "    model_ATE.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    # Tokenize the input sentence\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    input_ids_tensor = torch.tensor([input_ids]).to(device)\n",
    "    attention_mask = torch.tensor([[1] * len(input_ids)]).to(device)\n",
    "\n",
    "    # Make predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model_ATE(ids_tensors=input_ids_tensor, tags_tensors=None, masks_tensors=attention_mask)\n",
    "        _, predictions = torch.max(outputs, dim=2)\n",
    "\n",
    "    # Convert predictions to tags\n",
    "    predicted_tags = predictions.squeeze().tolist()\n",
    "    token_tag_pairs = list(zip(tokens, predicted_tags))\n",
    "\n",
    "    print(\"Sentence:\", sentence)\n",
    "    print(\"Predictions:\")\n",
    "    for token, tag in token_tag_pairs:\n",
    "        print(f\"Token: {token}, Predicted Tag: {tag}\")\n",
    "\n",
    "    return token_tag_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The food was amazing but the service was terrible.\n",
      "Predictions:\n",
      "Token: the, Predicted Tag: 0\n",
      "Token: food, Predicted Tag: 1\n",
      "Token: was, Predicted Tag: 0\n",
      "Token: amazing, Predicted Tag: 0\n",
      "Token: but, Predicted Tag: 0\n",
      "Token: the, Predicted Tag: 0\n",
      "Token: service, Predicted Tag: 1\n",
      "Token: was, Predicted Tag: 0\n",
      "Token: terrible, Predicted Tag: 0\n",
      "Token: ., Predicted Tag: 0\n",
      "Sentence: The pasta was delicious, but the service was slow.\n",
      "Predictions:\n",
      "Token: the, Predicted Tag: 0\n",
      "Token: pasta, Predicted Tag: 1\n",
      "Token: was, Predicted Tag: 0\n",
      "Token: delicious, Predicted Tag: 0\n",
      "Token: ,, Predicted Tag: 0\n",
      "Token: but, Predicted Tag: 0\n",
      "Token: the, Predicted Tag: 0\n",
      "Token: service, Predicted Tag: 1\n",
      "Token: was, Predicted Tag: 0\n",
      "Token: slow, Predicted Tag: 0\n",
      "Token: ., Predicted Tag: 0\n",
      "Sentence: The ambiance was fantastic, but the food was overpriced.\n",
      "Predictions:\n",
      "Token: the, Predicted Tag: 0\n",
      "Token: am, Predicted Tag: 1\n",
      "Token: ##bian, Predicted Tag: 1\n",
      "Token: ##ce, Predicted Tag: 1\n",
      "Token: was, Predicted Tag: 0\n",
      "Token: fantastic, Predicted Tag: 0\n",
      "Token: ,, Predicted Tag: 0\n",
      "Token: but, Predicted Tag: 0\n",
      "Token: the, Predicted Tag: 0\n",
      "Token: food, Predicted Tag: 1\n",
      "Token: was, Predicted Tag: 0\n",
      "Token: over, Predicted Tag: 0\n",
      "Token: ##pr, Predicted Tag: 0\n",
      "Token: ##ice, Predicted Tag: 0\n",
      "Token: ##d, Predicted Tag: 0\n",
      "Token: ., Predicted Tag: 0\n",
      "Sentence: The waiter was very friendly, and the desserts were outstanding\n",
      "Predictions:\n",
      "Token: the, Predicted Tag: 0\n",
      "Token: waiter, Predicted Tag: 1\n",
      "Token: was, Predicted Tag: 0\n",
      "Token: very, Predicted Tag: 0\n",
      "Token: friendly, Predicted Tag: 0\n",
      "Token: ,, Predicted Tag: 0\n",
      "Token: and, Predicted Tag: 0\n",
      "Token: the, Predicted Tag: 0\n",
      "Token: dessert, Predicted Tag: 1\n",
      "Token: ##s, Predicted Tag: 1\n",
      "Token: were, Predicted Tag: 0\n",
      "Token: outstanding, Predicted Tag: 0\n"
     ]
    }
   ],
   "source": [
    "sentence = \"The food was amazing but the service was terrible.\"\n",
    "token_tag_pairs = test_sentence_ATE(sentence, tokenizer, model_ATE)\n",
    "\n",
    "sentence = \"The pasta was delicious, but the service was slow.\"\n",
    "token_tag_pairs= test_sentence_ATE(sentence,tokenizer,model_ATE)\n",
    "\n",
    "sentence = \"The ambiance was fantastic, but the food was overpriced.\"\n",
    "token_tag_pairs= test_sentence_ATE(sentence,tokenizer,model_ATE)\n",
    "\n",
    "sentence = \"The waiter was very friendly, and the desserts were outstanding\"\n",
    "token_tag_pairs= test_sentence_ATE(sentence,tokenizer,model_ATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3min 45s\n",
      "Wall time: 2min 8s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     64196\n",
      "           1       0.92      0.81      0.86      4022\n",
      "           2       0.73      0.85      0.79      2141\n",
      "\n",
      "    accuracy                           0.98     70359\n",
      "   macro avg       0.88      0.88      0.88     70359\n",
      "weighted avg       0.98      0.98      0.98     70359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%time x, y = test_model_ATE(test_loader)\n",
    "print(classification_report(x, y, target_names=[str(i) for i in range(3)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aspect Based Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# restaurants_train_ds = dataset_ABSA(pd.read_csv(\"data/restaurants_train.csv\"), tokenizer)\n",
    "restaurants_train_ds = dataset_ABSA(pd.read_csv(\"data/ABSA5restaurants_train.csv\"), tokenizer)\n",
    "restaurants_test_ds = dataset_ABSA(pd.read_csv(\"data/restaurants_test.csv\"), tokenizer)\n",
    "restaurants_val_ds = dataset_ABSA(pd.read_csv(\"data/V1restaurants_test.csv\"), tokenizer)\n",
    "\n",
    "\n",
    "# restaurants_train_ds = dataset_ABSA(pd.read_csv(\"data/train_test.csv\"), tokenizer)\n",
    "# restaurants_test_ds = dataset_ABSA(pd.read_csv(\"data/test_test.csv\"), tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[cls]', 'i', 'went', 'there', 'in', 'late', 'afternoon', 'for', 'some', 'bite', 'size', 'food', 'and', 'ref', '##les', '##hm', '##ent', 'with', 'my', 'date', '.', '[sep]', 'food']\n",
      "23\n",
      "tensor([  100,  1045,  2253,  2045,  1999,  2397,  5027,  2005,  2070,  6805,\n",
      "         2946,  2833,  1998, 25416,  4244, 14227,  4765,  2007,  2026,  3058,\n",
      "         1012,   100,  2833])\n",
      "23\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
      "23\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "w,x,y,z = restaurants_train_ds.__getitem__(121)\n",
    "print(w)\n",
    "print(len(w))\n",
    "print(x)\n",
    "print(len(x))\n",
    "print(y)\n",
    "print(len(y))\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mini_batch2(samples):\n",
    "    # Find the max length in the current batch\n",
    "    max_len = max([len(s[1]) for s in samples])\n",
    "\n",
    "    ids_tensors = [torch.cat([s[1], torch.zeros(max_len - len(s[1]), dtype=torch.long)]) for s in samples]\n",
    "    ids_tensors = torch.stack(ids_tensors)\n",
    "\n",
    "    segments_tensors = [torch.cat([s[2], torch.zeros(max_len - len(s[2]), dtype=torch.long)]) for s in samples]\n",
    "    segments_tensors = torch.stack(segments_tensors)\n",
    "\n",
    "    label_ids = torch.stack([s[3] for s in samples])\n",
    "    \n",
    "    masks_tensors = torch.zeros(ids_tensors.shape, dtype=torch.long)\n",
    "    masks_tensors = masks_tensors.masked_fill(ids_tensors != 0, 1)\n",
    "\n",
    "    return ids_tensors, segments_tensors, masks_tensors, label_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds = ConcatDataset([laptops_train_ds, restaurants_train_ds, twitter_train_ds])\n",
    "# test_ds = ConcatDataset([laptops_test_ds, restaurants_test_ds, twitter_test_ds])\n",
    "\n",
    "# train_ds = restaurants_train_ds\n",
    "# test_ds = restaurants_test_ds\n",
    "\n",
    "\n",
    "# train_loader = DataLoader(train_ds, batch_size=4, collate_fn=create_mini_batch2, shuffle = True)\n",
    "# test_loader = DataLoader(test_ds, batch_size=50, collate_fn=create_mini_batch2, shuffle = True)\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# Split the training dataset into training and validation sets\n",
    "\n",
    "\n",
    "# test_size = int(0.5 * len(restaurants_test_ds))\n",
    "# val_size = len(restaurants_test_ds) - test_size\n",
    "# test_ds, validation_ds = random_split(restaurants_test_ds, [test_size, val_size])\n",
    "\n",
    "train_ds = restaurants_train_ds\n",
    "test_ds = restaurants_test_ds\n",
    "validation_ds = restaurants_val_ds\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_ds, batch_size=16, collate_fn=create_mini_batch2, shuffle=True)\n",
    "validation_loader = DataLoader(validation_ds, batch_size=32, collate_fn=create_mini_batch2, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=50, collate_fn=create_mini_batch2, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in train_loader:\n",
    "#     w,x,y,z = batch\n",
    "#     print(w)\n",
    "#     print(w.size())\n",
    "#     print(x)\n",
    "#     print(x.size())\n",
    "#     print(y)\n",
    "#     print(y.size())\n",
    "#     print(z)\n",
    "#     print(z.size())\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "# def train_model_ABSA(loader, epochs):\n",
    "#     all_data = len(loader)\n",
    "#     for epoch in range(epochs):\n",
    "#         finish_data = 0\n",
    "#         losses = []\n",
    "#         current_times = []\n",
    "#         correct_predictions = 0\n",
    "        \n",
    "#         for data in loader:\n",
    "#             t0 = time.time()\n",
    "#             ids_tensors, segments_tensors, masks_tensors, label_ids = data\n",
    "#             ids_tensors = ids_tensors.to(DEVICE)\n",
    "#             segments_tensors = segments_tensors.to(DEVICE)\n",
    "#             label_ids = label_ids.to(DEVICE)\n",
    "#             masks_tensors = masks_tensors.to(DEVICE)\n",
    "\n",
    "#             loss = model_ABSA(ids_tensors=ids_tensors, lable_tensors=label_ids, masks_tensors=masks_tensors, segments_tensors=segments_tensors)\n",
    "#             losses.append(loss.item())\n",
    "#             loss.backward()\n",
    "#             optimizer_ABSA.step()\n",
    "#             optimizer_ABSA.zero_grad()\n",
    "\n",
    "#             finish_data += 1\n",
    "#             current_times.append(round(time.time()-t0,3))\n",
    "#             current = np.mean(current_times)\n",
    "#             hr, min, sec = evl_time(current*(all_data-finish_data) + current*all_data*(epochs-epoch-1))\n",
    "#             print('epoch:', epoch, \" batch:\", finish_data, \"/\" , all_data, \" loss:\", np.mean(losses), \" hr:\", hr, \" min:\", min,\" sec:\", sec)         \n",
    "\n",
    "#         save_model(model_ABSA, 'bert_ABSA3.pkl')\n",
    "#############################################################################\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "def validate_model_ABSA(loader):\n",
    "    model_ABSA.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            ids_tensors, segments_tensors, masks_tensors, label_ids = data\n",
    "            ids_tensors = ids_tensors.to(DEVICE)\n",
    "            segments_tensors = segments_tensors.to(DEVICE)\n",
    "            label_ids = label_ids.to(DEVICE)\n",
    "            masks_tensors = masks_tensors.to(DEVICE)\n",
    "\n",
    "            # Compute the loss during validation\n",
    "            loss = model_ABSA(ids_tensors=ids_tensors, lable_tensors=label_ids, masks_tensors=masks_tensors, segments_tensors=segments_tensors)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    # Return the average validation loss\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "\n",
    "def train_model_ABSA(loader, validation_loader, epochs):\n",
    "\n",
    "    total_steps = len(loader) * epochs\n",
    "    warmup_steps = int(0.1 * total_steps)  # 10% warmup\n",
    "\n",
    "    # Create the scheduler\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer_ABSA,\n",
    "        num_warmup_steps=warmup_steps,\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "\n",
    "    all_data = len(loader)\n",
    "    best_loss = float('inf')\n",
    "    patience = 10\n",
    "    early_stop_counter = 0\n",
    "\n",
    "    # Scheduler\n",
    "    #scheduler = StepLR(optimizer_ABSA, step_size=1, gamma=0.9)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        finish_data = 0\n",
    "        losses = []\n",
    "        current_times = []\n",
    "        \n",
    "        model_ABSA.train()  # Ensure model is in training mode\n",
    "        for data in loader:\n",
    "            t0 = time.time()\n",
    "            ids_tensors, segments_tensors, masks_tensors, label_ids = data\n",
    "            ids_tensors = ids_tensors.to(DEVICE)\n",
    "            segments_tensors = segments_tensors.to(DEVICE)\n",
    "            label_ids = label_ids.to(DEVICE)\n",
    "            masks_tensors = masks_tensors.to(DEVICE)\n",
    "\n",
    "            loss = model_ABSA(ids_tensors=ids_tensors, lable_tensors=label_ids, masks_tensors=masks_tensors, segments_tensors=segments_tensors)\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "\n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model_ABSA.parameters(), max_norm=1.0)\n",
    "\n",
    "            optimizer_ABSA.step()\n",
    "\n",
    "            scheduler.step() #get_linear_schedule_with_warmup\n",
    "\n",
    "            optimizer_ABSA.zero_grad()\n",
    "\n",
    "            finish_data += 1\n",
    "            current_times.append(round(time.time() - t0, 3))\n",
    "            current = np.mean(current_times)\n",
    "            hr, min, sec = evl_time(current * (all_data - finish_data) + current * all_data * (epochs - epoch - 1))\n",
    "            print('epoch:', epoch, \" batch:\", finish_data, \"/\", all_data, \" loss:\", np.mean(losses), \" hr:\", hr, \" min:\", min, \" sec:\", sec)\n",
    "\n",
    "            # Periodic validation within the epoch\n",
    "            if finish_data % 100 == 0:\n",
    "                val_loss = validate_model_ABSA(validation_loader)\n",
    "                print(f\"Validation Loss after {finish_data} batches: {val_loss}\")\n",
    "\n",
    "        # Print learning rate\n",
    "        for param_group in optimizer_ABSA.param_groups:\n",
    "            print(f\"Learning rate: {param_group['lr']}\")\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        val_loss = validate_model_ABSA(validation_loader)\n",
    "        print(val_loss)\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            early_stop_counter = 0\n",
    "            save_model(model_ABSA, 'bert_ABSA6.pkl')\n",
    "            print(\"Saving...\")\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "            if early_stop_counter >= patience:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "\n",
    "        # Step scheduler\n",
    "        #sscheduler.step()\n",
    "\n",
    "\n",
    "\n",
    "def test_model_ABSA(loader):\n",
    "    pred = []\n",
    "    trueth = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "\n",
    "            ids_tensors, segments_tensors, masks_tensors, label_ids = data\n",
    "            ids_tensors = ids_tensors.to(DEVICE)\n",
    "            segments_tensors = segments_tensors.to(DEVICE)\n",
    "            masks_tensors = masks_tensors.to(DEVICE)\n",
    "\n",
    "            outputs = model_ABSA(ids_tensors, None, masks_tensors=masks_tensors, segments_tensors=segments_tensors)\n",
    "            \n",
    "            _, predictions = torch.max(outputs, dim=1)\n",
    "\n",
    "            pred += list([int(i) for i in predictions])\n",
    "            trueth += list([int(i) for i in label_ids])\n",
    "\n",
    "    return trueth, pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  batch: 1 / 122  loss: 1.2386082410812378  hr: 5  min: 1  sec: 43\n",
      "epoch: 0  batch: 2 / 122  loss: 1.3027727603912354  hr: 4  min: 2  sec: 30\n",
      "epoch: 0  batch: 3 / 122  loss: 1.2826074361801147  hr: 3  min: 43  sec: 47\n",
      "epoch: 0  batch: 4 / 122  loss: 1.2728183567523956  hr: 3  min: 43  sec: 9\n",
      "epoch: 0  batch: 5 / 122  loss: 1.2616460561752318  hr: 3  min: 52  sec: 24\n",
      "epoch: 0  batch: 6 / 122  loss: 1.2394850850105286  hr: 3  min: 41  sec: 40\n",
      "epoch: 0  batch: 7 / 122  loss: 1.2411294834954398  hr: 3  min: 37  sec: 41\n",
      "epoch: 0  batch: 8 / 122  loss: 1.2542251497507095  hr: 3  min: 34  sec: 51\n",
      "epoch: 0  batch: 9 / 122  loss: 1.2320403258005779  hr: 3  min: 27  sec: 31\n",
      "epoch: 0  batch: 10 / 122  loss: 1.2267006158828735  hr: 3  min: 29  sec: 33\n",
      "epoch: 0  batch: 11 / 122  loss: 1.2286709980531172  hr: 3  min: 32  sec: 28\n",
      "epoch: 0  batch: 12 / 122  loss: 1.222141255935033  hr: 3  min: 33  sec: 42\n",
      "epoch: 0  batch: 13 / 122  loss: 1.2278896386806781  hr: 3  min: 32  sec: 0\n",
      "epoch: 0  batch: 14 / 122  loss: 1.2232933385031564  hr: 3  min: 27  sec: 40\n",
      "epoch: 0  batch: 15 / 122  loss: 1.2183933814366659  hr: 3  min: 29  sec: 4\n",
      "epoch: 0  batch: 16 / 122  loss: 1.22765501588583  hr: 3  min: 28  sec: 8\n",
      "epoch: 0  batch: 17 / 122  loss: 1.2190747892155367  hr: 3  min: 38  sec: 21\n",
      "epoch: 0  batch: 18 / 122  loss: 1.2133344146940443  hr: 3  min: 38  sec: 9\n",
      "epoch: 0  batch: 19 / 122  loss: 1.2168098813609074  hr: 3  min: 36  sec: 19\n",
      "epoch: 0  batch: 20 / 122  loss: 1.2188021004199983  hr: 3  min: 35  sec: 42\n",
      "epoch: 0  batch: 21 / 122  loss: 1.228734981446039  hr: 3  min: 36  sec: 43\n",
      "epoch: 0  batch: 22 / 122  loss: 1.2268052317879417  hr: 3  min: 38  sec: 46\n",
      "epoch: 0  batch: 23 / 122  loss: 1.2349002361297607  hr: 3  min: 40  sec: 17\n",
      "epoch: 0  batch: 24 / 122  loss: 1.2352771361668904  hr: 3  min: 43  sec: 54\n",
      "epoch: 0  batch: 25 / 122  loss: 1.2297000885009766  hr: 3  min: 43  sec: 17\n",
      "epoch: 0  batch: 26 / 122  loss: 1.2218838700881371  hr: 3  min: 41  sec: 27\n",
      "epoch: 0  batch: 27 / 122  loss: 1.219633314344618  hr: 3  min: 41  sec: 37\n",
      "epoch: 0  batch: 28 / 122  loss: 1.214613024677549  hr: 3  min: 40  sec: 38\n",
      "epoch: 0  batch: 29 / 122  loss: 1.2155621257321587  hr: 3  min: 39  sec: 47\n",
      "epoch: 0  batch: 30 / 122  loss: 1.2131824135780334  hr: 3  min: 39  sec: 38\n",
      "epoch: 0  batch: 31 / 122  loss: 1.2129382894885155  hr: 3  min: 37  sec: 41\n",
      "epoch: 0  batch: 32 / 122  loss: 1.2093443274497986  hr: 3  min: 36  sec: 9\n",
      "epoch: 0  batch: 33 / 122  loss: 1.2046581940217451  hr: 3  min: 34  sec: 39\n",
      "epoch: 0  batch: 34 / 122  loss: 1.2020536941640518  hr: 3  min: 32  sec: 23\n",
      "epoch: 0  batch: 35 / 122  loss: 1.199637256349836  hr: 3  min: 31  sec: 25\n",
      "epoch: 0  batch: 36 / 122  loss: 1.2020034061537848  hr: 3  min: 29  sec: 58\n",
      "epoch: 0  batch: 37 / 122  loss: 1.1959676613678802  hr: 3  min: 30  sec: 13\n",
      "epoch: 0  batch: 38 / 122  loss: 1.1949195453995152  hr: 3  min: 29  sec: 27\n",
      "epoch: 0  batch: 39 / 122  loss: 1.1917372941970825  hr: 3  min: 28  sec: 38\n",
      "epoch: 0  batch: 40 / 122  loss: 1.1901516526937486  hr: 3  min: 27  sec: 27\n",
      "epoch: 0  batch: 41 / 122  loss: 1.1868982111535422  hr: 3  min: 28  sec: 26\n",
      "epoch: 0  batch: 42 / 122  loss: 1.1861215971765064  hr: 3  min: 29  sec: 57\n",
      "epoch: 0  batch: 43 / 122  loss: 1.1826193637626117  hr: 3  min: 28  sec: 54\n",
      "epoch: 0  batch: 44 / 122  loss: 1.1812274158000946  hr: 3  min: 27  sec: 32\n",
      "epoch: 0  batch: 45 / 122  loss: 1.1789734496010675  hr: 3  min: 26  sec: 24\n",
      "epoch: 0  batch: 46 / 122  loss: 1.177032849063044  hr: 3  min: 25  sec: 24\n",
      "epoch: 0  batch: 47 / 122  loss: 1.1775185377039807  hr: 3  min: 24  sec: 27\n",
      "epoch: 0  batch: 48 / 122  loss: 1.1753021453817685  hr: 3  min: 25  sec: 14\n",
      "epoch: 0  batch: 49 / 122  loss: 1.1750928747410676  hr: 3  min: 24  sec: 12\n",
      "epoch: 0  batch: 50 / 122  loss: 1.1754159331321716  hr: 3  min: 23  sec: 42\n",
      "epoch: 0  batch: 51 / 122  loss: 1.1728491152034086  hr: 3  min: 23  sec: 9\n",
      "epoch: 0  batch: 52 / 122  loss: 1.17234700688949  hr: 3  min: 22  sec: 39\n",
      "epoch: 0  batch: 53 / 122  loss: 1.1711168649061672  hr: 3  min: 24  sec: 35\n",
      "epoch: 0  batch: 54 / 122  loss: 1.1692839198642306  hr: 3  min: 24  sec: 9\n",
      "epoch: 0  batch: 55 / 122  loss: 1.167270786112005  hr: 3  min: 23  sec: 16\n",
      "epoch: 0  batch: 56 / 122  loss: 1.1648741619927543  hr: 3  min: 23  sec: 12\n",
      "epoch: 0  batch: 57 / 122  loss: 1.1641139189402263  hr: 3  min: 22  sec: 20\n",
      "epoch: 0  batch: 58 / 122  loss: 1.1647824254529229  hr: 3  min: 22  sec: 32\n",
      "epoch: 0  batch: 59 / 122  loss: 1.163546000496816  hr: 3  min: 21  sec: 57\n",
      "epoch: 0  batch: 60 / 122  loss: 1.164304995536804  hr: 3  min: 21  sec: 4\n",
      "epoch: 0  batch: 61 / 122  loss: 1.1660782704587842  hr: 3  min: 20  sec: 54\n",
      "epoch: 0  batch: 62 / 122  loss: 1.164213409346919  hr: 3  min: 20  sec: 18\n",
      "epoch: 0  batch: 63 / 122  loss: 1.1641444913924686  hr: 3  min: 19  sec: 42\n",
      "epoch: 0  batch: 64 / 122  loss: 1.163238063454628  hr: 3  min: 18  sec: 38\n",
      "epoch: 0  batch: 65 / 122  loss: 1.163673784182622  hr: 3  min: 17  sec: 35\n",
      "epoch: 0  batch: 66 / 122  loss: 1.1627522074814998  hr: 3  min: 17  sec: 23\n",
      "epoch: 0  batch: 67 / 122  loss: 1.1617571844983456  hr: 3  min: 16  sec: 51\n",
      "epoch: 0  batch: 68 / 122  loss: 1.1615314360927134  hr: 3  min: 16  sec: 3\n",
      "epoch: 0  batch: 69 / 122  loss: 1.162019904109015  hr: 3  min: 15  sec: 45\n",
      "epoch: 0  batch: 70 / 122  loss: 1.1601303815841675  hr: 3  min: 15  sec: 37\n",
      "epoch: 0  batch: 71 / 122  loss: 1.1596284399569874  hr: 3  min: 17  sec: 3\n",
      "epoch: 0  batch: 72 / 122  loss: 1.1587943269146814  hr: 3  min: 16  sec: 31\n",
      "epoch: 0  batch: 73 / 122  loss: 1.1602016066851681  hr: 3  min: 16  sec: 29\n",
      "epoch: 0  batch: 74 / 122  loss: 1.1603660084105827  hr: 3  min: 16  sec: 20\n",
      "epoch: 0  batch: 75 / 122  loss: 1.1615548308690389  hr: 3  min: 16  sec: 12\n",
      "epoch: 0  batch: 76 / 122  loss: 1.1602199642281783  hr: 3  min: 16  sec: 32\n",
      "epoch: 0  batch: 77 / 122  loss: 1.1601790003962331  hr: 3  min: 17  sec: 17\n",
      "epoch: 0  batch: 78 / 122  loss: 1.1603467770111866  hr: 3  min: 18  sec: 46\n",
      "epoch: 0  batch: 79 / 122  loss: 1.1602083338966853  hr: 3  min: 20  sec: 10\n",
      "epoch: 0  batch: 80 / 122  loss: 1.1589553490281106  hr: 3  min: 19  sec: 47\n",
      "epoch: 0  batch: 81 / 122  loss: 1.1580605271421833  hr: 3  min: 19  sec: 32\n",
      "epoch: 0  batch: 82 / 122  loss: 1.159363899289108  hr: 3  min: 19  sec: 29\n",
      "epoch: 0  batch: 83 / 122  loss: 1.1588330714099377  hr: 3  min: 19  sec: 10\n",
      "epoch: 0  batch: 84 / 122  loss: 1.1591332114878155  hr: 3  min: 19  sec: 3\n",
      "epoch: 0  batch: 85 / 122  loss: 1.1600918180802289  hr: 3  min: 18  sec: 18\n",
      "epoch: 0  batch: 86 / 122  loss: 1.1587711933047273  hr: 3  min: 17  sec: 39\n",
      "epoch: 0  batch: 87 / 122  loss: 1.1577492486471417  hr: 3  min: 17  sec: 8\n",
      "epoch: 0  batch: 88 / 122  loss: 1.156984718008475  hr: 3  min: 16  sec: 32\n",
      "epoch: 0  batch: 89 / 122  loss: 1.157105973597323  hr: 3  min: 16  sec: 39\n",
      "epoch: 0  batch: 90 / 122  loss: 1.15716329548094  hr: 3  min: 16  sec: 56\n",
      "epoch: 0  batch: 91 / 122  loss: 1.1574252935556264  hr: 3  min: 16  sec: 38\n",
      "epoch: 0  batch: 92 / 122  loss: 1.1566486242024794  hr: 3  min: 16  sec: 3\n",
      "epoch: 0  batch: 93 / 122  loss: 1.1546372264944098  hr: 3  min: 15  sec: 33\n",
      "epoch: 0  batch: 94 / 122  loss: 1.1547482381475733  hr: 3  min: 15  sec: 2\n",
      "epoch: 0  batch: 95 / 122  loss: 1.1536096961874711  hr: 3  min: 14  sec: 31\n",
      "epoch: 0  batch: 96 / 122  loss: 1.1542563425997894  hr: 3  min: 13  sec: 48\n",
      "epoch: 0  batch: 97 / 122  loss: 1.1526652562249566  hr: 3  min: 13  sec: 25\n",
      "epoch: 0  batch: 98 / 122  loss: 1.1527570753681415  hr: 3  min: 13  sec: 32\n",
      "epoch: 0  batch: 99 / 122  loss: 1.152609858850036  hr: 3  min: 13  sec: 28\n",
      "epoch: 0  batch: 100 / 122  loss: 1.1519371712207793  hr: 3  min: 13  sec: 19\n",
      "Validation Loss after 100 batches: 1.1309990584850311\n",
      "epoch: 0  batch: 101 / 122  loss: 1.1509035093949573  hr: 3  min: 12  sec: 45\n",
      "epoch: 0  batch: 102 / 122  loss: 1.1501949230829875  hr: 3  min: 12  sec: 23\n",
      "epoch: 0  batch: 103 / 122  loss: 1.1501893221753314  hr: 3  min: 12  sec: 23\n",
      "epoch: 0  batch: 104 / 122  loss: 1.1497341726834958  hr: 3  min: 12  sec: 17\n",
      "epoch: 0  batch: 105 / 122  loss: 1.1489508753731137  hr: 3  min: 12  sec: 4\n",
      "epoch: 0  batch: 106 / 122  loss: 1.1474735180162035  hr: 3  min: 11  sec: 47\n",
      "epoch: 0  batch: 107 / 122  loss: 1.146617479970522  hr: 3  min: 11  sec: 17\n",
      "epoch: 0  batch: 108 / 122  loss: 1.146760959868078  hr: 3  min: 11  sec: 2\n",
      "epoch: 0  batch: 109 / 122  loss: 1.146505977582494  hr: 3  min: 10  sec: 34\n",
      "epoch: 0  batch: 110 / 122  loss: 1.1453130012208765  hr: 3  min: 10  sec: 11\n",
      "epoch: 0  batch: 111 / 122  loss: 1.1441294744208053  hr: 3  min: 9  sec: 43\n",
      "epoch: 0  batch: 112 / 122  loss: 1.142849228743996  hr: 3  min: 10  sec: 18\n",
      "epoch: 0  batch: 113 / 122  loss: 1.1426014441304502  hr: 3  min: 9  sec: 44\n",
      "epoch: 0  batch: 114 / 122  loss: 1.1411047326891046  hr: 3  min: 9  sec: 12\n",
      "epoch: 0  batch: 115 / 122  loss: 1.1406259951384172  hr: 3  min: 9  sec: 5\n",
      "epoch: 0  batch: 116 / 122  loss: 1.1398731295404763  hr: 3  min: 8  sec: 59\n",
      "epoch: 0  batch: 117 / 122  loss: 1.1390958912352211  hr: 3  min: 8  sec: 44\n",
      "epoch: 0  batch: 118 / 122  loss: 1.1378657449099978  hr: 3  min: 8  sec: 57\n",
      "epoch: 0  batch: 119 / 122  loss: 1.1372708457858622  hr: 3  min: 9  sec: 33\n",
      "epoch: 0  batch: 120 / 122  loss: 1.1371466691295307  hr: 3  min: 10  sec: 1\n",
      "epoch: 0  batch: 121 / 122  loss: 1.1372342764838668  hr: 3  min: 9  sec: 57\n",
      "epoch: 0  batch: 122 / 122  loss: 1.1365506116484032  hr: 3  min: 9  sec: 36\n",
      "Learning rate: 1.3333333333333333e-05\n",
      "Saving...\n",
      "epoch: 1  batch: 1 / 122  loss: 1.1272826194763184  hr: 3  min: 5  sec: 34\n",
      "epoch: 1  batch: 2 / 122  loss: 1.1568086743354797  hr: 3  min: 8  sec: 58\n",
      "epoch: 1  batch: 3 / 122  loss: 1.0847369035085042  hr: 3  min: 13  sec: 50\n",
      "epoch: 1  batch: 4 / 122  loss: 1.0428243577480316  hr: 3  min: 7  sec: 31\n",
      "epoch: 1  batch: 5 / 122  loss: 1.0365875482559204  hr: 3  min: 30  sec: 14\n",
      "epoch: 1  batch: 6 / 122  loss: 1.0509183406829834  hr: 3  min: 21  sec: 40\n",
      "epoch: 1  batch: 7 / 122  loss: 1.0622721399579729  hr: 3  min: 12  sec: 18\n",
      "epoch: 1  batch: 8 / 122  loss: 1.0711353570222855  hr: 3  min: 9  sec: 40\n",
      "epoch: 1  batch: 9 / 122  loss: 1.059286097685496  hr: 3  min: 10  sec: 1\n",
      "epoch: 1  batch: 10 / 122  loss: 1.0701272189617157  hr: 3  min: 20  sec: 31\n",
      "epoch: 1  batch: 11 / 122  loss: 1.08739526163448  hr: 3  min: 20  sec: 27\n",
      "epoch: 1  batch: 12 / 122  loss: 1.0940487335125606  hr: 3  min: 21  sec: 24\n",
      "epoch: 1  batch: 13 / 122  loss: 1.0920490622520447  hr: 3  min: 20  sec: 54\n",
      "epoch: 1  batch: 14 / 122  loss: 1.094428790467126  hr: 3  min: 17  sec: 58\n",
      "epoch: 1  batch: 15 / 122  loss: 1.0943317691485086  hr: 3  min: 16  sec: 26\n",
      "epoch: 1  batch: 16 / 122  loss: 1.0923318676650524  hr: 3  min: 16  sec: 3\n",
      "epoch: 1  batch: 17 / 122  loss: 1.0895977826679455  hr: 3  min: 14  sec: 18\n",
      "epoch: 1  batch: 18 / 122  loss: 1.098498327864541  hr: 3  min: 12  sec: 9\n",
      "epoch: 1  batch: 19 / 122  loss: 1.103108497042405  hr: 3  min: 10  sec: 22\n",
      "epoch: 1  batch: 20 / 122  loss: 1.103746846318245  hr: 3  min: 7  sec: 33\n",
      "epoch: 1  batch: 21 / 122  loss: 1.099396015916552  hr: 3  min: 7  sec: 34\n",
      "epoch: 1  batch: 22 / 122  loss: 1.0964815426956525  hr: 3  min: 7  sec: 36\n",
      "epoch: 1  batch: 23 / 122  loss: 1.0947544600652612  hr: 3  min: 6  sec: 27\n",
      "epoch: 1  batch: 24 / 122  loss: 1.096464954316616  hr: 3  min: 4  sec: 37\n",
      "epoch: 1  batch: 25 / 122  loss: 1.0969993233680726  hr: 3  min: 2  sec: 44\n",
      "epoch: 1  batch: 26 / 122  loss: 1.0952839369957263  hr: 3  min: 2  sec: 4\n",
      "epoch: 1  batch: 27 / 122  loss: 1.0973585468751412  hr: 3  min: 3  sec: 50\n",
      "epoch: 1  batch: 28 / 122  loss: 1.099523384656225  hr: 3  min: 2  sec: 3\n",
      "epoch: 1  batch: 29 / 122  loss: 1.1045702839719838  hr: 3  min: 2  sec: 56\n",
      "epoch: 1  batch: 30 / 122  loss: 1.1065478384494782  hr: 3  min: 4  sec: 54\n",
      "epoch: 1  batch: 31 / 122  loss: 1.1061962169985617  hr: 3  min: 3  sec: 47\n",
      "epoch: 1  batch: 32 / 122  loss: 1.1043950188905  hr: 3  min: 2  sec: 17\n",
      "epoch: 1  batch: 33 / 122  loss: 1.1072765679070444  hr: 3  min: 1  sec: 15\n",
      "epoch: 1  batch: 34 / 122  loss: 1.110685539596221  hr: 3  min: 0  sec: 8\n",
      "epoch: 1  batch: 35 / 122  loss: 1.1079314010483878  hr: 3  min: 2  sec: 18\n",
      "epoch: 1  batch: 36 / 122  loss: 1.1088126450777054  hr: 3  min: 1  sec: 47\n",
      "epoch: 1  batch: 37 / 122  loss: 1.1109930035230275  hr: 3  min: 0  sec: 47\n",
      "epoch: 1  batch: 38 / 122  loss: 1.1132295147368783  hr: 3  min: 0  sec: 35\n",
      "epoch: 1  batch: 39 / 122  loss: 1.117353917696537  hr: 3  min: 0  sec: 51\n",
      "epoch: 1  batch: 40 / 122  loss: 1.1209913954138755  hr: 3  min: 2  sec: 4\n",
      "epoch: 1  batch: 41 / 122  loss: 1.1235095596894986  hr: 3  min: 1  sec: 25\n",
      "epoch: 1  batch: 42 / 122  loss: 1.124038876522155  hr: 3  min: 0  sec: 18\n",
      "epoch: 1  batch: 43 / 122  loss: 1.1239235941753831  hr: 2  min: 59  sec: 31\n",
      "epoch: 1  batch: 44 / 122  loss: 1.1230449392036959  hr: 2  min: 58  sec: 47\n",
      "epoch: 1  batch: 45 / 122  loss: 1.1253138793839348  hr: 3  min: 1  sec: 3\n",
      "epoch: 1  batch: 46 / 122  loss: 1.1249982209309288  hr: 3  min: 0  sec: 48\n",
      "epoch: 1  batch: 47 / 122  loss: 1.1236085042040398  hr: 3  min: 0  sec: 23\n",
      "epoch: 1  batch: 48 / 122  loss: 1.1208251876135666  hr: 3  min: 1  sec: 8\n",
      "epoch: 1  batch: 49 / 122  loss: 1.1227712546076094  hr: 3  min: 0  sec: 34\n",
      "epoch: 1  batch: 50 / 122  loss: 1.1227545607089997  hr: 3  min: 0  sec: 10\n",
      "epoch: 1  batch: 51 / 122  loss: 1.1217121014408036  hr: 2  min: 59  sec: 35\n",
      "epoch: 1  batch: 52 / 122  loss: 1.1202089889691427  hr: 2  min: 59  sec: 30\n",
      "epoch: 1  batch: 53 / 122  loss: 1.120723176677272  hr: 2  min: 59  sec: 56\n",
      "epoch: 1  batch: 54 / 122  loss: 1.1201112060635179  hr: 3  min: 0  sec: 49\n",
      "epoch: 1  batch: 55 / 122  loss: 1.1198661641641097  hr: 3  min: 0  sec: 23\n",
      "epoch: 1  batch: 56 / 122  loss: 1.1203246787190437  hr: 2  min: 59  sec: 35\n",
      "epoch: 1  batch: 57 / 122  loss: 1.1213157919415258  hr: 2  min: 59  sec: 22\n",
      "epoch: 1  batch: 58 / 122  loss: 1.1219833339082783  hr: 2  min: 58  sec: 46\n",
      "epoch: 1  batch: 59 / 122  loss: 1.1226793517500668  hr: 2  min: 58  sec: 4\n",
      "epoch: 1  batch: 60 / 122  loss: 1.1234496722618739  hr: 2  min: 57  sec: 52\n",
      "epoch: 1  batch: 61 / 122  loss: 1.1237683774995022  hr: 2  min: 58  sec: 39\n",
      "epoch: 1  batch: 62 / 122  loss: 1.123818467701635  hr: 2  min: 58  sec: 54\n",
      "epoch: 1  batch: 63 / 122  loss: 1.1240399196034385  hr: 2  min: 58  sec: 27\n",
      "epoch: 1  batch: 64 / 122  loss: 1.1236965535208583  hr: 2  min: 58  sec: 34\n",
      "epoch: 1  batch: 65 / 122  loss: 1.122358688024374  hr: 2  min: 58  sec: 24\n",
      "epoch: 1  batch: 66 / 122  loss: 1.123319101152998  hr: 2  min: 58  sec: 14\n",
      "epoch: 1  batch: 67 / 122  loss: 1.1256178359487163  hr: 2  min: 58  sec: 4\n",
      "epoch: 1  batch: 68 / 122  loss: 1.1252129682723213  hr: 2  min: 57  sec: 45\n",
      "epoch: 1  batch: 69 / 122  loss: 1.126155726287676  hr: 2  min: 57  sec: 45\n",
      "epoch: 1  batch: 70 / 122  loss: 1.1283676973411014  hr: 2  min: 57  sec: 26\n",
      "epoch: 1  batch: 71 / 122  loss: 1.1281454907336705  hr: 2  min: 56  sec: 49\n",
      "epoch: 1  batch: 72 / 122  loss: 1.1293872371315956  hr: 2  min: 56  sec: 17\n",
      "epoch: 1  batch: 73 / 122  loss: 1.1290610008043787  hr: 2  min: 56  sec: 37\n",
      "epoch: 1  batch: 74 / 122  loss: 1.129107205448924  hr: 2  min: 56  sec: 45\n",
      "epoch: 1  batch: 75 / 122  loss: 1.1293146141370138  hr: 2  min: 56  sec: 12\n",
      "epoch: 1  batch: 76 / 122  loss: 1.1339778123717559  hr: 2  min: 55  sec: 50\n",
      "epoch: 1  batch: 77 / 122  loss: 1.1342684734951367  hr: 2  min: 55  sec: 26\n",
      "epoch: 1  batch: 78 / 122  loss: 1.1360290210980635  hr: 2  min: 55  sec: 27\n",
      "epoch: 1  batch: 79 / 122  loss: 1.1368606882759287  hr: 2  min: 56  sec: 1\n",
      "epoch: 1  batch: 80 / 122  loss: 1.140958420187235  hr: 2  min: 55  sec: 31\n",
      "epoch: 1  batch: 81 / 122  loss: 1.1419824236704978  hr: 2  min: 55  sec: 1\n",
      "epoch: 1  batch: 82 / 122  loss: 1.1423627755990842  hr: 2  min: 54  sec: 22\n",
      "epoch: 1  batch: 83 / 122  loss: 1.1420523567372058  hr: 2  min: 53  sec: 35\n",
      "epoch: 1  batch: 84 / 122  loss: 1.1414996477819623  hr: 2  min: 53  sec: 3\n",
      "epoch: 1  batch: 85 / 122  loss: 1.1404472512357375  hr: 2  min: 52  sec: 53\n",
      "epoch: 1  batch: 86 / 122  loss: 1.1402649872524793  hr: 2  min: 52  sec: 53\n",
      "epoch: 1  batch: 87 / 122  loss: 1.1410677617993847  hr: 2  min: 52  sec: 40\n",
      "epoch: 1  batch: 88 / 122  loss: 1.1421039693734862  hr: 2  min: 52  sec: 38\n",
      "epoch: 1  batch: 89 / 122  loss: 1.143808437867111  hr: 2  min: 52  sec: 25\n",
      "epoch: 1  batch: 90 / 122  loss: 1.1430165999465518  hr: 2  min: 53  sec: 39\n",
      "epoch: 1  batch: 91 / 122  loss: 1.1419707320548675  hr: 2  min: 53  sec: 7\n",
      "epoch: 1  batch: 92 / 122  loss: 1.141424514029337  hr: 2  min: 52  sec: 40\n",
      "epoch: 1  batch: 93 / 122  loss: 1.1405084959922298  hr: 2  min: 52  sec: 23\n",
      "epoch: 1  batch: 94 / 122  loss: 1.1409827882939196  hr: 2  min: 51  sec: 51\n",
      "epoch: 1  batch: 95 / 122  loss: 1.140379674183695  hr: 2  min: 51  sec: 18\n",
      "epoch: 1  batch: 96 / 122  loss: 1.1396783882131178  hr: 2  min: 50  sec: 48\n",
      "epoch: 1  batch: 97 / 122  loss: 1.1399628495432668  hr: 2  min: 50  sec: 37\n",
      "epoch: 1  batch: 98 / 122  loss: 1.1399640897098853  hr: 2  min: 50  sec: 3\n",
      "epoch: 1  batch: 99 / 122  loss: 1.139309798226212  hr: 2  min: 49  sec: 56\n",
      "epoch: 1  batch: 100 / 122  loss: 1.1393811863660812  hr: 2  min: 50  sec: 25\n",
      "Validation Loss after 100 batches: 1.0878878116607666\n",
      "epoch: 1  batch: 101 / 122  loss: 1.1390382671120143  hr: 2  min: 50  sec: 22\n",
      "epoch: 1  batch: 102 / 122  loss: 1.1387099243846595  hr: 2  min: 50  sec: 0\n",
      "epoch: 1  batch: 103 / 122  loss: 1.1384203370335033  hr: 2  min: 49  sec: 34\n",
      "epoch: 1  batch: 104 / 122  loss: 1.137548908018149  hr: 2  min: 50  sec: 25\n",
      "epoch: 1  batch: 105 / 122  loss: 1.137013758364178  hr: 2  min: 50  sec: 15\n",
      "epoch: 1  batch: 106 / 122  loss: 1.1369494092914294  hr: 2  min: 49  sec: 55\n",
      "epoch: 1  batch: 107 / 122  loss: 1.136679798086113  hr: 2  min: 49  sec: 45\n",
      "epoch: 1  batch: 108 / 122  loss: 1.1356802731752396  hr: 2  min: 49  sec: 27\n",
      "epoch: 1  batch: 109 / 122  loss: 1.1357504517660229  hr: 2  min: 49  sec: 24\n",
      "epoch: 1  batch: 110 / 122  loss: 1.135244792699814  hr: 2  min: 49  sec: 4\n",
      "epoch: 1  batch: 111 / 122  loss: 1.1344518999795656  hr: 2  min: 48  sec: 58\n",
      "epoch: 1  batch: 112 / 122  loss: 1.1341135517827101  hr: 2  min: 49  sec: 41\n",
      "epoch: 1  batch: 113 / 122  loss: 1.1340848444837384  hr: 2  min: 49  sec: 32\n",
      "epoch: 1  batch: 114 / 122  loss: 1.1341582897462343  hr: 2  min: 49  sec: 21\n",
      "epoch: 1  batch: 115 / 122  loss: 1.1337275634641233  hr: 2  min: 49  sec: 7\n",
      "epoch: 1  batch: 116 / 122  loss: 1.1332933856495495  hr: 2  min: 48  sec: 58\n",
      "epoch: 1  batch: 117 / 122  loss: 1.1339480372575612  hr: 2  min: 48  sec: 51\n",
      "epoch: 1  batch: 118 / 122  loss: 1.1337767157514216  hr: 2  min: 48  sec: 40\n",
      "epoch: 1  batch: 119 / 122  loss: 1.1333653270697392  hr: 2  min: 48  sec: 34\n",
      "epoch: 1  batch: 120 / 122  loss: 1.1331627115607261  hr: 2  min: 48  sec: 25\n",
      "epoch: 1  batch: 121 / 122  loss: 1.1330536470925512  hr: 2  min: 48  sec: 15\n",
      "epoch: 1  batch: 122 / 122  loss: 1.1324305324280848  hr: 2  min: 48  sec: 13\n",
      "Learning rate: 1.925925925925926e-05\n",
      "Saving...\n",
      "epoch: 2  batch: 1 / 122  loss: 1.1737773418426514  hr: 3  min: 0  sec: 28\n",
      "epoch: 2  batch: 2 / 122  loss: 1.1142171025276184  hr: 2  min: 41  sec: 45\n",
      "epoch: 2  batch: 3 / 122  loss: 1.0901540120442708  hr: 3  min: 22  sec: 56\n",
      "epoch: 2  batch: 4 / 122  loss: 1.0951116383075714  hr: 3  min: 5  sec: 4\n",
      "epoch: 2  batch: 5 / 122  loss: 1.0926347732543946  hr: 2  min: 59  sec: 15\n",
      "epoch: 2  batch: 6 / 122  loss: 1.1058967113494873  hr: 2  min: 57  sec: 28\n",
      "epoch: 2  batch: 7 / 122  loss: 1.129583580153329  hr: 2  min: 53  sec: 44\n",
      "epoch: 2  batch: 8 / 122  loss: 1.126648172736168  hr: 2  min: 57  sec: 13\n",
      "epoch: 2  batch: 9 / 122  loss: 1.1252508163452148  hr: 2  min: 57  sec: 56\n",
      "epoch: 2  batch: 10 / 122  loss: 1.1455214023590088  hr: 2  min: 58  sec: 13\n",
      "epoch: 2  batch: 11 / 122  loss: 1.1424591541290283  hr: 3  min: 7  sec: 45\n",
      "epoch: 2  batch: 12 / 122  loss: 1.143549342950185  hr: 3  min: 6  sec: 22\n",
      "epoch: 2  batch: 13 / 122  loss: 1.1419786673325758  hr: 3  min: 3  sec: 47\n",
      "epoch: 2  batch: 14 / 122  loss: 1.143176325729915  hr: 3  min: 11  sec: 4\n",
      "epoch: 2  batch: 15 / 122  loss: 1.1402347803115844  hr: 3  min: 7  sec: 37\n",
      "epoch: 2  batch: 16 / 122  loss: 1.1406806781888008  hr: 3  min: 12  sec: 12\n",
      "epoch: 2  batch: 17 / 122  loss: 1.1363806794671452  hr: 3  min: 8  sec: 24\n",
      "epoch: 2  batch: 18 / 122  loss: 1.1327412393358018  hr: 3  min: 5  sec: 6\n",
      "epoch: 2  batch: 19 / 122  loss: 1.1312767831902755  hr: 3  min: 2  sec: 12\n",
      "epoch: 2  batch: 20 / 122  loss: 1.1313215851783753  hr: 2  min: 59  sec: 42\n",
      "epoch: 2  batch: 21 / 122  loss: 1.1315263566516696  hr: 2  min: 59  sec: 14\n",
      "epoch: 2  batch: 22 / 122  loss: 1.1249904740940442  hr: 2  min: 56  sec: 18\n",
      "epoch: 2  batch: 23 / 122  loss: 1.1255797095920728  hr: 2  min: 56  sec: 1\n",
      "epoch: 2  batch: 24 / 122  loss: 1.1227889756361644  hr: 2  min: 58  sec: 38\n",
      "epoch: 2  batch: 25 / 122  loss: 1.1212919235229493  hr: 2  min: 59  sec: 36\n",
      "epoch: 2  batch: 26 / 122  loss: 1.1192112610890315  hr: 3  min: 0  sec: 10\n",
      "epoch: 2  batch: 27 / 122  loss: 1.1162652130480166  hr: 2  min: 58  sec: 22\n",
      "epoch: 2  batch: 28 / 122  loss: 1.1157918402126856  hr: 2  min: 57  sec: 59\n",
      "epoch: 2  batch: 29 / 122  loss: 1.1149532137245968  hr: 2  min: 56  sec: 3\n",
      "epoch: 2  batch: 30 / 122  loss: 1.1124422868092856  hr: 2  min: 54  sec: 19\n",
      "epoch: 2  batch: 31 / 122  loss: 1.1107753015333606  hr: 2  min: 53  sec: 6\n",
      "epoch: 2  batch: 32 / 122  loss: 1.1098590902984142  hr: 2  min: 52  sec: 35\n",
      "epoch: 2  batch: 33 / 122  loss: 1.1116613655379324  hr: 2  min: 51  sec: 42\n",
      "epoch: 2  batch: 34 / 122  loss: 1.11434906019884  hr: 2  min: 51  sec: 57\n",
      "epoch: 2  batch: 35 / 122  loss: 1.1157833542142594  hr: 2  min: 51  sec: 11\n",
      "epoch: 2  batch: 36 / 122  loss: 1.116711613204744  hr: 2  min: 49  sec: 57\n",
      "epoch: 2  batch: 37 / 122  loss: 1.1161223553322457  hr: 2  min: 49  sec: 2\n",
      "epoch: 2  batch: 38 / 122  loss: 1.1160524456124556  hr: 2  min: 49  sec: 5\n",
      "epoch: 2  batch: 39 / 122  loss: 1.1165803762582631  hr: 2  min: 49  sec: 5\n",
      "epoch: 2  batch: 40 / 122  loss: 1.1161649763584136  hr: 2  min: 48  sec: 24\n",
      "epoch: 2  batch: 41 / 122  loss: 1.1151019887226383  hr: 2  min: 48  sec: 47\n",
      "epoch: 2  batch: 42 / 122  loss: 1.1150415057227725  hr: 2  min: 48  sec: 30\n",
      "epoch: 2  batch: 43 / 122  loss: 1.112489054369372  hr: 2  min: 48  sec: 43\n",
      "epoch: 2  batch: 44 / 122  loss: 1.110613465309143  hr: 2  min: 48  sec: 32\n",
      "epoch: 2  batch: 45 / 122  loss: 1.1113067362043592  hr: 2  min: 48  sec: 38\n",
      "epoch: 2  batch: 46 / 122  loss: 1.1103318204050479  hr: 2  min: 48  sec: 13\n",
      "epoch: 2  batch: 47 / 122  loss: 1.1060087769589526  hr: 2  min: 47  sec: 39\n",
      "epoch: 2  batch: 48 / 122  loss: 1.1019631375869114  hr: 2  min: 46  sec: 49\n",
      "epoch: 2  batch: 49 / 122  loss: 1.0978958509406265  hr: 2  min: 46  sec: 25\n",
      "epoch: 2  batch: 50 / 122  loss: 1.0994233870506287  hr: 2  min: 46  sec: 5\n",
      "epoch: 2  batch: 51 / 122  loss: 1.0985392191830803  hr: 2  min: 47  sec: 51\n",
      "epoch: 2  batch: 52 / 122  loss: 1.0999945241671343  hr: 2  min: 48  sec: 42\n",
      "epoch: 2  batch: 53 / 122  loss: 1.1033070019955904  hr: 2  min: 48  sec: 18\n",
      "epoch: 2  batch: 54 / 122  loss: 1.101902460610425  hr: 2  min: 48  sec: 8\n",
      "epoch: 2  batch: 55 / 122  loss: 1.1002750916914505  hr: 2  min: 47  sec: 26\n",
      "epoch: 2  batch: 56 / 122  loss: 1.0997845019612993  hr: 2  min: 46  sec: 36\n",
      "epoch: 2  batch: 57 / 122  loss: 1.096693055671558  hr: 2  min: 46  sec: 11\n",
      "epoch: 2  batch: 58 / 122  loss: 1.0946821642333064  hr: 2  min: 46  sec: 30\n",
      "epoch: 2  batch: 59 / 122  loss: 1.0905601917687109  hr: 2  min: 46  sec: 38\n",
      "epoch: 2  batch: 60 / 122  loss: 1.0905795772870381  hr: 2  min: 46  sec: 17\n",
      "epoch: 2  batch: 61 / 122  loss: 1.0875314464334582  hr: 2  min: 46  sec: 57\n",
      "epoch: 2  batch: 62 / 122  loss: 1.0821953858098676  hr: 2  min: 47  sec: 16\n",
      "epoch: 2  batch: 63 / 122  loss: 1.0833580683148096  hr: 2  min: 46  sec: 35\n",
      "epoch: 2  batch: 64 / 122  loss: 1.078789328224957  hr: 2  min: 45  sec: 46\n",
      "epoch: 2  batch: 65 / 122  loss: 1.0799549863888667  hr: 2  min: 45  sec: 5\n",
      "epoch: 2  batch: 66 / 122  loss: 1.0787135055570891  hr: 2  min: 44  sec: 44\n",
      "epoch: 2  batch: 67 / 122  loss: 1.0745090103861112  hr: 2  min: 44  sec: 33\n",
      "epoch: 2  batch: 68 / 122  loss: 1.072877246667357  hr: 2  min: 44  sec: 26\n",
      "epoch: 2  batch: 69 / 122  loss: 1.0726164968117424  hr: 2  min: 45  sec: 49\n",
      "epoch: 2  batch: 70 / 122  loss: 1.0673842098031725  hr: 2  min: 45  sec: 47\n",
      "epoch: 2  batch: 71 / 122  loss: 1.0636198780906032  hr: 2  min: 45  sec: 48\n",
      "epoch: 2  batch: 72 / 122  loss: 1.0617980178859499  hr: 2  min: 46  sec: 8\n",
      "epoch: 2  batch: 73 / 122  loss: 1.0592788988596773  hr: 2  min: 46  sec: 42\n",
      "epoch: 2  batch: 74 / 122  loss: 1.0622304379940033  hr: 2  min: 46  sec: 11\n",
      "epoch: 2  batch: 75 / 122  loss: 1.0601646264394124  hr: 2  min: 45  sec: 41\n",
      "epoch: 2  batch: 76 / 122  loss: 1.0590263307094574  hr: 2  min: 45  sec: 17\n",
      "epoch: 2  batch: 77 / 122  loss: 1.0587873443380578  hr: 2  min: 45  sec: 21\n",
      "epoch: 2  batch: 78 / 122  loss: 1.0605191343869917  hr: 2  min: 45  sec: 3\n",
      "epoch: 2  batch: 79 / 122  loss: 1.060436322719236  hr: 2  min: 44  sec: 11\n",
      "epoch: 2  batch: 80 / 122  loss: 1.0597671806812285  hr: 2  min: 43  sec: 23\n",
      "epoch: 2  batch: 81 / 122  loss: 1.0562448781213643  hr: 2  min: 43  sec: 53\n",
      "epoch: 2  batch: 82 / 122  loss: 1.0534493305334232  hr: 2  min: 43  sec: 22\n",
      "epoch: 2  batch: 83 / 122  loss: 1.056214985359146  hr: 2  min: 43  sec: 0\n",
      "epoch: 2  batch: 84 / 122  loss: 1.0569889325471151  hr: 2  min: 42  sec: 38\n",
      "epoch: 2  batch: 85 / 122  loss: 1.0570615312632392  hr: 2  min: 42  sec: 21\n",
      "epoch: 2  batch: 86 / 122  loss: 1.0576419102591137  hr: 2  min: 42  sec: 26\n",
      "epoch: 2  batch: 87 / 122  loss: 1.0589310184292409  hr: 2  min: 43  sec: 10\n",
      "epoch: 2  batch: 88 / 122  loss: 1.0577550740404562  hr: 2  min: 42  sec: 51\n",
      "epoch: 2  batch: 89 / 122  loss: 1.0546583077880773  hr: 2  min: 42  sec: 42\n",
      "epoch: 2  batch: 90 / 122  loss: 1.0526823620001475  hr: 2  min: 42  sec: 19\n",
      "epoch: 2  batch: 91 / 122  loss: 1.049769986461807  hr: 2  min: 42  sec: 2\n",
      "epoch: 2  batch: 92 / 122  loss: 1.0494355306677197  hr: 2  min: 41  sec: 55\n",
      "epoch: 2  batch: 93 / 122  loss: 1.0512001995117433  hr: 2  min: 42  sec: 2\n",
      "epoch: 2  batch: 94 / 122  loss: 1.0543811112008197  hr: 2  min: 42  sec: 4\n",
      "epoch: 2  batch: 95 / 122  loss: 1.0571899558368483  hr: 2  min: 42  sec: 30\n",
      "epoch: 2  batch: 96 / 122  loss: 1.0551854943235714  hr: 2  min: 42  sec: 3\n",
      "epoch: 2  batch: 97 / 122  loss: 1.0560871571609654  hr: 2  min: 41  sec: 43\n",
      "epoch: 2  batch: 98 / 122  loss: 1.0553914612653303  hr: 2  min: 42  sec: 42\n",
      "epoch: 2  batch: 99 / 122  loss: 1.0530419536311217  hr: 2  min: 42  sec: 28\n",
      "epoch: 2  batch: 100 / 122  loss: 1.0533959931135177  hr: 2  min: 42  sec: 44\n",
      "Validation Loss after 100 batches: 0.8037121683359146\n",
      "epoch: 2  batch: 101 / 122  loss: 1.053443989541271  hr: 2  min: 42  sec: 21\n",
      "epoch: 2  batch: 102 / 122  loss: 1.0508296144943612  hr: 2  min: 42  sec: 8\n",
      "epoch: 2  batch: 103 / 122  loss: 1.0487060309613792  hr: 2  min: 41  sec: 47\n",
      "epoch: 2  batch: 104 / 122  loss: 1.045263870404317  hr: 2  min: 41  sec: 53\n",
      "epoch: 2  batch: 105 / 122  loss: 1.0422344378062658  hr: 2  min: 41  sec: 33\n",
      "epoch: 2  batch: 106 / 122  loss: 1.0416931948571835  hr: 2  min: 41  sec: 18\n",
      "epoch: 2  batch: 107 / 122  loss: 1.0401143687907781  hr: 2  min: 41  sec: 55\n",
      "epoch: 2  batch: 108 / 122  loss: 1.0391578254876312  hr: 2  min: 41  sec: 22\n",
      "epoch: 2  batch: 109 / 122  loss: 1.0370297464755698  hr: 2  min: 41  sec: 9\n",
      "epoch: 2  batch: 110 / 122  loss: 1.0344129513610494  hr: 2  min: 40  sec: 57\n",
      "epoch: 2  batch: 111 / 122  loss: 1.0334405716475066  hr: 2  min: 40  sec: 39\n",
      "epoch: 2  batch: 112 / 122  loss: 1.03164069460971  hr: 2  min: 40  sec: 27\n",
      "epoch: 2  batch: 113 / 122  loss: 1.0298150772542025  hr: 2  min: 40  sec: 5\n",
      "epoch: 2  batch: 114 / 122  loss: 1.0271235233859013  hr: 2  min: 39  sec: 35\n",
      "epoch: 2  batch: 115 / 122  loss: 1.0261152329652206  hr: 2  min: 39  sec: 31\n",
      "epoch: 2  batch: 116 / 122  loss: 1.026444808162492  hr: 2  min: 39  sec: 14\n",
      "epoch: 2  batch: 117 / 122  loss: 1.0240791287177649  hr: 2  min: 39  sec: 11\n",
      "epoch: 2  batch: 118 / 122  loss: 1.0247989413091692  hr: 2  min: 38  sec: 40\n",
      "epoch: 2  batch: 119 / 122  loss: 1.0223453495682788  hr: 2  min: 38  sec: 20\n",
      "epoch: 2  batch: 120 / 122  loss: 1.0182993809382122  hr: 2  min: 37  sec: 56\n",
      "epoch: 2  batch: 121 / 122  loss: 1.015037126777586  hr: 2  min: 37  sec: 43\n",
      "epoch: 2  batch: 122 / 122  loss: 1.013296163472973  hr: 2  min: 37  sec: 17\n",
      "Learning rate: 1.7777777777777777e-05\n",
      "Saving...\n",
      "epoch: 3  batch: 1 / 122  loss: 0.6759675741195679  hr: 2  min: 20  sec: 41\n",
      "epoch: 3  batch: 2 / 122  loss: 0.7288209795951843  hr: 2  min: 35  sec: 58\n",
      "epoch: 3  batch: 3 / 122  loss: 0.7455342411994934  hr: 2  min: 25  sec: 59\n",
      "epoch: 3  batch: 4 / 122  loss: 0.7814236581325531  hr: 2  min: 26  sec: 6\n",
      "epoch: 3  batch: 5 / 122  loss: 0.801405954360962  hr: 2  min: 21  sec: 25\n",
      "epoch: 3  batch: 6 / 122  loss: 0.8065597812334696  hr: 2  min: 17  sec: 24\n",
      "epoch: 3  batch: 7 / 122  loss: 0.8034394127982003  hr: 2  min: 17  sec: 53\n",
      "epoch: 3  batch: 8 / 122  loss: 0.7866258770227432  hr: 2  min: 15  sec: 55\n",
      "epoch: 3  batch: 9 / 122  loss: 0.8019571304321289  hr: 2  min: 16  sec: 17\n",
      "epoch: 3  batch: 10 / 122  loss: 0.8089582443237304  hr: 2  min: 16  sec: 37\n",
      "epoch: 3  batch: 11 / 122  loss: 0.8449585871262983  hr: 2  min: 16  sec: 12\n",
      "epoch: 3  batch: 12 / 122  loss: 0.8329883068799973  hr: 2  min: 19  sec: 26\n",
      "epoch: 3  batch: 13 / 122  loss: 0.8333865633377662  hr: 2  min: 19  sec: 52\n",
      "epoch: 3  batch: 14 / 122  loss: 0.8317506100450244  hr: 2  min: 20  sec: 45\n",
      "epoch: 3  batch: 15 / 122  loss: 0.8105435093243917  hr: 2  min: 19  sec: 38\n",
      "epoch: 3  batch: 16 / 122  loss: 0.8100670725107193  hr: 2  min: 19  sec: 18\n",
      "epoch: 3  batch: 17 / 122  loss: 0.795187210335451  hr: 2  min: 20  sec: 52\n",
      "epoch: 3  batch: 18 / 122  loss: 0.7947976158724891  hr: 2  min: 18  sec: 52\n",
      "epoch: 3  batch: 19 / 122  loss: 0.8137040232357226  hr: 2  min: 20  sec: 10\n",
      "epoch: 3  batch: 20 / 122  loss: 0.8057045310735702  hr: 2  min: 21  sec: 38\n",
      "epoch: 3  batch: 21 / 122  loss: 0.793461126940591  hr: 2  min: 22  sec: 48\n",
      "epoch: 3  batch: 22 / 122  loss: 0.7750414745374159  hr: 2  min: 21  sec: 34\n",
      "epoch: 3  batch: 23 / 122  loss: 0.7631201562674149  hr: 2  min: 20  sec: 50\n",
      "epoch: 3  batch: 24 / 122  loss: 0.7479795416196188  hr: 2  min: 22  sec: 35\n",
      "epoch: 3  batch: 25 / 122  loss: 0.7512321138381958  hr: 2  min: 22  sec: 18\n",
      "epoch: 3  batch: 26 / 122  loss: 0.7450131773948669  hr: 2  min: 22  sec: 39\n",
      "epoch: 3  batch: 27 / 122  loss: 0.7432085849620678  hr: 2  min: 23  sec: 24\n",
      "epoch: 3  batch: 28 / 122  loss: 0.7521124184131622  hr: 2  min: 22  sec: 18\n",
      "epoch: 3  batch: 29 / 122  loss: 0.758745082493486  hr: 2  min: 21  sec: 47\n",
      "epoch: 3  batch: 30 / 122  loss: 0.7625367939472198  hr: 2  min: 22  sec: 21\n",
      "epoch: 3  batch: 31 / 122  loss: 0.7609926789037643  hr: 2  min: 22  sec: 44\n",
      "epoch: 3  batch: 32 / 122  loss: 0.7562872022390366  hr: 2  min: 22  sec: 25\n",
      "epoch: 3  batch: 33 / 122  loss: 0.7507712841033936  hr: 2  min: 21  sec: 48\n",
      "epoch: 3  batch: 34 / 122  loss: 0.7502688818118152  hr: 2  min: 20  sec: 41\n",
      "epoch: 3  batch: 35 / 122  loss: 0.7432329603603908  hr: 2  min: 19  sec: 47\n",
      "epoch: 3  batch: 36 / 122  loss: 0.7419049872292413  hr: 2  min: 19  sec: 28\n",
      "epoch: 3  batch: 37 / 122  loss: 0.7443439606073741  hr: 2  min: 19  sec: 38\n",
      "epoch: 3  batch: 38 / 122  loss: 0.7518561356946042  hr: 2  min: 19  sec: 48\n",
      "epoch: 3  batch: 39 / 122  loss: 0.7536222139994303  hr: 2  min: 19  sec: 25\n",
      "epoch: 3  batch: 40 / 122  loss: 0.7627479881048203  hr: 2  min: 19  sec: 55\n",
      "epoch: 3  batch: 41 / 122  loss: 0.7628108670071858  hr: 2  min: 19  sec: 39\n",
      "epoch: 3  batch: 42 / 122  loss: 0.7616363068421682  hr: 2  min: 20  sec: 11\n",
      "epoch: 3  batch: 43 / 122  loss: 0.7630241582559985  hr: 2  min: 20  sec: 28\n",
      "epoch: 3  batch: 44 / 122  loss: 0.7678456360643561  hr: 2  min: 21  sec: 13\n",
      "epoch: 3  batch: 45 / 122  loss: 0.7709186421500311  hr: 2  min: 22  sec: 15\n",
      "epoch: 3  batch: 46 / 122  loss: 0.7710450395293857  hr: 2  min: 22  sec: 17\n",
      "epoch: 3  batch: 47 / 122  loss: 0.768130306233751  hr: 2  min: 22  sec: 11\n",
      "epoch: 3  batch: 48 / 122  loss: 0.7728845824797949  hr: 2  min: 21  sec: 26\n",
      "epoch: 3  batch: 49 / 122  loss: 0.7787159924604454  hr: 2  min: 21  sec: 8\n",
      "epoch: 3  batch: 50 / 122  loss: 0.775746408700943  hr: 2  min: 20  sec: 33\n",
      "epoch: 3  batch: 51 / 122  loss: 0.7770159267911724  hr: 2  min: 20  sec: 8\n",
      "epoch: 3  batch: 52 / 122  loss: 0.7763942732260778  hr: 2  min: 20  sec: 34\n",
      "epoch: 3  batch: 53 / 122  loss: 0.7755620963168595  hr: 2  min: 20  sec: 38\n",
      "epoch: 3  batch: 54 / 122  loss: 0.77248505420155  hr: 2  min: 21  sec: 39\n",
      "epoch: 3  batch: 55 / 122  loss: 0.7701173879883506  hr: 2  min: 21  sec: 26\n",
      "epoch: 3  batch: 56 / 122  loss: 0.7706279477902821  hr: 2  min: 21  sec: 3\n",
      "epoch: 3  batch: 57 / 122  loss: 0.7694049948140195  hr: 2  min: 21  sec: 40\n",
      "epoch: 3  batch: 58 / 122  loss: 0.7729486062608916  hr: 2  min: 21  sec: 27\n",
      "epoch: 3  batch: 59 / 122  loss: 0.7688846487109944  hr: 2  min: 22  sec: 2\n",
      "epoch: 3  batch: 60 / 122  loss: 0.7641223827997844  hr: 2  min: 21  sec: 49\n",
      "epoch: 3  batch: 61 / 122  loss: 0.7634117906210852  hr: 2  min: 21  sec: 36\n",
      "epoch: 3  batch: 62 / 122  loss: 0.7684992542189937  hr: 2  min: 21  sec: 18\n",
      "epoch: 3  batch: 63 / 122  loss: 0.7644288662880186  hr: 2  min: 21  sec: 18\n",
      "epoch: 3  batch: 64 / 122  loss: 0.7669885950163007  hr: 2  min: 21  sec: 2\n",
      "epoch: 3  batch: 65 / 122  loss: 0.7623933379466717  hr: 2  min: 21  sec: 13\n",
      "epoch: 3  batch: 66 / 122  loss: 0.7623435647198649  hr: 2  min: 22  sec: 45\n",
      "epoch: 3  batch: 67 / 122  loss: 0.7663825723662305  hr: 2  min: 22  sec: 6\n",
      "epoch: 3  batch: 68 / 122  loss: 0.7712310175685322  hr: 2  min: 22  sec: 12\n",
      "epoch: 3  batch: 69 / 122  loss: 0.7690010925997859  hr: 2  min: 22  sec: 3\n",
      "epoch: 3  batch: 70 / 122  loss: 0.7663015569959368  hr: 2  min: 21  sec: 36\n",
      "epoch: 3  batch: 71 / 122  loss: 0.7649927491873083  hr: 2  min: 21  sec: 20\n",
      "epoch: 3  batch: 72 / 122  loss: 0.765430656572183  hr: 2  min: 20  sec: 59\n",
      "epoch: 3  batch: 73 / 122  loss: 0.7717097695559672  hr: 2  min: 22  sec: 20\n",
      "epoch: 3  batch: 74 / 122  loss: 0.7693595547933836  hr: 2  min: 22  sec: 6\n",
      "epoch: 3  batch: 75 / 122  loss: 0.7706080102920532  hr: 2  min: 21  sec: 47\n",
      "epoch: 3  batch: 76 / 122  loss: 0.7685563681941283  hr: 2  min: 21  sec: 46\n",
      "epoch: 3  batch: 77 / 122  loss: 0.7676030947016431  hr: 2  min: 21  sec: 42\n",
      "epoch: 3  batch: 78 / 122  loss: 0.7689117361337711  hr: 2  min: 21  sec: 33\n",
      "epoch: 3  batch: 79 / 122  loss: 0.7665664093403877  hr: 2  min: 21  sec: 15\n",
      "epoch: 3  batch: 80 / 122  loss: 0.7656762838363648  hr: 2  min: 21  sec: 9\n",
      "epoch: 3  batch: 81 / 122  loss: 0.7696484842418153  hr: 2  min: 21  sec: 43\n",
      "epoch: 3  batch: 82 / 122  loss: 0.7688475469263588  hr: 2  min: 22  sec: 29\n",
      "epoch: 3  batch: 83 / 122  loss: 0.7668390841369169  hr: 2  min: 22  sec: 24\n",
      "epoch: 3  batch: 84 / 122  loss: 0.766416568841253  hr: 2  min: 23  sec: 4\n",
      "epoch: 3  batch: 85 / 122  loss: 0.7673067752052756  hr: 2  min: 24  sec: 13\n",
      "epoch: 3  batch: 86 / 122  loss: 0.7694108846575715  hr: 2  min: 24  sec: 18\n",
      "epoch: 3  batch: 87 / 122  loss: 0.7683048241439907  hr: 2  min: 23  sec: 50\n",
      "epoch: 3  batch: 88 / 122  loss: 0.7641403566707264  hr: 2  min: 23  sec: 22\n",
      "epoch: 3  batch: 89 / 122  loss: 0.7626504985134254  hr: 2  min: 23  sec: 50\n",
      "epoch: 3  batch: 90 / 122  loss: 0.7616999652650621  hr: 2  min: 24  sec: 2\n",
      "epoch: 3  batch: 91 / 122  loss: 0.758673485163804  hr: 2  min: 23  sec: 57\n",
      "epoch: 3  batch: 92 / 122  loss: 0.7587898755850999  hr: 2  min: 24  sec: 54\n",
      "epoch: 3  batch: 93 / 122  loss: 0.7594341251157946  hr: 2  min: 24  sec: 27\n",
      "epoch: 3  batch: 94 / 122  loss: 0.7574483454227448  hr: 2  min: 24  sec: 26\n",
      "epoch: 3  batch: 95 / 122  loss: 0.7571624555085835  hr: 2  min: 24  sec: 26\n",
      "epoch: 3  batch: 96 / 122  loss: 0.755417212843895  hr: 2  min: 25  sec: 11\n",
      "epoch: 3  batch: 97 / 122  loss: 0.7551175435793769  hr: 2  min: 26  sec: 4\n",
      "epoch: 3  batch: 98 / 122  loss: 0.751774535799513  hr: 2  min: 26  sec: 49\n",
      "epoch: 3  batch: 99 / 122  loss: 0.7515278889073266  hr: 2  min: 26  sec: 36\n",
      "epoch: 3  batch: 100 / 122  loss: 0.7517761442065239  hr: 2  min: 26  sec: 22\n",
      "Validation Loss after 100 batches: 0.6733603283762932\n",
      "epoch: 3  batch: 101 / 122  loss: 0.7507680144050334  hr: 2  min: 25  sec: 48\n",
      "epoch: 3  batch: 102 / 122  loss: 0.7484249674222049  hr: 2  min: 26  sec: 1\n",
      "epoch: 3  batch: 103 / 122  loss: 0.7487042896377231  hr: 2  min: 25  sec: 45\n",
      "epoch: 3  batch: 104 / 122  loss: 0.7501599304378033  hr: 2  min: 25  sec: 32\n",
      "epoch: 3  batch: 105 / 122  loss: 0.7504275069350288  hr: 2  min: 25  sec: 21\n",
      "epoch: 3  batch: 106 / 122  loss: 0.7498458002535802  hr: 2  min: 24  sec: 49\n",
      "epoch: 3  batch: 107 / 122  loss: 0.7509863034029988  hr: 2  min: 24  sec: 26\n",
      "epoch: 3  batch: 108 / 122  loss: 0.7507846336121913  hr: 2  min: 24  sec: 16\n",
      "epoch: 3  batch: 109 / 122  loss: 0.7506507894861589  hr: 2  min: 23  sec: 50\n",
      "epoch: 3  batch: 110 / 122  loss: 0.7481763040477579  hr: 2  min: 23  sec: 27\n",
      "epoch: 3  batch: 111 / 122  loss: 0.7490078997504603  hr: 2  min: 23  sec: 30\n",
      "epoch: 3  batch: 112 / 122  loss: 0.7482186957661595  hr: 2  min: 23  sec: 24\n",
      "epoch: 3  batch: 113 / 122  loss: 0.7506022471769721  hr: 2  min: 23  sec: 25\n",
      "epoch: 3  batch: 114 / 122  loss: 0.7495246730875551  hr: 2  min: 23  sec: 6\n",
      "epoch: 3  batch: 115 / 122  loss: 0.7467413829720538  hr: 2  min: 23  sec: 17\n",
      "epoch: 3  batch: 116 / 122  loss: 0.7463842085723219  hr: 2  min: 23  sec: 10\n",
      "epoch: 3  batch: 117 / 122  loss: 0.7460031280150781  hr: 2  min: 22  sec: 49\n",
      "epoch: 3  batch: 118 / 122  loss: 0.7444359508611388  hr: 2  min: 22  sec: 35\n",
      "epoch: 3  batch: 119 / 122  loss: 0.7417255900487179  hr: 2  min: 22  sec: 50\n",
      "epoch: 3  batch: 120 / 122  loss: 0.7391925550997257  hr: 2  min: 22  sec: 39\n",
      "epoch: 3  batch: 121 / 122  loss: 0.7390506516310794  hr: 2  min: 23  sec: 9\n",
      "epoch: 3  batch: 122 / 122  loss: 0.7374904949645527  hr: 2  min: 22  sec: 46\n",
      "Learning rate: 1.6296296296296297e-05\n",
      "Saving...\n",
      "epoch: 4  batch: 1 / 122  loss: 0.9284000992774963  hr: 2  min: 10  sec: 9\n",
      "epoch: 4  batch: 2 / 122  loss: 0.6093029081821442  hr: 2  min: 7  sec: 6\n",
      "epoch: 4  batch: 3 / 122  loss: 0.6413885553677877  hr: 2  min: 10  sec: 41\n",
      "epoch: 4  batch: 4 / 122  loss: 0.5721265152096748  hr: 2  min: 13  sec: 8\n",
      "epoch: 4  batch: 5 / 122  loss: 0.6091325104236602  hr: 2  min: 12  sec: 42\n",
      "epoch: 4  batch: 6 / 122  loss: 0.5559894144535065  hr: 2  min: 10  sec: 26\n",
      "epoch: 4  batch: 7 / 122  loss: 0.5618204644748143  hr: 2  min: 12  sec: 26\n",
      "epoch: 4  batch: 8 / 122  loss: 0.5726405009627342  hr: 2  min: 14  sec: 41\n",
      "epoch: 4  batch: 9 / 122  loss: 0.6103484961721632  hr: 2  min: 25  sec: 54\n",
      "epoch: 4  batch: 10 / 122  loss: 0.598797670006752  hr: 2  min: 26  sec: 55\n",
      "epoch: 4  batch: 11 / 122  loss: 0.5737212029370394  hr: 2  min: 26  sec: 34\n",
      "epoch: 4  batch: 12 / 122  loss: 0.572523777683576  hr: 2  min: 25  sec: 50\n",
      "epoch: 4  batch: 13 / 122  loss: 0.5832650386370145  hr: 2  min: 30  sec: 8\n",
      "epoch: 4  batch: 14 / 122  loss: 0.5806887873581478  hr: 2  min: 27  sec: 34\n",
      "epoch: 4  batch: 15 / 122  loss: 0.5861629803975423  hr: 2  min: 25  sec: 59\n",
      "epoch: 4  batch: 16 / 122  loss: 0.5790666975080967  hr: 2  min: 27  sec: 8\n",
      "epoch: 4  batch: 17 / 122  loss: 0.5872042775154114  hr: 2  min: 24  sec: 39\n",
      "epoch: 4  batch: 18 / 122  loss: 0.5973422229290009  hr: 2  min: 26  sec: 20\n",
      "epoch: 4  batch: 19 / 122  loss: 0.6237745818338896  hr: 2  min: 26  sec: 50\n",
      "epoch: 4  batch: 20 / 122  loss: 0.6160001665353775  hr: 2  min: 31  sec: 12\n",
      "epoch: 4  batch: 21 / 122  loss: 0.6047332570666358  hr: 2  min: 30  sec: 40\n",
      "epoch: 4  batch: 22 / 122  loss: 0.5922288217327811  hr: 2  min: 29  sec: 1\n",
      "epoch: 4  batch: 23 / 122  loss: 0.5825927438943282  hr: 2  min: 28  sec: 16\n",
      "epoch: 4  batch: 24 / 122  loss: 0.5858831529815992  hr: 2  min: 26  sec: 43\n",
      "epoch: 4  batch: 25 / 122  loss: 0.5735715138912201  hr: 2  min: 25  sec: 11\n",
      "epoch: 4  batch: 26 / 122  loss: 0.5808030011562201  hr: 2  min: 24  sec: 35\n",
      "epoch: 4  batch: 27 / 122  loss: 0.5868792213775493  hr: 2  min: 23  sec: 51\n",
      "epoch: 4  batch: 28 / 122  loss: 0.5805677111659732  hr: 2  min: 22  sec: 53\n",
      "epoch: 4  batch: 29 / 122  loss: 0.5935730255883316  hr: 2  min: 24  sec: 11\n",
      "epoch: 4  batch: 30 / 122  loss: 0.5912141819794973  hr: 2  min: 23  sec: 58\n",
      "epoch: 4  batch: 31 / 122  loss: 0.5988142221204696  hr: 2  min: 22  sec: 47\n",
      "epoch: 4  batch: 32 / 122  loss: 0.6017192639410496  hr: 2  min: 22  sec: 50\n",
      "epoch: 4  batch: 33 / 122  loss: 0.6017904389988292  hr: 2  min: 22  sec: 9\n",
      "epoch: 4  batch: 34 / 122  loss: 0.6009928426321816  hr: 2  min: 21  sec: 16\n",
      "epoch: 4  batch: 35 / 122  loss: 0.598190530708858  hr: 2  min: 20  sec: 23\n",
      "epoch: 4  batch: 36 / 122  loss: 0.59608051346408  hr: 2  min: 19  sec: 30\n",
      "epoch: 4  batch: 37 / 122  loss: 0.5858383223011687  hr: 2  min: 19  sec: 17\n",
      "epoch: 4  batch: 38 / 122  loss: 0.5752552939872992  hr: 2  min: 18  sec: 43\n",
      "epoch: 4  batch: 39 / 122  loss: 0.5765245499519202  hr: 2  min: 18  sec: 1\n",
      "epoch: 4  batch: 40 / 122  loss: 0.5761468056589365  hr: 2  min: 17  sec: 51\n",
      "epoch: 4  batch: 41 / 122  loss: 0.5719459387587338  hr: 2  min: 18  sec: 50\n",
      "epoch: 4  batch: 42 / 122  loss: 0.5634353934299379  hr: 2  min: 19  sec: 5\n",
      "epoch: 4  batch: 43 / 122  loss: 0.5663550572339878  hr: 2  min: 18  sec: 16\n",
      "epoch: 4  batch: 44 / 122  loss: 0.5675603131001646  hr: 2  min: 18  sec: 0\n",
      "epoch: 4  batch: 45 / 122  loss: 0.5631868720054627  hr: 2  min: 17  sec: 2\n",
      "epoch: 4  batch: 46 / 122  loss: 0.5584965425988903  hr: 2  min: 16  sec: 33\n",
      "epoch: 4  batch: 47 / 122  loss: 0.5528172546244682  hr: 2  min: 16  sec: 1\n",
      "epoch: 4  batch: 48 / 122  loss: 0.549027631059289  hr: 2  min: 16  sec: 29\n",
      "epoch: 4  batch: 49 / 122  loss: 0.5582877780709948  hr: 2  min: 15  sec: 53\n",
      "epoch: 4  batch: 50 / 122  loss: 0.5571826297044754  hr: 2  min: 15  sec: 58\n",
      "epoch: 4  batch: 51 / 122  loss: 0.5569015314766005  hr: 2  min: 15  sec: 47\n",
      "epoch: 4  batch: 52 / 122  loss: 0.5551494067678084  hr: 2  min: 15  sec: 34\n",
      "epoch: 4  batch: 53 / 122  loss: 0.5524148564293699  hr: 2  min: 16  sec: 11\n",
      "epoch: 4  batch: 54 / 122  loss: 0.5548762209989406  hr: 2  min: 17  sec: 46\n",
      "epoch: 4  batch: 55 / 122  loss: 0.5689893240278417  hr: 2  min: 17  sec: 52\n",
      "epoch: 4  batch: 56 / 122  loss: 0.5736305708331721  hr: 2  min: 17  sec: 16\n",
      "epoch: 4  batch: 57 / 122  loss: 0.5691820325558645  hr: 2  min: 16  sec: 51\n",
      "epoch: 4  batch: 58 / 122  loss: 0.5676641243285147  hr: 2  min: 18  sec: 15\n",
      "epoch: 4  batch: 59 / 122  loss: 0.5715390307418371  hr: 2  min: 17  sec: 50\n",
      "epoch: 4  batch: 60 / 122  loss: 0.5674302404125532  hr: 2  min: 17  sec: 54\n",
      "epoch: 4  batch: 61 / 122  loss: 0.5657247598053979  hr: 2  min: 17  sec: 26\n",
      "epoch: 4  batch: 62 / 122  loss: 0.5690007527028361  hr: 2  min: 17  sec: 7\n",
      "epoch: 4  batch: 63 / 122  loss: 0.5679450612219553  hr: 2  min: 17  sec: 0\n",
      "epoch: 4  batch: 64 / 122  loss: 0.5708342669531703  hr: 2  min: 16  sec: 28\n",
      "epoch: 4  batch: 65 / 122  loss: 0.5721896914335397  hr: 2  min: 16  sec: 6\n",
      "epoch: 4  batch: 66 / 122  loss: 0.5741159563714807  hr: 2  min: 16  sec: 3\n",
      "epoch: 4  batch: 67 / 122  loss: 0.5744586711499229  hr: 2  min: 15  sec: 25\n",
      "epoch: 4  batch: 68 / 122  loss: 0.5728491763858234  hr: 2  min: 14  sec: 59\n",
      "epoch: 4  batch: 69 / 122  loss: 0.5695819172306337  hr: 2  min: 14  sec: 33\n",
      "epoch: 4  batch: 70 / 122  loss: 0.5711418219975063  hr: 2  min: 14  sec: 8\n",
      "epoch: 4  batch: 71 / 122  loss: 0.5700954161059688  hr: 2  min: 14  sec: 39\n",
      "epoch: 4  batch: 72 / 122  loss: 0.5692541015644869  hr: 2  min: 14  sec: 55\n",
      "epoch: 4  batch: 73 / 122  loss: 0.5711641168757661  hr: 2  min: 14  sec: 36\n",
      "epoch: 4  batch: 74 / 122  loss: 0.5725668125055932  hr: 2  min: 13  sec: 57\n",
      "epoch: 4  batch: 75 / 122  loss: 0.5760762782891592  hr: 2  min: 13  sec: 49\n",
      "epoch: 4  batch: 76 / 122  loss: 0.5787336500851732  hr: 2  min: 13  sec: 34\n",
      "epoch: 4  batch: 77 / 122  loss: 0.5773171364486992  hr: 2  min: 13  sec: 22\n",
      "epoch: 4  batch: 78 / 122  loss: 0.5751969734063516  hr: 2  min: 13  sec: 13\n",
      "epoch: 4  batch: 79 / 122  loss: 0.5776999438110786  hr: 2  min: 13  sec: 17\n",
      "epoch: 4  batch: 80 / 122  loss: 0.5784289937466383  hr: 2  min: 13  sec: 7\n",
      "epoch: 4  batch: 81 / 122  loss: 0.5767686613547949  hr: 2  min: 12  sec: 30\n",
      "epoch: 4  batch: 82 / 122  loss: 0.5745001882314682  hr: 2  min: 11  sec: 58\n",
      "epoch: 4  batch: 83 / 122  loss: 0.5732294216931585  hr: 2  min: 11  sec: 36\n",
      "epoch: 4  batch: 84 / 122  loss: 0.5744343183579899  hr: 2  min: 11  sec: 28\n",
      "epoch: 4  batch: 85 / 122  loss: 0.5778803667601418  hr: 2  min: 11  sec: 3\n",
      "epoch: 4  batch: 86 / 122  loss: 0.5746353819619777  hr: 2  min: 11  sec: 28\n",
      "epoch: 4  batch: 87 / 122  loss: 0.577353632655637  hr: 2  min: 11  sec: 37\n",
      "epoch: 4  batch: 88 / 122  loss: 0.5802662105045535  hr: 2  min: 12  sec: 29\n",
      "epoch: 4  batch: 89 / 122  loss: 0.580686479137185  hr: 2  min: 12  sec: 14\n",
      "epoch: 4  batch: 90 / 122  loss: 0.585677804880672  hr: 2  min: 11  sec: 59\n",
      "epoch: 4  batch: 91 / 122  loss: 0.5890029311835111  hr: 2  min: 12  sec: 11\n",
      "epoch: 4  batch: 92 / 122  loss: 0.5898880605464396  hr: 2  min: 12  sec: 46\n",
      "epoch: 4  batch: 93 / 122  loss: 0.587902884329519  hr: 2  min: 12  sec: 44\n",
      "epoch: 4  batch: 94 / 122  loss: 0.5856194122040526  hr: 2  min: 12  sec: 46\n",
      "epoch: 4  batch: 95 / 122  loss: 0.5873085335681313  hr: 2  min: 12  sec: 20\n",
      "epoch: 4  batch: 96 / 122  loss: 0.5890651407341162  hr: 2  min: 12  sec: 7\n",
      "epoch: 4  batch: 97 / 122  loss: 0.5882995048749078  hr: 2  min: 11  sec: 37\n",
      "epoch: 4  batch: 98 / 122  loss: 0.5863083020156744  hr: 2  min: 12  sec: 17\n",
      "epoch: 4  batch: 99 / 122  loss: 0.5869178094647147  hr: 2  min: 12  sec: 3\n",
      "epoch: 4  batch: 100 / 122  loss: 0.5875994929671288  hr: 2  min: 11  sec: 57\n",
      "Validation Loss after 100 batches: 0.660013847053051\n",
      "epoch: 4  batch: 101 / 122  loss: 0.5870606382884601  hr: 2  min: 12  sec: 10\n",
      "epoch: 4  batch: 102 / 122  loss: 0.586510923855445  hr: 2  min: 12  sec: 1\n",
      "epoch: 4  batch: 103 / 122  loss: 0.5862323986095133  hr: 2  min: 11  sec: 56\n",
      "epoch: 4  batch: 104 / 122  loss: 0.5832763431737056  hr: 2  min: 11  sec: 35\n",
      "epoch: 4  batch: 105 / 122  loss: 0.5802862652710505  hr: 2  min: 11  sec: 22\n",
      "epoch: 4  batch: 106 / 122  loss: 0.5817770668358173  hr: 2  min: 11  sec: 12\n",
      "epoch: 4  batch: 107 / 122  loss: 0.5832504415623495  hr: 2  min: 11  sec: 9\n",
      "epoch: 4  batch: 108 / 122  loss: 0.5834399177520363  hr: 2  min: 11  sec: 40\n",
      "epoch: 4  batch: 109 / 122  loss: 0.5835655383560636  hr: 2  min: 12  sec: 10\n",
      "epoch: 4  batch: 110 / 122  loss: 0.5807491660118103  hr: 2  min: 12  sec: 5\n",
      "epoch: 4  batch: 111 / 122  loss: 0.5845071807637945  hr: 2  min: 11  sec: 48\n",
      "epoch: 4  batch: 112 / 122  loss: 0.5843357337372643  hr: 2  min: 11  sec: 36\n",
      "epoch: 4  batch: 113 / 122  loss: 0.583400798846135  hr: 2  min: 11  sec: 21\n",
      "epoch: 4  batch: 114 / 122  loss: 0.5850982490861625  hr: 2  min: 11  sec: 17\n",
      "epoch: 4  batch: 115 / 122  loss: 0.5845364371071691  hr: 2  min: 10  sec: 56\n",
      "epoch: 4  batch: 116 / 122  loss: 0.5864429625457731  hr: 2  min: 10  sec: 34\n",
      "epoch: 4  batch: 117 / 122  loss: 0.5853230423397489  hr: 2  min: 10  sec: 20\n",
      "epoch: 4  batch: 118 / 122  loss: 0.5858362231214168  hr: 2  min: 10  sec: 1\n",
      "epoch: 4  batch: 119 / 122  loss: 0.5829419538754375  hr: 2  min: 10  sec: 11\n",
      "epoch: 4  batch: 120 / 122  loss: 0.5863395273685456  hr: 2  min: 10  sec: 11\n",
      "epoch: 4  batch: 121 / 122  loss: 0.5854095464402979  hr: 2  min: 10  sec: 6\n",
      "epoch: 4  batch: 122 / 122  loss: 0.5842317259702526  hr: 2  min: 9  sec: 57\n",
      "Learning rate: 1.4814814814814815e-05\n",
      "Saving...\n",
      "epoch: 5  batch: 1 / 122  loss: 0.832634449005127  hr: 2  min: 0  sec: 29\n",
      "epoch: 5  batch: 2 / 122  loss: 0.649835467338562  hr: 2  min: 3  sec: 0\n",
      "epoch: 5  batch: 3 / 122  loss: 0.6351476709047953  hr: 1  min: 58  sec: 3\n",
      "epoch: 5  batch: 4 / 122  loss: 0.6018304824829102  hr: 2  min: 3  sec: 25\n",
      "epoch: 5  batch: 5 / 122  loss: 0.5541168272495269  hr: 2  min: 4  sec: 30\n",
      "epoch: 5  batch: 6 / 122  loss: 0.5427694569031397  hr: 2  min: 4  sec: 53\n",
      "epoch: 5  batch: 7 / 122  loss: 0.5005214703934533  hr: 2  min: 0  sec: 6\n",
      "epoch: 5  batch: 8 / 122  loss: 0.47941927798092365  hr: 1  min: 59  sec: 22\n",
      "epoch: 5  batch: 9 / 122  loss: 0.4836493283510208  hr: 1  min: 58  sec: 33\n",
      "epoch: 5  batch: 10 / 122  loss: 0.4656550422310829  hr: 1  min: 59  sec: 1\n",
      "epoch: 5  batch: 11 / 122  loss: 0.4609685391187668  hr: 1  min: 59  sec: 38\n",
      "epoch: 5  batch: 12 / 122  loss: 0.4673737945655982  hr: 2  min: 2  sec: 13\n",
      "epoch: 5  batch: 13 / 122  loss: 0.4411325099376532  hr: 2  min: 4  sec: 9\n",
      "epoch: 5  batch: 14 / 122  loss: 0.4358377956918308  hr: 2  min: 2  sec: 41\n",
      "epoch: 5  batch: 15 / 122  loss: 0.42625361581643423  hr: 2  min: 10  sec: 10\n",
      "epoch: 5  batch: 16 / 122  loss: 0.410188764333725  hr: 2  min: 13  sec: 29\n",
      "epoch: 5  batch: 17 / 122  loss: 0.4148833716616911  hr: 2  min: 13  sec: 5\n",
      "epoch: 5  batch: 18 / 122  loss: 0.41387924883100724  hr: 2  min: 13  sec: 7\n",
      "epoch: 5  batch: 19 / 122  loss: 0.4158574562323721  hr: 2  min: 13  sec: 17\n",
      "epoch: 5  batch: 20 / 122  loss: 0.41601266115903857  hr: 2  min: 14  sec: 31\n",
      "epoch: 5  batch: 21 / 122  loss: 0.4286050470102401  hr: 2  min: 16  sec: 3\n",
      "epoch: 5  batch: 22 / 122  loss: 0.4175275747071613  hr: 2  min: 15  sec: 57\n",
      "epoch: 5  batch: 23 / 122  loss: 0.41097724372925964  hr: 2  min: 15  sec: 42\n",
      "epoch: 5  batch: 24 / 122  loss: 0.40438934974372387  hr: 2  min: 15  sec: 3\n",
      "epoch: 5  batch: 25 / 122  loss: 0.3992286783456802  hr: 2  min: 16  sec: 31\n",
      "epoch: 5  batch: 26 / 122  loss: 0.39608368564110535  hr: 2  min: 16  sec: 22\n",
      "epoch: 5  batch: 27 / 122  loss: 0.4125345509361338  hr: 2  min: 19  sec: 44\n",
      "epoch: 5  batch: 28 / 122  loss: 0.3997726082535727  hr: 2  min: 20  sec: 4\n",
      "epoch: 5  batch: 29 / 122  loss: 0.4015586873323753  hr: 2  min: 19  sec: 48\n",
      "epoch: 5  batch: 30 / 122  loss: 0.40758021113773185  hr: 2  min: 23  sec: 14\n",
      "epoch: 5  batch: 31 / 122  loss: 0.42368179595758837  hr: 2  min: 23  sec: 20\n",
      "epoch: 5  batch: 32 / 122  loss: 0.4138723775977269  hr: 2  min: 22  sec: 14\n",
      "epoch: 5  batch: 33 / 122  loss: 0.41038340747807966  hr: 2  min: 21  sec: 20\n",
      "epoch: 5  batch: 34 / 122  loss: 0.40132252269369717  hr: 2  min: 20  sec: 58\n",
      "epoch: 5  batch: 35 / 122  loss: 0.4021737312631948  hr: 2  min: 23  sec: 46\n",
      "epoch: 5  batch: 36 / 122  loss: 0.4044019001432591  hr: 2  min: 23  sec: 35\n",
      "epoch: 5  batch: 37 / 122  loss: 0.4138432726062633  hr: 2  min: 23  sec: 17\n",
      "epoch: 5  batch: 38 / 122  loss: 0.4045566401787494  hr: 2  min: 23  sec: 46\n",
      "epoch: 5  batch: 39 / 122  loss: 0.3976543858074225  hr: 2  min: 23  sec: 47\n",
      "epoch: 5  batch: 40 / 122  loss: 0.39224853431805967  hr: 2  min: 24  sec: 6\n",
      "epoch: 5  batch: 41 / 122  loss: 0.391239057862904  hr: 2  min: 23  sec: 36\n",
      "epoch: 5  batch: 42 / 122  loss: 0.3857131574657701  hr: 2  min: 22  sec: 55\n",
      "epoch: 5  batch: 43 / 122  loss: 0.3900769854527573  hr: 2  min: 22  sec: 57\n",
      "epoch: 5  batch: 44 / 122  loss: 0.3874341272325678  hr: 2  min: 22  sec: 26\n",
      "epoch: 5  batch: 45 / 122  loss: 0.3892316920061906  hr: 2  min: 22  sec: 26\n",
      "epoch: 5  batch: 46 / 122  loss: 0.3896729624627725  hr: 2  min: 21  sec: 59\n",
      "epoch: 5  batch: 47 / 122  loss: 0.3866118721346906  hr: 2  min: 22  sec: 8\n",
      "epoch: 5  batch: 48 / 122  loss: 0.3863159165872882  hr: 2  min: 22  sec: 8\n",
      "epoch: 5  batch: 49 / 122  loss: 0.3895352053246936  hr: 2  min: 21  sec: 47\n",
      "epoch: 5  batch: 50 / 122  loss: 0.3913181712478399  hr: 2  min: 21  sec: 30\n",
      "epoch: 5  batch: 51 / 122  loss: 0.39114952226187666  hr: 2  min: 20  sec: 52\n",
      "epoch: 5  batch: 52 / 122  loss: 0.3962511812121822  hr: 2  min: 21  sec: 20\n",
      "epoch: 5  batch: 53 / 122  loss: 0.39665883463227525  hr: 2  min: 21  sec: 10\n",
      "epoch: 5  batch: 54 / 122  loss: 0.3974164941658576  hr: 2  min: 20  sec: 54\n",
      "epoch: 5  batch: 55 / 122  loss: 0.40402546111832965  hr: 2  min: 21  sec: 23\n",
      "epoch: 5  batch: 56 / 122  loss: 0.4088759972447796  hr: 2  min: 20  sec: 58\n",
      "epoch: 5  batch: 57 / 122  loss: 0.4047661229575935  hr: 2  min: 20  sec: 20\n",
      "epoch: 5  batch: 58 / 122  loss: 0.4015506076273219  hr: 2  min: 21  sec: 9\n",
      "epoch: 5  batch: 59 / 122  loss: 0.4004567176482435  hr: 2  min: 21  sec: 40\n",
      "epoch: 5  batch: 60 / 122  loss: 0.4122968059654037  hr: 2  min: 21  sec: 50\n",
      "epoch: 5  batch: 61 / 122  loss: 0.4075264877593908  hr: 2  min: 21  sec: 51\n",
      "epoch: 5  batch: 62 / 122  loss: 0.4096389735538152  hr: 2  min: 21  sec: 52\n",
      "epoch: 5  batch: 63 / 122  loss: 0.41356345354801133  hr: 2  min: 22  sec: 0\n",
      "epoch: 5  batch: 64 / 122  loss: 0.4224529243656434  hr: 2  min: 21  sec: 13\n",
      "epoch: 5  batch: 65 / 122  loss: 0.42331694186880037  hr: 2  min: 20  sec: 58\n",
      "epoch: 5  batch: 66 / 122  loss: 0.423835418949073  hr: 2  min: 20  sec: 28\n",
      "epoch: 5  batch: 67 / 122  loss: 0.4249958187452893  hr: 2  min: 19  sec: 55\n",
      "epoch: 5  batch: 68 / 122  loss: 0.4277732745360802  hr: 2  min: 19  sec: 49\n",
      "epoch: 5  batch: 69 / 122  loss: 0.42504903096435726  hr: 2  min: 20  sec: 29\n",
      "epoch: 5  batch: 70 / 122  loss: 0.42264437616935796  hr: 2  min: 20  sec: 0\n",
      "epoch: 5  batch: 71 / 122  loss: 0.42714532690358836  hr: 2  min: 19  sec: 58\n",
      "epoch: 5  batch: 72 / 122  loss: 0.4275289822059373  hr: 2  min: 19  sec: 40\n",
      "epoch: 5  batch: 73 / 122  loss: 0.42925506080054254  hr: 2  min: 19  sec: 18\n",
      "epoch: 5  batch: 74 / 122  loss: 0.431214000576654  hr: 2  min: 18  sec: 54\n",
      "epoch: 5  batch: 75 / 122  loss: 0.43360489115118983  hr: 2  min: 19  sec: 27\n",
      "epoch: 5  batch: 76 / 122  loss: 0.4347572113436304  hr: 2  min: 19  sec: 37\n",
      "epoch: 5  batch: 77 / 122  loss: 0.4348388510187725  hr: 2  min: 19  sec: 43\n",
      "epoch: 5  batch: 78 / 122  loss: 0.4364826161987506  hr: 2  min: 20  sec: 41\n",
      "epoch: 5  batch: 79 / 122  loss: 0.4370483528303949  hr: 2  min: 21  sec: 20\n",
      "epoch: 5  batch: 80 / 122  loss: 0.43681285516358914  hr: 2  min: 21  sec: 51\n",
      "epoch: 5  batch: 81 / 122  loss: 0.4354932895505134  hr: 2  min: 21  sec: 55\n",
      "epoch: 5  batch: 82 / 122  loss: 0.4380264804221508  hr: 2  min: 21  sec: 56\n",
      "epoch: 5  batch: 83 / 122  loss: 0.438064097505377  hr: 2  min: 22  sec: 18\n",
      "epoch: 5  batch: 84 / 122  loss: 0.44154139062655823  hr: 2  min: 22  sec: 6\n",
      "epoch: 5  batch: 85 / 122  loss: 0.4407200429807691  hr: 2  min: 21  sec: 40\n",
      "epoch: 5  batch: 86 / 122  loss: 0.4415929991925179  hr: 2  min: 22  sec: 40\n",
      "epoch: 5  batch: 87 / 122  loss: 0.44197259094009456  hr: 2  min: 22  sec: 32\n",
      "epoch: 5  batch: 88 / 122  loss: 0.4403566953895444  hr: 2  min: 22  sec: 25\n",
      "epoch: 5  batch: 89 / 122  loss: 0.4402899851373742  hr: 2  min: 22  sec: 9\n",
      "epoch: 5  batch: 90 / 122  loss: 0.44027481563389304  hr: 2  min: 21  sec: 52\n",
      "epoch: 5  batch: 91 / 122  loss: 0.4376416336130965  hr: 2  min: 21  sec: 52\n",
      "epoch: 5  batch: 92 / 122  loss: 0.43925256107974314  hr: 2  min: 21  sec: 42\n",
      "epoch: 5  batch: 93 / 122  loss: 0.4382650777296994  hr: 2  min: 21  sec: 41\n",
      "epoch: 5  batch: 94 / 122  loss: 0.4387711852868187  hr: 2  min: 21  sec: 49\n",
      "epoch: 5  batch: 95 / 122  loss: 0.4421643008134867  hr: 2  min: 21  sec: 48\n",
      "epoch: 5  batch: 96 / 122  loss: 0.4418370126513764  hr: 2  min: 21  sec: 32\n",
      "epoch: 5  batch: 97 / 122  loss: 0.4403427162198062  hr: 2  min: 21  sec: 13\n",
      "epoch: 5  batch: 98 / 122  loss: 0.43886986910840686  hr: 2  min: 20  sec: 56\n",
      "epoch: 5  batch: 99 / 122  loss: 0.4389498909991799  hr: 2  min: 20  sec: 35\n",
      "epoch: 5  batch: 100 / 122  loss: 0.4364575697854161  hr: 2  min: 20  sec: 1\n",
      "Validation Loss after 100 batches: 0.6817643269896507\n",
      "epoch: 5  batch: 101 / 122  loss: 0.43658873663827924  hr: 2  min: 19  sec: 51\n",
      "epoch: 5  batch: 102 / 122  loss: 0.43345596717999263  hr: 2  min: 19  sec: 50\n",
      "epoch: 5  batch: 103 / 122  loss: 0.42987990028505185  hr: 2  min: 20  sec: 5\n",
      "epoch: 5  batch: 104 / 122  loss: 0.43061213592927045  hr: 2  min: 20  sec: 27\n",
      "epoch: 5  batch: 105 / 122  loss: 0.42803644534377827  hr: 2  min: 20  sec: 15\n",
      "epoch: 5  batch: 106 / 122  loss: 0.42973335983477673  hr: 2  min: 20  sec: 21\n",
      "epoch: 5  batch: 107 / 122  loss: 0.43287297355655197  hr: 2  min: 20  sec: 35\n",
      "epoch: 5  batch: 108 / 122  loss: 0.43479734297013944  hr: 2  min: 20  sec: 16\n",
      "epoch: 5  batch: 109 / 122  loss: 0.43423729612056267  hr: 2  min: 20  sec: 11\n",
      "epoch: 5  batch: 110 / 122  loss: 0.4342661616138437  hr: 2  min: 19  sec: 57\n",
      "epoch: 5  batch: 111 / 122  loss: 0.43795151508471986  hr: 2  min: 19  sec: 45\n",
      "epoch: 5  batch: 112 / 122  loss: 0.436626791920779  hr: 2  min: 19  sec: 41\n",
      "epoch: 5  batch: 113 / 122  loss: 0.4401184299021168  hr: 2  min: 19  sec: 16\n",
      "epoch: 5  batch: 114 / 122  loss: 0.44250954344476523  hr: 2  min: 19  sec: 2\n",
      "epoch: 5  batch: 115 / 122  loss: 0.440508565403845  hr: 2  min: 18  sec: 35\n",
      "epoch: 5  batch: 116 / 122  loss: 0.44398622288657674  hr: 2  min: 18  sec: 24\n",
      "epoch: 5  batch: 117 / 122  loss: 0.4458420462269559  hr: 2  min: 18  sec: 10\n",
      "epoch: 5  batch: 118 / 122  loss: 0.44873112058109144  hr: 2  min: 18  sec: 40\n",
      "epoch: 5  batch: 119 / 122  loss: 0.44946821919885005  hr: 2  min: 19  sec: 10\n",
      "epoch: 5  batch: 120 / 122  loss: 0.44994815411046146  hr: 2  min: 18  sec: 47\n",
      "epoch: 5  batch: 121 / 122  loss: 0.4492288992609367  hr: 2  min: 18  sec: 36\n",
      "epoch: 5  batch: 122 / 122  loss: 0.44755756155755677  hr: 2  min: 18  sec: 27\n",
      "Learning rate: 1.3333333333333333e-05\n",
      "epoch: 6  batch: 1 / 122  loss: 0.4241376221179962  hr: 2  min: 45  sec: 55\n",
      "epoch: 6  batch: 2 / 122  loss: 0.4450525492429733  hr: 2  min: 21  sec: 24\n",
      "epoch: 6  batch: 3 / 122  loss: 0.39435669779777527  hr: 2  min: 24  sec: 34\n",
      "epoch: 6  batch: 4 / 122  loss: 0.38480719178915024  hr: 2  min: 19  sec: 55\n",
      "epoch: 6  batch: 5 / 122  loss: 0.3518949538469315  hr: 2  min: 11  sec: 48\n",
      "epoch: 6  batch: 6 / 122  loss: 0.32282071312268573  hr: 2  min: 14  sec: 36\n",
      "epoch: 6  batch: 7 / 122  loss: 0.3193196952342987  hr: 2  min: 11  sec: 43\n",
      "epoch: 6  batch: 8 / 122  loss: 0.3018771018832922  hr: 2  min: 13  sec: 46\n",
      "epoch: 6  batch: 9 / 122  loss: 0.31314199997319114  hr: 2  min: 22  sec: 49\n",
      "epoch: 6  batch: 10 / 122  loss: 0.32405177801847457  hr: 2  min: 25  sec: 18\n",
      "epoch: 6  batch: 11 / 122  loss: 0.33748613568869507  hr: 2  min: 29  sec: 28\n",
      "epoch: 6  batch: 12 / 122  loss: 0.3270220384001732  hr: 2  min: 25  sec: 2\n",
      "epoch: 6  batch: 13 / 122  loss: 0.3207498135475012  hr: 2  min: 23  sec: 59\n",
      "epoch: 6  batch: 14 / 122  loss: 0.30946229504687445  hr: 2  min: 21  sec: 24\n",
      "epoch: 6  batch: 15 / 122  loss: 0.30064905285835264  hr: 2  min: 19  sec: 40\n",
      "epoch: 6  batch: 16 / 122  loss: 0.2908507538959384  hr: 2  min: 18  sec: 31\n",
      "epoch: 6  batch: 17 / 122  loss: 0.30606433486237244  hr: 2  min: 23  sec: 31\n",
      "epoch: 6  batch: 18 / 122  loss: 0.30635575701793033  hr: 2  min: 23  sec: 46\n",
      "epoch: 6  batch: 19 / 122  loss: 0.3126917285354514  hr: 2  min: 21  sec: 15\n",
      "epoch: 6  batch: 20 / 122  loss: 0.3060800716280937  hr: 2  min: 19  sec: 48\n",
      "epoch: 6  batch: 21 / 122  loss: 0.29739351180337725  hr: 2  min: 19  sec: 14\n",
      "epoch: 6  batch: 22 / 122  loss: 0.30498276752504433  hr: 2  min: 17  sec: 20\n",
      "epoch: 6  batch: 23 / 122  loss: 0.30192769318819046  hr: 2  min: 16  sec: 2\n",
      "epoch: 6  batch: 24 / 122  loss: 0.3023643863076965  hr: 2  min: 15  sec: 43\n",
      "epoch: 6  batch: 25 / 122  loss: 0.3018126544356346  hr: 2  min: 15  sec: 43\n",
      "epoch: 6  batch: 26 / 122  loss: 0.3080043021876078  hr: 2  min: 14  sec: 29\n",
      "epoch: 6  batch: 27 / 122  loss: 0.3088477913428236  hr: 2  min: 13  sec: 28\n",
      "epoch: 6  batch: 28 / 122  loss: 0.3167341284986053  hr: 2  min: 11  sec: 46\n",
      "epoch: 6  batch: 29 / 122  loss: 0.3176322998157863  hr: 2  min: 10  sec: 15\n",
      "epoch: 6  batch: 30 / 122  loss: 0.3157664972047011  hr: 2  min: 9  sec: 19\n",
      "epoch: 6  batch: 31 / 122  loss: 0.3290541227306089  hr: 2  min: 7  sec: 57\n",
      "epoch: 6  batch: 32 / 122  loss: 0.3264704660978168  hr: 2  min: 7  sec: 33\n",
      "epoch: 6  batch: 33 / 122  loss: 0.3312312895149896  hr: 2  min: 6  sec: 52\n",
      "epoch: 6  batch: 34 / 122  loss: 0.3383389086846043  hr: 2  min: 8  sec: 25\n",
      "epoch: 6  batch: 35 / 122  loss: 0.33166130908897945  hr: 2  min: 7  sec: 26\n",
      "epoch: 6  batch: 36 / 122  loss: 0.3264407776296139  hr: 2  min: 7  sec: 12\n",
      "epoch: 6  batch: 37 / 122  loss: 0.3243183630543786  hr: 2  min: 6  sec: 27\n",
      "epoch: 6  batch: 38 / 122  loss: 0.31935935467481613  hr: 2  min: 5  sec: 54\n",
      "epoch: 6  batch: 39 / 122  loss: 0.3128787554227389  hr: 2  min: 4  sec: 36\n",
      "epoch: 6  batch: 40 / 122  loss: 0.3157308675348759  hr: 2  min: 3  sec: 46\n",
      "epoch: 6  batch: 41 / 122  loss: 0.30863349425901726  hr: 2  min: 3  sec: 17\n",
      "epoch: 6  batch: 42 / 122  loss: 0.31903561909816097  hr: 2  min: 2  sec: 41\n",
      "epoch: 6  batch: 43 / 122  loss: 0.32057390478981096  hr: 2  min: 2  sec: 22\n",
      "epoch: 6  batch: 44 / 122  loss: 0.31689392533999955  hr: 2  min: 1  sec: 28\n",
      "epoch: 6  batch: 45 / 122  loss: 0.31402670174009273  hr: 2  min: 1  sec: 50\n",
      "epoch: 6  batch: 46 / 122  loss: 0.3125576706927108  hr: 2  min: 0  sec: 58\n",
      "epoch: 6  batch: 47 / 122  loss: 0.3151239352895224  hr: 2  min: 0  sec: 33\n",
      "epoch: 6  batch: 48 / 122  loss: 0.3180214681585009  hr: 1  min: 59  sec: 57\n",
      "epoch: 6  batch: 49 / 122  loss: 0.3124128073377877  hr: 1  min: 59  sec: 19\n",
      "epoch: 6  batch: 50 / 122  loss: 0.32615799229592085  hr: 1  min: 58  sec: 32\n",
      "epoch: 6  batch: 51 / 122  loss: 0.32239553372503493  hr: 1  min: 57  sec: 52\n",
      "epoch: 6  batch: 52 / 122  loss: 0.32577136141033125  hr: 1  min: 58  sec: 31\n",
      "epoch: 6  batch: 53 / 122  loss: 0.3212906552021796  hr: 1  min: 57  sec: 50\n",
      "epoch: 6  batch: 54 / 122  loss: 0.31998682653324473  hr: 1  min: 57  sec: 20\n",
      "epoch: 6  batch: 55 / 122  loss: 0.3199200350791216  hr: 1  min: 57  sec: 8\n",
      "epoch: 6  batch: 56 / 122  loss: 0.3205576929862478  hr: 1  min: 57  sec: 6\n",
      "epoch: 6  batch: 57 / 122  loss: 0.3230837575372374  hr: 1  min: 56  sec: 37\n",
      "epoch: 6  batch: 58 / 122  loss: 0.32111433890230695  hr: 1  min: 56  sec: 20\n",
      "epoch: 6  batch: 59 / 122  loss: 0.32497875793379244  hr: 1  min: 56  sec: 6\n",
      "epoch: 6  batch: 60 / 122  loss: 0.3239557462123533  hr: 1  min: 56  sec: 21\n",
      "epoch: 6  batch: 61 / 122  loss: 0.3255482298612106  hr: 1  min: 55  sec: 55\n",
      "epoch: 6  batch: 62 / 122  loss: 0.3311330476295083  hr: 1  min: 55  sec: 22\n",
      "epoch: 6  batch: 63 / 122  loss: 0.3306538057883108  hr: 1  min: 55  sec: 19\n",
      "epoch: 6  batch: 64 / 122  loss: 0.3281303362164181  hr: 1  min: 54  sec: 57\n",
      "epoch: 6  batch: 65 / 122  loss: 0.3306964504890717  hr: 1  min: 54  sec: 47\n",
      "epoch: 6  batch: 66 / 122  loss: 0.3347659812901508  hr: 1  min: 54  sec: 41\n",
      "epoch: 6  batch: 67 / 122  loss: 0.34124688845850637  hr: 1  min: 54  sec: 13\n",
      "epoch: 6  batch: 68 / 122  loss: 0.34275087514234814  hr: 1  min: 53  sec: 49\n",
      "epoch: 6  batch: 69 / 122  loss: 0.34309472875210684  hr: 1  min: 53  sec: 45\n",
      "epoch: 6  batch: 70 / 122  loss: 0.3399729129193085  hr: 1  min: 53  sec: 17\n",
      "epoch: 6  batch: 71 / 122  loss: 0.3416106747856862  hr: 1  min: 53  sec: 3\n",
      "epoch: 6  batch: 72 / 122  loss: 0.34656159214985865  hr: 1  min: 52  sec: 36\n",
      "epoch: 6  batch: 73 / 122  loss: 0.3457641283892197  hr: 1  min: 52  sec: 5\n",
      "epoch: 6  batch: 74 / 122  loss: 0.3442460595302888  hr: 1  min: 51  sec: 47\n",
      "epoch: 6  batch: 75 / 122  loss: 0.34912573563555876  hr: 1  min: 51  sec: 55\n",
      "epoch: 6  batch: 76 / 122  loss: 0.3487316827583862  hr: 1  min: 51  sec: 42\n",
      "epoch: 6  batch: 77 / 122  loss: 0.34921979388923613  hr: 1  min: 51  sec: 44\n",
      "epoch: 6  batch: 78 / 122  loss: 0.35303351309341496  hr: 1  min: 51  sec: 16\n",
      "epoch: 6  batch: 79 / 122  loss: 0.3541263616113346  hr: 1  min: 50  sec: 43\n",
      "epoch: 6  batch: 80 / 122  loss: 0.3551151579944417  hr: 1  min: 50  sec: 25\n",
      "epoch: 6  batch: 81 / 122  loss: 0.35168906206977957  hr: 1  min: 50  sec: 6\n",
      "epoch: 6  batch: 82 / 122  loss: 0.35368750523775816  hr: 1  min: 49  sec: 53\n",
      "epoch: 6  batch: 83 / 122  loss: 0.3551167225218322  hr: 1  min: 49  sec: 30\n",
      "epoch: 6  batch: 84 / 122  loss: 0.35335111021552057  hr: 1  min: 49  sec: 7\n",
      "epoch: 6  batch: 85 / 122  loss: 0.35208774548681343  hr: 1  min: 48  sec: 56\n",
      "epoch: 6  batch: 86 / 122  loss: 0.35665974252705657  hr: 1  min: 48  sec: 53\n",
      "epoch: 6  batch: 87 / 122  loss: 0.3569596768410384  hr: 1  min: 48  sec: 40\n",
      "epoch: 6  batch: 88 / 122  loss: 0.357422000199387  hr: 1  min: 48  sec: 29\n",
      "epoch: 6  batch: 89 / 122  loss: 0.35770689693980673  hr: 1  min: 48  sec: 7\n",
      "epoch: 6  batch: 90 / 122  loss: 0.3576115991299351  hr: 1  min: 48  sec: 36\n",
      "epoch: 6  batch: 91 / 122  loss: 0.3566368876209298  hr: 1  min: 48  sec: 10\n",
      "epoch: 6  batch: 92 / 122  loss: 0.35887026841468783  hr: 1  min: 48  sec: 24\n",
      "epoch: 6  batch: 93 / 122  loss: 0.35827019191797704  hr: 1  min: 48  sec: 10\n",
      "epoch: 6  batch: 94 / 122  loss: 0.35899261105805635  hr: 1  min: 48  sec: 24\n",
      "epoch: 6  batch: 95 / 122  loss: 0.35915361131100276  hr: 1  min: 48  sec: 4\n",
      "epoch: 6  batch: 96 / 122  loss: 0.3583315799284416  hr: 1  min: 47  sec: 43\n",
      "epoch: 6  batch: 97 / 122  loss: 0.35805116814666804  hr: 1  min: 47  sec: 39\n",
      "epoch: 6  batch: 98 / 122  loss: 0.3566771452790316  hr: 1  min: 47  sec: 24\n",
      "epoch: 6  batch: 99 / 122  loss: 0.35531972610212936  hr: 1  min: 47  sec: 2\n",
      "epoch: 6  batch: 100 / 122  loss: 0.352642385866493  hr: 1  min: 47  sec: 13\n",
      "Validation Loss after 100 batches: 0.747661241889\n",
      "epoch: 6  batch: 101 / 122  loss: 0.3503532091542931  hr: 1  min: 47  sec: 5\n",
      "epoch: 6  batch: 102 / 122  loss: 0.34841533843427896  hr: 1  min: 46  sec: 54\n",
      "epoch: 6  batch: 103 / 122  loss: 0.3462322912567738  hr: 1  min: 46  sec: 44\n",
      "epoch: 6  batch: 104 / 122  loss: 0.34407388159217167  hr: 1  min: 46  sec: 31\n",
      "epoch: 6  batch: 105 / 122  loss: 0.34446741198854786  hr: 1  min: 46  sec: 52\n",
      "epoch: 6  batch: 106 / 122  loss: 0.3423198777655104  hr: 1  min: 46  sec: 39\n",
      "epoch: 6  batch: 107 / 122  loss: 0.3416652819925101  hr: 1  min: 46  sec: 43\n",
      "epoch: 6  batch: 108 / 122  loss: 0.3399853921426391  hr: 1  min: 46  sec: 41\n",
      "epoch: 6  batch: 109 / 122  loss: 0.3376251422039686  hr: 1  min: 46  sec: 22\n",
      "epoch: 6  batch: 110 / 122  loss: 0.33960490997203374  hr: 1  min: 46  sec: 10\n",
      "epoch: 6  batch: 111 / 122  loss: 0.3394317450924768  hr: 1  min: 46  sec: 10\n",
      "epoch: 6  batch: 112 / 122  loss: 0.3375062052260286  hr: 1  min: 46  sec: 31\n",
      "epoch: 6  batch: 113 / 122  loss: 0.33625417036226896  hr: 1  min: 46  sec: 49\n",
      "epoch: 6  batch: 114 / 122  loss: 0.33652624420887023  hr: 1  min: 47  sec: 7\n",
      "epoch: 6  batch: 115 / 122  loss: 0.3354739847228579  hr: 1  min: 46  sec: 53\n",
      "epoch: 6  batch: 116 / 122  loss: 0.33963037511847655  hr: 1  min: 46  sec: 57\n",
      "epoch: 6  batch: 117 / 122  loss: 0.3369354413042211  hr: 1  min: 46  sec: 41\n",
      "epoch: 6  batch: 118 / 122  loss: 0.3416198381869975  hr: 1  min: 46  sec: 27\n",
      "epoch: 6  batch: 119 / 122  loss: 0.3396269540388544  hr: 1  min: 46  sec: 5\n",
      "epoch: 6  batch: 120 / 122  loss: 0.3413979233863453  hr: 1  min: 45  sec: 51\n",
      "epoch: 6  batch: 121 / 122  loss: 0.3430217850860978  hr: 1  min: 45  sec: 34\n",
      "epoch: 6  batch: 122 / 122  loss: 0.34325139972640845  hr: 1  min: 45  sec: 28\n",
      "Learning rate: 1.1851851851851852e-05\n",
      "epoch: 7  batch: 1 / 122  loss: 0.04532693699002266  hr: 1  min: 38  sec: 5\n",
      "epoch: 7  batch: 2 / 122  loss: 0.07304819114506245  hr: 1  min: 44  sec: 12\n",
      "epoch: 7  batch: 3 / 122  loss: 0.11790718759099643  hr: 2  min: 4  sec: 18\n",
      "epoch: 7  batch: 4 / 122  loss: 0.0953799169510603  hr: 1  min: 58  sec: 37\n",
      "epoch: 7  batch: 5 / 122  loss: 0.08871427848935128  hr: 1  min: 54  sec: 56\n",
      "epoch: 7  batch: 6 / 122  loss: 0.09638932906091213  hr: 1  min: 58  sec: 7\n",
      "epoch: 7  batch: 7 / 122  loss: 0.14139638681496894  hr: 1  min: 57  sec: 5\n",
      "epoch: 7  batch: 8 / 122  loss: 0.19561998592689633  hr: 2  min: 3  sec: 10\n",
      "epoch: 7  batch: 9 / 122  loss: 0.1875783730712202  hr: 1  min: 58  sec: 12\n",
      "epoch: 7  batch: 10 / 122  loss: 0.20742055736482143  hr: 1  min: 53  sec: 47\n",
      "epoch: 7  batch: 11 / 122  loss: 0.22653962502425368  hr: 1  min: 51  sec: 34\n",
      "epoch: 7  batch: 12 / 122  loss: 0.2124676996221145  hr: 1  min: 49  sec: 42\n",
      "epoch: 7  batch: 13 / 122  loss: 0.2048335109765713  hr: 1  min: 50  sec: 22\n",
      "epoch: 7  batch: 14 / 122  loss: 0.21385905678783143  hr: 1  min: 51  sec: 4\n",
      "epoch: 7  batch: 15 / 122  loss: 0.20320371488730113  hr: 1  min: 49  sec: 5\n",
      "epoch: 7  batch: 16 / 122  loss: 0.21153466310352087  hr: 1  min: 48  sec: 57\n",
      "epoch: 7  batch: 17 / 122  loss: 0.20225221378838315  hr: 1  min: 46  sec: 55\n",
      "epoch: 7  batch: 18 / 122  loss: 0.19872656485272777  hr: 1  min: 45  sec: 41\n",
      "epoch: 7  batch: 19 / 122  loss: 0.20117722000730665  hr: 1  min: 44  sec: 17\n",
      "epoch: 7  batch: 20 / 122  loss: 0.19430732373148202  hr: 1  min: 42  sec: 37\n",
      "epoch: 7  batch: 21 / 122  loss: 0.20449413376904668  hr: 1  min: 41  sec: 37\n",
      "epoch: 7  batch: 22 / 122  loss: 0.21916076083752242  hr: 1  min: 40  sec: 46\n",
      "epoch: 7  batch: 23 / 122  loss: 0.21710160909139592  hr: 1  min: 39  sec: 52\n",
      "epoch: 7  batch: 24 / 122  loss: 0.20971430310358605  hr: 1  min: 39  sec: 37\n",
      "epoch: 7  batch: 25 / 122  loss: 0.21971455067396164  hr: 1  min: 39  sec: 35\n",
      "epoch: 7  batch: 26 / 122  loss: 0.21523029529131377  hr: 1  min: 39  sec: 48\n",
      "epoch: 7  batch: 27 / 122  loss: 0.21935559974776375  hr: 1  min: 39  sec: 39\n",
      "epoch: 7  batch: 28 / 122  loss: 0.21338452398777008  hr: 1  min: 38  sec: 47\n",
      "epoch: 7  batch: 29 / 122  loss: 0.20823231005463108  hr: 1  min: 38  sec: 48\n",
      "epoch: 7  batch: 30 / 122  loss: 0.20763652250170708  hr: 1  min: 38  sec: 40\n",
      "epoch: 7  batch: 31 / 122  loss: 0.20931034439033078  hr: 1  min: 38  sec: 11\n",
      "epoch: 7  batch: 32 / 122  loss: 0.20526244887150824  hr: 1  min: 38  sec: 25\n",
      "epoch: 7  batch: 33 / 122  loss: 0.21891451988256339  hr: 1  min: 40  sec: 16\n",
      "epoch: 7  batch: 34 / 122  loss: 0.2131017848082325  hr: 1  min: 40  sec: 21\n",
      "epoch: 7  batch: 35 / 122  loss: 0.20946734063327313  hr: 1  min: 39  sec: 31\n",
      "epoch: 7  batch: 36 / 122  loss: 0.21536668664258388  hr: 1  min: 39  sec: 3\n",
      "epoch: 7  batch: 37 / 122  loss: 0.21605754487619205  hr: 1  min: 39  sec: 7\n",
      "epoch: 7  batch: 38 / 122  loss: 0.21092683880736954  hr: 1  min: 38  sec: 40\n",
      "epoch: 7  batch: 39 / 122  loss: 0.230418022053364  hr: 1  min: 37  sec: 56\n",
      "epoch: 7  batch: 40 / 122  loss: 0.2275803629308939  hr: 1  min: 37  sec: 4\n",
      "epoch: 7  batch: 41 / 122  loss: 0.22537138876391621  hr: 1  min: 36  sec: 47\n",
      "epoch: 7  batch: 42 / 122  loss: 0.2242948434182576  hr: 1  min: 36  sec: 51\n",
      "epoch: 7  batch: 43 / 122  loss: 0.23111483038857925  hr: 1  min: 36  sec: 47\n",
      "epoch: 7  batch: 44 / 122  loss: 0.2298655780878934  hr: 1  min: 36  sec: 21\n",
      "epoch: 7  batch: 45 / 122  loss: 0.2354354480902354  hr: 1  min: 37  sec: 23\n",
      "epoch: 7  batch: 46 / 122  loss: 0.23436646293038907  hr: 1  min: 37  sec: 17\n",
      "epoch: 7  batch: 47 / 122  loss: 0.23008056555656678  hr: 1  min: 37  sec: 7\n",
      "epoch: 7  batch: 48 / 122  loss: 0.22776152519509196  hr: 1  min: 36  sec: 40\n",
      "epoch: 7  batch: 49 / 122  loss: 0.23630577888415785  hr: 1  min: 36  sec: 12\n",
      "epoch: 7  batch: 50 / 122  loss: 0.2431606574356556  hr: 1  min: 37  sec: 19\n",
      "epoch: 7  batch: 51 / 122  loss: 0.24450294074474596  hr: 1  min: 36  sec: 49\n",
      "epoch: 7  batch: 52 / 122  loss: 0.2537284242705657  hr: 1  min: 36  sec: 41\n",
      "epoch: 7  batch: 53 / 122  loss: 0.2492470912424461  hr: 1  min: 36  sec: 14\n",
      "epoch: 7  batch: 54 / 122  loss: 0.24551592329172073  hr: 1  min: 36  sec: 0\n",
      "epoch: 7  batch: 55 / 122  loss: 0.2523352487859401  hr: 1  min: 36  sec: 17\n",
      "epoch: 7  batch: 56 / 122  loss: 0.2511390290954815  hr: 1  min: 35  sec: 52\n",
      "epoch: 7  batch: 57 / 122  loss: 0.24854874797165394  hr: 1  min: 35  sec: 59\n",
      "epoch: 7  batch: 58 / 122  loss: 0.24484494177560354  hr: 1  min: 35  sec: 59\n",
      "epoch: 7  batch: 59 / 122  loss: 0.2434998910116442  hr: 1  min: 35  sec: 38\n",
      "epoch: 7  batch: 60 / 122  loss: 0.24479890493676065  hr: 1  min: 35  sec: 32\n",
      "epoch: 7  batch: 61 / 122  loss: 0.24172903600408405  hr: 1  min: 36  sec: 47\n",
      "epoch: 7  batch: 62 / 122  loss: 0.2498680163595465  hr: 1  min: 37  sec: 38\n",
      "epoch: 7  batch: 63 / 122  loss: 0.24801860823636018  hr: 1  min: 37  sec: 44\n",
      "epoch: 7  batch: 64 / 122  loss: 0.24698650839854963  hr: 1  min: 38  sec: 17\n",
      "epoch: 7  batch: 65 / 122  loss: 0.24556534545352826  hr: 1  min: 39  sec: 3\n",
      "epoch: 7  batch: 66 / 122  loss: 0.24463952967727726  hr: 1  min: 39  sec: 18\n",
      "epoch: 7  batch: 67 / 122  loss: 0.24363323893231242  hr: 1  min: 39  sec: 12\n",
      "epoch: 7  batch: 68 / 122  loss: 0.2457263016361086  hr: 1  min: 39  sec: 16\n",
      "epoch: 7  batch: 69 / 122  loss: 0.2569027485028989  hr: 1  min: 39  sec: 57\n",
      "epoch: 7  batch: 70 / 122  loss: 0.25491090834672964  hr: 1  min: 40  sec: 31\n",
      "epoch: 7  batch: 71 / 122  loss: 0.2576989173941629  hr: 1  min: 40  sec: 37\n",
      "epoch: 7  batch: 72 / 122  loss: 0.2603266449489941  hr: 1  min: 41  sec: 4\n",
      "epoch: 7  batch: 73 / 122  loss: 0.2616696785625121  hr: 1  min: 41  sec: 8\n",
      "epoch: 7  batch: 74 / 122  loss: 0.25955032086553603  hr: 1  min: 41  sec: 12\n",
      "epoch: 7  batch: 75 / 122  loss: 0.2565499349683523  hr: 1  min: 41  sec: 5\n",
      "epoch: 7  batch: 76 / 122  loss: 0.2542389655044596  hr: 1  min: 42  sec: 6\n",
      "epoch: 7  batch: 77 / 122  loss: 0.25366734125494184  hr: 1  min: 41  sec: 55\n",
      "epoch: 7  batch: 78 / 122  loss: 0.25334976940678483  hr: 1  min: 42  sec: 31\n",
      "epoch: 7  batch: 79 / 122  loss: 0.25078823415067375  hr: 1  min: 42  sec: 6\n",
      "epoch: 7  batch: 80 / 122  loss: 0.24776962480973452  hr: 1  min: 41  sec: 49\n",
      "epoch: 7  batch: 81 / 122  loss: 0.2548202998062343  hr: 1  min: 41  sec: 24\n",
      "epoch: 7  batch: 82 / 122  loss: 0.2582276006251937  hr: 1  min: 41  sec: 13\n",
      "epoch: 7  batch: 83 / 122  loss: 0.25583278152149125  hr: 1  min: 40  sec: 44\n",
      "epoch: 7  batch: 84 / 122  loss: 0.2579944632903096  hr: 1  min: 40  sec: 12\n",
      "epoch: 7  batch: 85 / 122  loss: 0.2552472227636506  hr: 1  min: 40  sec: 0\n",
      "epoch: 7  batch: 86 / 122  loss: 0.2534543193530205  hr: 1  min: 39  sec: 36\n",
      "epoch: 7  batch: 87 / 122  loss: 0.2520512581385415  hr: 1  min: 39  sec: 52\n",
      "epoch: 7  batch: 88 / 122  loss: 0.25167780970646575  hr: 1  min: 39  sec: 41\n",
      "epoch: 7  batch: 89 / 122  loss: 0.24979020228211798  hr: 1  min: 39  sec: 30\n",
      "epoch: 7  batch: 90 / 122  loss: 0.2518857339190112  hr: 1  min: 39  sec: 23\n",
      "epoch: 7  batch: 91 / 122  loss: 0.25039600007809126  hr: 1  min: 39  sec: 18\n",
      "epoch: 7  batch: 92 / 122  loss: 0.25322728628373664  hr: 1  min: 38  sec: 49\n",
      "epoch: 7  batch: 93 / 122  loss: 0.25494195112297613  hr: 1  min: 38  sec: 43\n",
      "epoch: 7  batch: 94 / 122  loss: 0.2546149168084276  hr: 1  min: 38  sec: 30\n",
      "epoch: 7  batch: 95 / 122  loss: 0.2525339372063938  hr: 1  min: 38  sec: 10\n",
      "epoch: 7  batch: 96 / 122  loss: 0.25117702479474247  hr: 1  min: 37  sec: 55\n",
      "epoch: 7  batch: 97 / 122  loss: 0.24986535280021197  hr: 1  min: 37  sec: 36\n",
      "epoch: 7  batch: 98 / 122  loss: 0.2508359268611791  hr: 1  min: 37  sec: 23\n",
      "epoch: 7  batch: 99 / 122  loss: 0.2501109554009004  hr: 1  min: 37  sec: 36\n",
      "epoch: 7  batch: 100 / 122  loss: 0.24779292630031705  hr: 1  min: 37  sec: 19\n",
      "Validation Loss after 100 batches: 0.9165867224335671\n",
      "epoch: 7  batch: 101 / 122  loss: 0.24828251298185033  hr: 1  min: 36  sec: 59\n",
      "epoch: 7  batch: 102 / 122  loss: 0.2461726756255124  hr: 1  min: 36  sec: 50\n",
      "epoch: 7  batch: 103 / 122  loss: 0.24386961857598383  hr: 1  min: 36  sec: 30\n",
      "epoch: 7  batch: 104 / 122  loss: 0.24470955274927503  hr: 1  min: 36  sec: 16\n",
      "epoch: 7  batch: 105 / 122  loss: 0.2469529566133306  hr: 1  min: 36  sec: 3\n",
      "epoch: 7  batch: 106 / 122  loss: 0.24770097910725283  hr: 1  min: 35  sec: 50\n",
      "epoch: 7  batch: 107 / 122  loss: 0.2466759979550805  hr: 1  min: 35  sec: 34\n",
      "epoch: 7  batch: 108 / 122  loss: 0.24448668975727977  hr: 1  min: 35  sec: 14\n",
      "epoch: 7  batch: 109 / 122  loss: 0.24460451774845976  hr: 1  min: 34  sec: 55\n",
      "epoch: 7  batch: 110 / 122  loss: 0.24603803040967745  hr: 1  min: 34  sec: 40\n",
      "epoch: 7  batch: 111 / 122  loss: 0.24425044529945464  hr: 1  min: 34  sec: 35\n",
      "epoch: 7  batch: 112 / 122  loss: 0.2424707735190168  hr: 1  min: 34  sec: 18\n",
      "epoch: 7  batch: 113 / 122  loss: 0.24051041863199357  hr: 1  min: 34  sec: 3\n",
      "epoch: 7  batch: 114 / 122  loss: 0.24045639617466613  hr: 1  min: 33  sec: 53\n",
      "epoch: 7  batch: 115 / 122  loss: 0.2393651525773432  hr: 1  min: 33  sec: 40\n",
      "epoch: 7  batch: 116 / 122  loss: 0.24003564272525496  hr: 1  min: 33  sec: 44\n",
      "epoch: 7  batch: 117 / 122  loss: 0.24188266517833257  hr: 1  min: 33  sec: 50\n",
      "epoch: 7  batch: 118 / 122  loss: 0.24386315011435142  hr: 1  min: 33  sec: 28\n",
      "epoch: 7  batch: 119 / 122  loss: 0.24289131867347144  hr: 1  min: 33  sec: 11\n",
      "epoch: 7  batch: 120 / 122  loss: 0.24197993714672825  hr: 1  min: 32  sec: 56\n",
      "epoch: 7  batch: 121 / 122  loss: 0.24211577604686427  hr: 1  min: 32  sec: 39\n",
      "epoch: 7  batch: 122 / 122  loss: 0.24152269289202866  hr: 1  min: 32  sec: 21\n",
      "Learning rate: 1.037037037037037e-05\n",
      "epoch: 8  batch: 1 / 122  loss: 0.2430005967617035  hr: 2  min: 9  sec: 32\n",
      "epoch: 8  batch: 2 / 122  loss: 0.18487470597028732  hr: 1  min: 59  sec: 10\n",
      "epoch: 8  batch: 3 / 122  loss: 0.16861925522486368  hr: 1  min: 46  sec: 27\n",
      "epoch: 8  batch: 4 / 122  loss: 0.16184397786855698  hr: 1  min: 41  sec: 14\n",
      "epoch: 8  batch: 5 / 122  loss: 0.14452869445085526  hr: 1  min: 36  sec: 10\n",
      "epoch: 8  batch: 6 / 122  loss: 0.14080284287532172  hr: 1  min: 32  sec: 51\n",
      "epoch: 8  batch: 7 / 122  loss: 0.12715180111782892  hr: 1  min: 31  sec: 58\n",
      "epoch: 8  batch: 8 / 122  loss: 0.1280859624966979  hr: 1  min: 29  sec: 23\n",
      "epoch: 8  batch: 9 / 122  loss: 0.1186232173608409  hr: 1  min: 28  sec: 38\n",
      "epoch: 8  batch: 10 / 122  loss: 0.13215274251997472  hr: 1  min: 29  sec: 5\n",
      "epoch: 8  batch: 11 / 122  loss: 0.1232127117162401  hr: 1  min: 28  sec: 3\n",
      "epoch: 8  batch: 12 / 122  loss: 0.11672768586625655  hr: 1  min: 26  sec: 44\n",
      "epoch: 8  batch: 13 / 122  loss: 0.11226501860297643  hr: 1  min: 25  sec: 30\n",
      "epoch: 8  batch: 14 / 122  loss: 0.10546386308435883  hr: 1  min: 26  sec: 15\n",
      "epoch: 8  batch: 15 / 122  loss: 0.10038636649648348  hr: 1  min: 28  sec: 9\n",
      "epoch: 8  batch: 16 / 122  loss: 0.10688314330764115  hr: 1  min: 27  sec: 37\n",
      "epoch: 8  batch: 17 / 122  loss: 0.11678159346475321  hr: 1  min: 28  sec: 4\n",
      "epoch: 8  batch: 18 / 122  loss: 0.11171471834596661  hr: 1  min: 26  sec: 39\n",
      "epoch: 8  batch: 19 / 122  loss: 0.12091049483340037  hr: 1  min: 29  sec: 4\n",
      "epoch: 8  batch: 20 / 122  loss: 0.12490665400400758  hr: 1  min: 28  sec: 52\n",
      "epoch: 8  batch: 21 / 122  loss: 0.12048354789259888  hr: 1  min: 28  sec: 13\n",
      "epoch: 8  batch: 22 / 122  loss: 0.11687611915509809  hr: 1  min: 27  sec: 51\n",
      "epoch: 8  batch: 23 / 122  loss: 0.11219401317446129  hr: 1  min: 26  sec: 38\n",
      "epoch: 8  batch: 24 / 122  loss: 0.10785845775778095  hr: 1  min: 26  sec: 21\n",
      "epoch: 8  batch: 25 / 122  loss: 0.10391177602112293  hr: 1  min: 27  sec: 19\n",
      "epoch: 8  batch: 26 / 122  loss: 0.1040919661665192  hr: 1  min: 27  sec: 26\n",
      "epoch: 8  batch: 27 / 122  loss: 0.10206343806176274  hr: 1  min: 27  sec: 18\n",
      "epoch: 8  batch: 28 / 122  loss: 0.10143717637817774  hr: 1  min: 26  sec: 33\n",
      "epoch: 8  batch: 29 / 122  loss: 0.11947212901351781  hr: 1  min: 25  sec: 52\n",
      "epoch: 8  batch: 30 / 122  loss: 0.11806547958403826  hr: 1  min: 26  sec: 56\n",
      "epoch: 8  batch: 31 / 122  loss: 0.11707895988177869  hr: 1  min: 26  sec: 24\n",
      "epoch: 8  batch: 32 / 122  loss: 0.1198202384985052  hr: 1  min: 26  sec: 5\n",
      "epoch: 8  batch: 33 / 122  loss: 0.11679945062055733  hr: 1  min: 25  sec: 36\n",
      "epoch: 8  batch: 34 / 122  loss: 0.12328928040669244  hr: 1  min: 25  sec: 33\n",
      "epoch: 8  batch: 35 / 122  loss: 0.12010598459414074  hr: 1  min: 25  sec: 22\n",
      "epoch: 8  batch: 36 / 122  loss: 0.11861260338789886  hr: 1  min: 25  sec: 16\n",
      "epoch: 8  batch: 37 / 122  loss: 0.11623354729365658  hr: 1  min: 25  sec: 10\n",
      "epoch: 8  batch: 38 / 122  loss: 0.12320033215770596  hr: 1  min: 25  sec: 11\n",
      "epoch: 8  batch: 39 / 122  loss: 0.12963510581698173  hr: 1  min: 24  sec: 33\n",
      "epoch: 8  batch: 40 / 122  loss: 0.12651022538775578  hr: 1  min: 24  sec: 6\n",
      "epoch: 8  batch: 41 / 122  loss: 0.12769982306195832  hr: 1  min: 24  sec: 35\n",
      "epoch: 8  batch: 42 / 122  loss: 0.1277842182510843  hr: 1  min: 25  sec: 53\n",
      "epoch: 8  batch: 43 / 122  loss: 0.12663855435066793  hr: 1  min: 25  sec: 9\n",
      "epoch: 8  batch: 44 / 122  loss: 0.12391454799481752  hr: 1  min: 25  sec: 38\n",
      "epoch: 8  batch: 45 / 122  loss: 0.12280029328539968  hr: 1  min: 26  sec: 7\n",
      "epoch: 8  batch: 46 / 122  loss: 0.12036617473780137  hr: 1  min: 26  sec: 18\n",
      "epoch: 8  batch: 47 / 122  loss: 0.1274310697682519  hr: 1  min: 26  sec: 7\n",
      "epoch: 8  batch: 48 / 122  loss: 0.12828709729365073  hr: 1  min: 25  sec: 44\n",
      "epoch: 8  batch: 49 / 122  loss: 0.12787510197115493  hr: 1  min: 25  sec: 33\n",
      "epoch: 8  batch: 50 / 122  loss: 0.13080328003503383  hr: 1  min: 25  sec: 42\n",
      "epoch: 8  batch: 51 / 122  loss: 0.12943472129785838  hr: 1  min: 25  sec: 7\n",
      "epoch: 8  batch: 52 / 122  loss: 0.1270610589372854  hr: 1  min: 24  sec: 48\n",
      "epoch: 8  batch: 53 / 122  loss: 0.12475180907069512  hr: 1  min: 24  sec: 46\n",
      "epoch: 8  batch: 54 / 122  loss: 0.12907301938092267  hr: 1  min: 24  sec: 38\n",
      "epoch: 8  batch: 55 / 122  loss: 0.1269014698029919  hr: 1  min: 24  sec: 37\n",
      "epoch: 8  batch: 56 / 122  loss: 0.1319972700605701  hr: 1  min: 24  sec: 29\n",
      "epoch: 8  batch: 57 / 122  loss: 0.13001909798109218  hr: 1  min: 24  sec: 5\n",
      "epoch: 8  batch: 58 / 122  loss: 0.1432927723428042  hr: 1  min: 23  sec: 40\n",
      "epoch: 8  batch: 59 / 122  loss: 0.15101633130935793  hr: 1  min: 23  sec: 27\n",
      "epoch: 8  batch: 60 / 122  loss: 0.15442358502186834  hr: 1  min: 23  sec: 8\n",
      "epoch: 8  batch: 61 / 122  loss: 0.15202453808828456  hr: 1  min: 22  sec: 35\n",
      "epoch: 8  batch: 62 / 122  loss: 0.15780181392666795  hr: 1  min: 22  sec: 22\n",
      "epoch: 8  batch: 63 / 122  loss: 0.1617132763836592  hr: 1  min: 22  sec: 5\n",
      "epoch: 8  batch: 64 / 122  loss: 0.1593659905192908  hr: 1  min: 21  sec: 51\n",
      "epoch: 8  batch: 65 / 122  loss: 0.16324497492840656  hr: 1  min: 21  sec: 44\n",
      "epoch: 8  batch: 66 / 122  loss: 0.16256728359131198  hr: 1  min: 21  sec: 27\n",
      "epoch: 8  batch: 67 / 122  loss: 0.1635188362213658  hr: 1  min: 21  sec: 6\n",
      "epoch: 8  batch: 68 / 122  loss: 0.16121668531559408  hr: 1  min: 20  sec: 41\n",
      "epoch: 8  batch: 69 / 122  loss: 0.15985577714130067  hr: 1  min: 20  sec: 30\n",
      "epoch: 8  batch: 70 / 122  loss: 0.1650749540621681  hr: 1  min: 20  sec: 14\n",
      "epoch: 8  batch: 71 / 122  loss: 0.17071099032346213  hr: 1  min: 20  sec: 14\n",
      "epoch: 8  batch: 72 / 122  loss: 0.16851464825837562  hr: 1  min: 20  sec: 51\n",
      "epoch: 8  batch: 73 / 122  loss: 0.1727788783227132  hr: 1  min: 21  sec: 8\n",
      "epoch: 8  batch: 74 / 122  loss: 0.1748150901340351  hr: 1  min: 21  sec: 46\n",
      "epoch: 8  batch: 75 / 122  loss: 0.17380674909800292  hr: 1  min: 21  sec: 52\n",
      "epoch: 8  batch: 76 / 122  loss: 0.17540416622681446  hr: 1  min: 21  sec: 37\n",
      "epoch: 8  batch: 77 / 122  loss: 0.17830003112215886  hr: 1  min: 21  sec: 20\n",
      "epoch: 8  batch: 78 / 122  loss: 0.17613767500584707  hr: 1  min: 21  sec: 6\n",
      "epoch: 8  batch: 79 / 122  loss: 0.1744239654486315  hr: 1  min: 20  sec: 57\n",
      "epoch: 8  batch: 80 / 122  loss: 0.17313741284888237  hr: 1  min: 21  sec: 11\n",
      "epoch: 8  batch: 81 / 122  loss: 0.17430976794365746  hr: 1  min: 21  sec: 11\n",
      "epoch: 8  batch: 82 / 122  loss: 0.175010159861569  hr: 1  min: 21  sec: 5\n",
      "epoch: 8  batch: 83 / 122  loss: 0.17725208462272063  hr: 1  min: 21  sec: 12\n",
      "epoch: 8  batch: 84 / 122  loss: 0.17671110753768257  hr: 1  min: 21  sec: 19\n",
      "epoch: 8  batch: 85 / 122  loss: 0.1747148115242667  hr: 1  min: 21  sec: 16\n",
      "epoch: 8  batch: 86 / 122  loss: 0.17435491824154417  hr: 1  min: 22  sec: 9\n",
      "epoch: 8  batch: 87 / 122  loss: 0.1764255996161922  hr: 1  min: 22  sec: 27\n",
      "epoch: 8  batch: 88 / 122  loss: 0.1780254086744125  hr: 1  min: 22  sec: 41\n",
      "epoch: 8  batch: 89 / 122  loss: 0.17614864796044283  hr: 1  min: 22  sec: 48\n",
      "epoch: 8  batch: 90 / 122  loss: 0.17528518971780108  hr: 1  min: 22  sec: 43\n",
      "epoch: 8  batch: 91 / 122  loss: 0.17483439865000136  hr: 1  min: 22  sec: 54\n",
      "epoch: 8  batch: 92 / 122  loss: 0.17573605335580753  hr: 1  min: 22  sec: 50\n",
      "epoch: 8  batch: 93 / 122  loss: 0.17395476180238909  hr: 1  min: 22  sec: 40\n",
      "epoch: 8  batch: 94 / 122  loss: 0.17219629474083317  hr: 1  min: 22  sec: 35\n",
      "epoch: 8  batch: 95 / 122  loss: 0.17158718197851588  hr: 1  min: 22  sec: 52\n",
      "epoch: 8  batch: 96 / 122  loss: 0.1699176365849174  hr: 1  min: 22  sec: 57\n",
      "epoch: 8  batch: 97 / 122  loss: 0.16848055676067458  hr: 1  min: 22  sec: 56\n",
      "epoch: 8  batch: 98 / 122  loss: 0.16746586541721256  hr: 1  min: 23  sec: 3\n",
      "epoch: 8  batch: 99 / 122  loss: 0.16586931360734983  hr: 1  min: 22  sec: 50\n",
      "epoch: 8  batch: 100 / 122  loss: 0.16591477239970118  hr: 1  min: 23  sec: 28\n",
      "Validation Loss after 100 batches: 1.028669038414955\n",
      "epoch: 8  batch: 101 / 122  loss: 0.164367175121598  hr: 1  min: 23  sec: 19\n",
      "epoch: 8  batch: 102 / 122  loss: 0.16591091958495477  hr: 1  min: 23  sec: 47\n",
      "epoch: 8  batch: 103 / 122  loss: 0.1659314024117459  hr: 1  min: 23  sec: 56\n",
      "epoch: 8  batch: 104 / 122  loss: 0.1643892934259314  hr: 1  min: 23  sec: 44\n",
      "epoch: 8  batch: 105 / 122  loss: 0.16430599270831972  hr: 1  min: 23  sec: 43\n",
      "epoch: 8  batch: 106 / 122  loss: 0.16356704552780907  hr: 1  min: 23  sec: 39\n",
      "epoch: 8  batch: 107 / 122  loss: 0.16619240053903275  hr: 1  min: 23  sec: 35\n",
      "epoch: 8  batch: 108 / 122  loss: 0.1651532680693048  hr: 1  min: 23  sec: 38\n",
      "epoch: 8  batch: 109 / 122  loss: 0.16370139564942876  hr: 1  min: 23  sec: 27\n",
      "epoch: 8  batch: 110 / 122  loss: 0.1678593556989323  hr: 1  min: 23  sec: 37\n",
      "epoch: 8  batch: 111 / 122  loss: 0.1665748130731486  hr: 1  min: 23  sec: 31\n",
      "epoch: 8  batch: 112 / 122  loss: 0.16611135755998216  hr: 1  min: 23  sec: 30\n",
      "epoch: 8  batch: 113 / 122  loss: 0.16853384797222318  hr: 1  min: 23  sec: 16\n",
      "epoch: 8  batch: 114 / 122  loss: 0.1694195689306709  hr: 1  min: 23  sec: 10\n",
      "epoch: 8  batch: 115 / 122  loss: 0.16807532606889372  hr: 1  min: 23  sec: 4\n",
      "epoch: 8  batch: 116 / 122  loss: 0.16704688502218704  hr: 1  min: 23  sec: 7\n",
      "epoch: 8  batch: 117 / 122  loss: 0.16576074388546821  hr: 1  min: 23  sec: 3\n",
      "epoch: 8  batch: 118 / 122  loss: 0.16446683104386775  hr: 1  min: 23  sec: 2\n",
      "epoch: 8  batch: 119 / 122  loss: 0.16388377650570468  hr: 1  min: 23  sec: 4\n",
      "epoch: 8  batch: 120 / 122  loss: 0.1626602217555046  hr: 1  min: 23  sec: 7\n",
      "epoch: 8  batch: 121 / 122  loss: 0.16149748199857955  hr: 1  min: 23  sec: 11\n",
      "epoch: 8  batch: 122 / 122  loss: 0.16078071494693638  hr: 1  min: 23  sec: 13\n",
      "Learning rate: 8.888888888888888e-06\n",
      "epoch: 9  batch: 1 / 122  loss: 0.024824056774377823  hr: 1  min: 3  sec: 49\n",
      "epoch: 9  batch: 2 / 122  loss: 0.014682709937915206  hr: 1  min: 9  sec: 46\n",
      "epoch: 9  batch: 3 / 122  loss: 0.012175931905706724  hr: 1  min: 27  sec: 30\n",
      "epoch: 9  batch: 4 / 122  loss: 0.0710364650003612  hr: 1  min: 22  sec: 33\n",
      "epoch: 9  batch: 5 / 122  loss: 0.05948488041758537  hr: 1  min: 17  sec: 33\n",
      "epoch: 9  batch: 6 / 122  loss: 0.05039976894234618  hr: 1  min: 16  sec: 22\n",
      "epoch: 9  batch: 7 / 122  loss: 0.13003063082162822  hr: 1  min: 14  sec: 30\n",
      "epoch: 9  batch: 8 / 122  loss: 0.1317895882530138  hr: 1  min: 12  sec: 59\n",
      "epoch: 9  batch: 9 / 122  loss: 0.1307326868797342  hr: 1  min: 12  sec: 16\n",
      "epoch: 9  batch: 10 / 122  loss: 0.11819518473930657  hr: 1  min: 11  sec: 40\n",
      "epoch: 9  batch: 11 / 122  loss: 0.12080105296759443  hr: 1  min: 14  sec: 50\n",
      "epoch: 9  batch: 12 / 122  loss: 0.1584905383254712  hr: 1  min: 16  sec: 1\n",
      "epoch: 9  batch: 13 / 122  loss: 0.14734987259054413  hr: 1  min: 17  sec: 12\n",
      "epoch: 9  batch: 14 / 122  loss: 0.14423325794216776  hr: 1  min: 17  sec: 30\n",
      "epoch: 9  batch: 15 / 122  loss: 0.1550537161839505  hr: 1  min: 18  sec: 23\n",
      "epoch: 9  batch: 16 / 122  loss: 0.15090649973717518  hr: 1  min: 18  sec: 7\n",
      "epoch: 9  batch: 17 / 122  loss: 0.1581828912227031  hr: 1  min: 17  sec: 33\n",
      "epoch: 9  batch: 18 / 122  loss: 0.1499245183594111  hr: 1  min: 17  sec: 38\n",
      "epoch: 9  batch: 19 / 122  loss: 0.14224219662872584  hr: 1  min: 18  sec: 8\n",
      "epoch: 9  batch: 20 / 122  loss: 0.14701046745758503  hr: 1  min: 17  sec: 38\n",
      "epoch: 9  batch: 21 / 122  loss: 0.1401639281262067  hr: 1  min: 17  sec: 41\n",
      "epoch: 9  batch: 22 / 122  loss: 0.13549141944597728  hr: 1  min: 16  sec: 32\n",
      "epoch: 9  batch: 23 / 122  loss: 0.12970059718329296  hr: 1  min: 15  sec: 52\n",
      "epoch: 9  batch: 24 / 122  loss: 0.1244731161762805  hr: 1  min: 15  sec: 39\n",
      "epoch: 9  batch: 25 / 122  loss: 0.11983639785088598  hr: 1  min: 15  sec: 23\n",
      "epoch: 9  batch: 26 / 122  loss: 0.13007753694322532  hr: 1  min: 15  sec: 41\n",
      "epoch: 9  batch: 27 / 122  loss: 0.1280710377851156  hr: 1  min: 14  sec: 57\n",
      "epoch: 9  batch: 28 / 122  loss: 0.12381539208581671  hr: 1  min: 14  sec: 44\n",
      "epoch: 9  batch: 29 / 122  loss: 0.12799690645348666  hr: 1  min: 14  sec: 38\n",
      "epoch: 9  batch: 30 / 122  loss: 0.13045991939337304  hr: 1  min: 14  sec: 16\n",
      "epoch: 9  batch: 31 / 122  loss: 0.1263206916215319  hr: 1  min: 14  sec: 28\n",
      "epoch: 9  batch: 32 / 122  loss: 0.12360396541043883  hr: 1  min: 15  sec: 25\n",
      "epoch: 9  batch: 33 / 122  loss: 0.12398674341172657  hr: 1  min: 16  sec: 39\n",
      "epoch: 9  batch: 34 / 122  loss: 0.12154919075478307  hr: 1  min: 15  sec: 57\n",
      "epoch: 9  batch: 35 / 122  loss: 0.11839276530247714  hr: 1  min: 15  sec: 33\n",
      "epoch: 9  batch: 36 / 122  loss: 0.11532338816646694  hr: 1  min: 15  sec: 20\n",
      "epoch: 9  batch: 37 / 122  loss: 0.11792254472478621  hr: 1  min: 14  sec: 53\n",
      "epoch: 9  batch: 38 / 122  loss: 0.11491628907816975  hr: 1  min: 14  sec: 55\n",
      "epoch: 9  batch: 39 / 122  loss: 0.11421235989874755  hr: 1  min: 15  sec: 28\n",
      "epoch: 9  batch: 40 / 122  loss: 0.11600531837902964  hr: 1  min: 15  sec: 38\n",
      "epoch: 9  batch: 41 / 122  loss: 0.11455732297788306  hr: 1  min: 15  sec: 28\n",
      "epoch: 9  batch: 42 / 122  loss: 0.11215702264702745  hr: 1  min: 15  sec: 20\n",
      "epoch: 9  batch: 43 / 122  loss: 0.10961803660164912  hr: 1  min: 15  sec: 15\n",
      "epoch: 9  batch: 44 / 122  loss: 0.10891214491989971  hr: 1  min: 14  sec: 50\n",
      "epoch: 9  batch: 45 / 122  loss: 0.10715391793702211  hr: 1  min: 14  sec: 35\n",
      "epoch: 9  batch: 46 / 122  loss: 0.104935493011473  hr: 1  min: 14  sec: 11\n",
      "epoch: 9  batch: 47 / 122  loss: 0.10781447257985302  hr: 1  min: 14  sec: 8\n",
      "epoch: 9  batch: 48 / 122  loss: 0.10563769681903068  hr: 1  min: 13  sec: 40\n",
      "epoch: 9  batch: 49 / 122  loss: 0.10779823417471228  hr: 1  min: 13  sec: 30\n",
      "epoch: 9  batch: 50 / 122  loss: 0.1057210709201172  hr: 1  min: 13  sec: 16\n",
      "epoch: 9  batch: 51 / 122  loss: 0.10368256733579305  hr: 1  min: 12  sec: 58\n",
      "epoch: 9  batch: 52 / 122  loss: 0.10942184662473245  hr: 1  min: 12  sec: 36\n",
      "epoch: 9  batch: 53 / 122  loss: 0.11168397396126375  hr: 1  min: 12  sec: 54\n",
      "epoch: 9  batch: 54 / 122  loss: 0.10969262612181613  hr: 1  min: 12  sec: 30\n",
      "epoch: 9  batch: 55 / 122  loss: 0.10869468132838268  hr: 1  min: 12  sec: 16\n",
      "epoch: 9  batch: 56 / 122  loss: 0.10706566906758651  hr: 1  min: 11  sec: 45\n",
      "epoch: 9  batch: 57 / 122  loss: 0.11140484343846574  hr: 1  min: 11  sec: 30\n",
      "epoch: 9  batch: 58 / 122  loss: 0.11029500412104394  hr: 1  min: 11  sec: 8\n",
      "epoch: 9  batch: 59 / 122  loss: 0.10874107057599634  hr: 1  min: 10  sec: 39\n",
      "epoch: 9  batch: 60 / 122  loss: 0.10740469927550293  hr: 1  min: 10  sec: 30\n",
      "epoch: 9  batch: 61 / 122  loss: 0.1090798418049044  hr: 1  min: 10  sec: 11\n",
      "epoch: 9  batch: 62 / 122  loss: 0.10739027947420254  hr: 1  min: 9  sec: 54\n",
      "epoch: 9  batch: 63 / 122  loss: 0.11109751011873226  hr: 1  min: 9  sec: 39\n",
      "epoch: 9  batch: 64 / 122  loss: 0.11282682044657122  hr: 1  min: 9  sec: 30\n",
      "epoch: 9  batch: 65 / 122  loss: 0.11113203639845148  hr: 1  min: 9  sec: 15\n",
      "epoch: 9  batch: 66 / 122  loss: 0.10948852945831745  hr: 1  min: 8  sec: 59\n",
      "epoch: 9  batch: 67 / 122  loss: 0.10795079962065471  hr: 1  min: 8  sec: 50\n",
      "epoch: 9  batch: 68 / 122  loss: 0.10639729552648906  hr: 1  min: 8  sec: 29\n",
      "epoch: 9  batch: 69 / 122  loss: 0.11067192779307294  hr: 1  min: 8  sec: 22\n",
      "epoch: 9  batch: 70 / 122  loss: 0.10925294412798914  hr: 1  min: 8  sec: 5\n",
      "epoch: 9  batch: 71 / 122  loss: 0.11643275657084994  hr: 1  min: 8  sec: 38\n",
      "epoch: 9  batch: 72 / 122  loss: 0.11485543935527352  hr: 1  min: 8  sec: 28\n",
      "epoch: 9  batch: 73 / 122  loss: 0.11767931104388904  hr: 1  min: 8  sec: 33\n",
      "epoch: 9  batch: 74 / 122  loss: 0.12179203538343662  hr: 1  min: 8  sec: 28\n",
      "epoch: 9  batch: 75 / 122  loss: 0.12132552281487734  hr: 1  min: 8  sec: 6\n",
      "epoch: 9  batch: 76 / 122  loss: 0.1197801481175702  hr: 1  min: 8  sec: 7\n",
      "epoch: 9  batch: 77 / 122  loss: 0.11827093724602858  hr: 1  min: 8  sec: 7\n",
      "epoch: 9  batch: 78 / 122  loss: 0.11679593851724161  hr: 1  min: 7  sec: 58\n",
      "epoch: 9  batch: 79 / 122  loss: 0.11695961254100681  hr: 1  min: 7  sec: 43\n",
      "epoch: 9  batch: 80 / 122  loss: 0.11551849115930964  hr: 1  min: 7  sec: 30\n",
      "epoch: 9  batch: 81 / 122  loss: 0.11414447171257142  hr: 1  min: 7  sec: 14\n",
      "epoch: 9  batch: 82 / 122  loss: 0.11537145425440608  hr: 1  min: 7  sec: 11\n",
      "epoch: 9  batch: 83 / 122  loss: 0.11794587702445507  hr: 1  min: 7  sec: 37\n",
      "epoch: 9  batch: 84 / 122  loss: 0.11887892319854083  hr: 1  min: 7  sec: 21\n",
      "epoch: 9  batch: 85 / 122  loss: 0.11752209574915469  hr: 1  min: 7  sec: 5\n",
      "epoch: 9  batch: 86 / 122  loss: 0.11949349332568344  hr: 1  min: 6  sec: 47\n",
      "epoch: 9  batch: 87 / 122  loss: 0.11814015654006695  hr: 1  min: 6  sec: 37\n",
      "epoch: 9  batch: 88 / 122  loss: 0.11772336687929717  hr: 1  min: 6  sec: 27\n",
      "epoch: 9  batch: 89 / 122  loss: 0.11644400455439569  hr: 1  min: 6  sec: 7\n",
      "epoch: 9  batch: 90 / 122  loss: 0.11820954399105782  hr: 1  min: 5  sec: 51\n",
      "epoch: 9  batch: 91 / 122  loss: 0.11693740436157396  hr: 1  min: 5  sec: 45\n",
      "epoch: 9  batch: 92 / 122  loss: 0.12060715862089241  hr: 1  min: 5  sec: 30\n",
      "epoch: 9  batch: 93 / 122  loss: 0.12100602787173283  hr: 1  min: 5  sec: 27\n",
      "epoch: 9  batch: 94 / 122  loss: 0.11981071981210063  hr: 1  min: 5  sec: 22\n",
      "epoch: 9  batch: 95 / 122  loss: 0.11877959595723568  hr: 1  min: 5  sec: 20\n",
      "epoch: 9  batch: 96 / 122  loss: 0.11805230920072063  hr: 1  min: 5  sec: 14\n",
      "epoch: 9  batch: 97 / 122  loss: 0.11827118462071629  hr: 1  min: 5  sec: 9\n",
      "epoch: 9  batch: 98 / 122  loss: 0.11709832997959373  hr: 1  min: 5  sec: 0\n",
      "epoch: 9  batch: 99 / 122  loss: 0.11594645105739773  hr: 1  min: 4  sec: 54\n",
      "epoch: 9  batch: 100 / 122  loss: 0.11485046448768116  hr: 1  min: 4  sec: 53\n",
      "Validation Loss after 100 batches: 1.1342928931117058\n",
      "epoch: 9  batch: 101 / 122  loss: 0.11372861158711338  hr: 1  min: 4  sec: 36\n",
      "epoch: 9  batch: 102 / 122  loss: 0.11263269297641647  hr: 1  min: 4  sec: 20\n",
      "epoch: 9  batch: 103 / 122  loss: 0.11156681256630974  hr: 1  min: 4  sec: 14\n",
      "epoch: 9  batch: 104 / 122  loss: 0.11050586862144812  hr: 1  min: 4  sec: 3\n",
      "epoch: 9  batch: 105 / 122  loss: 0.10974750661934238  hr: 1  min: 3  sec: 50\n",
      "epoch: 9  batch: 106 / 122  loss: 0.11235889315688631  hr: 1  min: 3  sec: 52\n",
      "epoch: 9  batch: 107 / 122  loss: 0.11277010467090583  hr: 1  min: 3  sec: 45\n",
      "epoch: 9  batch: 108 / 122  loss: 0.11173718489051142  hr: 1  min: 3  sec: 40\n",
      "epoch: 9  batch: 109 / 122  loss: 0.11072727915865087  hr: 1  min: 3  sec: 36\n",
      "epoch: 9  batch: 110 / 122  loss: 0.10972940391141243  hr: 1  min: 3  sec: 39\n",
      "epoch: 9  batch: 111 / 122  loss: 0.10874917334352562  hr: 1  min: 3  sec: 24\n",
      "epoch: 9  batch: 112 / 122  loss: 0.10828736929709391  hr: 1  min: 3  sec: 37\n",
      "epoch: 9  batch: 113 / 122  loss: 0.11070146681679066  hr: 1  min: 3  sec: 32\n",
      "epoch: 9  batch: 114 / 122  loss: 0.10974397717591114  hr: 1  min: 3  sec: 23\n",
      "epoch: 9  batch: 115 / 122  loss: 0.10936505306795563  hr: 1  min: 3  sec: 32\n",
      "epoch: 9  batch: 116 / 122  loss: 0.10843017287170996  hr: 1  min: 3  sec: 35\n",
      "epoch: 9  batch: 117 / 122  loss: 0.10751645181837499  hr: 1  min: 3  sec: 46\n",
      "epoch: 9  batch: 118 / 122  loss: 0.10661170599386253  hr: 1  min: 3  sec: 33\n",
      "epoch: 9  batch: 119 / 122  loss: 0.10572572331582078  hr: 1  min: 3  sec: 28\n",
      "epoch: 9  batch: 120 / 122  loss: 0.10765905942632041  hr: 1  min: 3  sec: 14\n",
      "epoch: 9  batch: 121 / 122  loss: 0.10679918895610262  hr: 1  min: 3  sec: 9\n",
      "epoch: 9  batch: 122 / 122  loss: 0.10931474579685199  hr: 1  min: 3  sec: 8\n",
      "Learning rate: 7.4074074074074075e-06\n",
      "epoch: 10  batch: 1 / 122  loss: 0.7291958928108215  hr: 1  min: 0  sec: 45\n",
      "epoch: 10  batch: 2 / 122  loss: 0.39550669863820076  hr: 1  min: 20  sec: 36\n",
      "epoch: 10  batch: 3 / 122  loss: 0.29118648171424866  hr: 1  min: 20  sec: 53\n",
      "epoch: 10  batch: 4 / 122  loss: 0.21896833495702595  hr: 1  min: 14  sec: 46\n",
      "epoch: 10  batch: 5 / 122  loss: 0.21756288362666965  hr: 1  min: 9  sec: 52\n",
      "epoch: 10  batch: 6 / 122  loss: 0.1917747031742086  hr: 1  min: 8  sec: 41\n",
      "epoch: 10  batch: 7 / 122  loss: 0.1646607456662293  hr: 1  min: 7  sec: 54\n",
      "epoch: 10  batch: 8 / 122  loss: 0.17705141587066464  hr: 1  min: 7  sec: 1\n",
      "epoch: 10  batch: 9 / 122  loss: 0.15773198893293738  hr: 1  min: 7  sec: 2\n",
      "epoch: 10  batch: 10 / 122  loss: 0.15903899571858346  hr: 1  min: 6  sec: 1\n",
      "epoch: 10  batch: 11 / 122  loss: 0.14912786652249369  hr: 1  min: 4  sec: 25\n",
      "epoch: 10  batch: 12 / 122  loss: 0.1433393934664006  hr: 1  min: 3  sec: 51\n",
      "epoch: 10  batch: 13 / 122  loss: 0.13295182266917366  hr: 1  min: 4  sec: 3\n",
      "epoch: 10  batch: 14 / 122  loss: 0.12734690278635494  hr: 1  min: 3  sec: 19\n",
      "epoch: 10  batch: 15 / 122  loss: 0.11915756420542796  hr: 1  min: 2  sec: 7\n",
      "epoch: 10  batch: 16 / 122  loss: 0.11428524676011875  hr: 1  min: 4  sec: 37\n",
      "epoch: 10  batch: 17 / 122  loss: 0.10803458373993635  hr: 1  min: 3  sec: 53\n",
      "epoch: 10  batch: 18 / 122  loss: 0.10273786525552471  hr: 1  min: 4  sec: 1\n",
      "epoch: 10  batch: 19 / 122  loss: 0.1019174085537854  hr: 1  min: 5  sec: 40\n",
      "epoch: 10  batch: 20 / 122  loss: 0.09777681301347911  hr: 1  min: 5  sec: 13\n",
      "epoch: 10  batch: 21 / 122  loss: 0.09418126865334454  hr: 1  min: 4  sec: 30\n",
      "epoch: 10  batch: 22 / 122  loss: 0.10236750742081892  hr: 1  min: 3  sec: 48\n",
      "epoch: 10  batch: 23 / 122  loss: 0.09805311678665811  hr: 1  min: 3  sec: 8\n",
      "epoch: 10  batch: 24 / 122  loss: 0.09438417924684472  hr: 1  min: 2  sec: 22\n",
      "epoch: 10  batch: 25 / 122  loss: 0.09072967323474586  hr: 1  min: 1  sec: 39\n",
      "epoch: 10  batch: 26 / 122  loss: 0.09934027180469666  hr: 1  min: 1  sec: 22\n",
      "epoch: 10  batch: 27 / 122  loss: 0.10366607459986375  hr: 1  min: 1  sec: 26\n",
      "epoch: 10  batch: 28 / 122  loss: 0.10004367753364411  hr: 1  min: 1  sec: 33\n",
      "epoch: 10  batch: 29 / 122  loss: 0.10487743101789263  hr: 1  min: 1  sec: 14\n",
      "epoch: 10  batch: 30 / 122  loss: 0.10146449659174929  hr: 1  min: 1  sec: 6\n",
      "epoch: 10  batch: 31 / 122  loss: 0.0982958048942589  hr: 1  min: 0  sec: 40\n",
      "epoch: 10  batch: 32 / 122  loss: 0.10588584741344675  hr: 1  min: 0  sec: 20\n",
      "epoch: 10  batch: 33 / 122  loss: 0.10911429148506034  hr: 1  min: 0  sec: 52\n",
      "epoch: 10  batch: 34 / 122  loss: 0.10595457459224716  hr: 1  min: 1  sec: 2\n",
      "epoch: 10  batch: 35 / 122  loss: 0.11455456897217248  hr: 1  min: 0  sec: 44\n",
      "epoch: 10  batch: 36 / 122  loss: 0.12481018679035413  hr: 1  min: 0  sec: 37\n",
      "epoch: 10  batch: 37 / 122  loss: 0.12764931475819163  hr: 1  min: 1  sec: 19\n",
      "epoch: 10  batch: 38 / 122  loss: 0.12682604187437774  hr: 1  min: 1  sec: 29\n",
      "epoch: 10  batch: 39 / 122  loss: 0.12362803114602008  hr: 1  min: 1  sec: 5\n",
      "epoch: 10  batch: 40 / 122  loss: 0.12100368339451961  hr: 1  min: 0  sec: 54\n",
      "epoch: 10  batch: 41 / 122  loss: 0.11810341864120125  hr: 1  min: 0  sec: 50\n",
      "epoch: 10  batch: 42 / 122  loss: 0.11533603783408623  hr: 1  min: 1  sec: 9\n",
      "epoch: 10  batch: 43 / 122  loss: 0.1128916540020687  hr: 1  min: 0  sec: 53\n",
      "epoch: 10  batch: 44 / 122  loss: 0.11888937387001616  hr: 1  min: 0  sec: 22\n",
      "epoch: 10  batch: 45 / 122  loss: 0.11628650883212685  hr: 1  min: 0  sec: 13\n",
      "epoch: 10  batch: 46 / 122  loss: 0.11379184696377943  hr: 1  min: 0  sec: 30\n",
      "epoch: 10  batch: 47 / 122  loss: 0.11391224610084232  hr: 1  min: 0  sec: 15\n",
      "epoch: 10  batch: 48 / 122  loss: 0.12255887416540645  hr: 1  min: 0  sec: 0\n",
      "epoch: 10  batch: 49 / 122  loss: 0.12749557509752257  hr: 1  min: 0  sec: 15\n",
      "epoch: 10  batch: 50 / 122  loss: 0.1249706552689895  hr: 0  min: 59  sec: 54\n",
      "epoch: 10  batch: 51 / 122  loss: 0.12869088305616935  hr: 0  min: 59  sec: 38\n",
      "epoch: 10  batch: 52 / 122  loss: 0.1262666916814991  hr: 0  min: 59  sec: 35\n",
      "epoch: 10  batch: 53 / 122  loss: 0.12392045772098496  hr: 0  min: 59  sec: 19\n",
      "epoch: 10  batch: 54 / 122  loss: 0.12484004172815562  hr: 0  min: 59  sec: 11\n",
      "epoch: 10  batch: 55 / 122  loss: 0.12950108610305258  hr: 0  min: 58  sec: 43\n",
      "epoch: 10  batch: 56 / 122  loss: 0.1272433765677436  hr: 0  min: 58  sec: 25\n",
      "epoch: 10  batch: 57 / 122  loss: 0.12503047554402433  hr: 0  min: 58  sec: 18\n",
      "epoch: 10  batch: 58 / 122  loss: 0.12291057782191463  hr: 0  min: 57  sec: 59\n",
      "epoch: 10  batch: 59 / 122  loss: 0.12085002583009585  hr: 0  min: 57  sec: 39\n",
      "epoch: 10  batch: 60 / 122  loss: 0.12155925406065458  hr: 0  min: 58  sec: 10\n",
      "epoch: 10  batch: 61 / 122  loss: 0.11966732914223656  hr: 0  min: 58  sec: 41\n",
      "epoch: 10  batch: 62 / 122  loss: 0.11776022838744064  hr: 0  min: 58  sec: 29\n",
      "epoch: 10  batch: 63 / 122  loss: 0.11604155378697055  hr: 0  min: 58  sec: 19\n",
      "epoch: 10  batch: 64 / 122  loss: 0.11425495569892519  hr: 0  min: 58  sec: 29\n",
      "epoch: 10  batch: 65 / 122  loss: 0.11380419000589218  hr: 0  min: 58  sec: 24\n",
      "epoch: 10  batch: 66 / 122  loss: 0.11209705989511515  hr: 0  min: 58  sec: 9\n",
      "epoch: 10  batch: 67 / 122  loss: 0.1105713700674085  hr: 0  min: 58  sec: 34\n",
      "epoch: 10  batch: 68 / 122  loss: 0.10895857360789224  hr: 0  min: 58  sec: 31\n",
      "epoch: 10  batch: 69 / 122  loss: 0.11031812184449771  hr: 0  min: 58  sec: 16\n",
      "epoch: 10  batch: 70 / 122  loss: 0.10876081814390741  hr: 0  min: 58  sec: 10\n",
      "epoch: 10  batch: 71 / 122  loss: 0.10958235589852951  hr: 0  min: 58  sec: 2\n",
      "epoch: 10  batch: 72 / 122  loss: 0.11057962802846709  hr: 0  min: 58  sec: 3\n",
      "epoch: 10  batch: 73 / 122  loss: 0.1091191230424718  hr: 0  min: 57  sec: 45\n",
      "epoch: 10  batch: 74 / 122  loss: 0.1076748046136738  hr: 0  min: 57  sec: 32\n",
      "epoch: 10  batch: 75 / 122  loss: 0.10642010649976631  hr: 0  min: 57  sec: 21\n",
      "epoch: 10  batch: 76 / 122  loss: 0.10881510691557962  hr: 0  min: 57  sec: 15\n",
      "epoch: 10  batch: 77 / 122  loss: 0.10743759234145574  hr: 0  min: 57  sec: 4\n",
      "epoch: 10  batch: 78 / 122  loss: 0.10617314015503208  hr: 0  min: 56  sec: 55\n",
      "epoch: 10  batch: 79 / 122  loss: 0.10491906941420387  hr: 0  min: 56  sec: 48\n",
      "epoch: 10  batch: 80 / 122  loss: 0.10401902539015281  hr: 0  min: 56  sec: 41\n",
      "epoch: 10  batch: 81 / 122  loss: 0.10274778046633726  hr: 0  min: 57  sec: 0\n",
      "epoch: 10  batch: 82 / 122  loss: 0.10151171058745737  hr: 0  min: 56  sec: 53\n",
      "epoch: 10  batch: 83 / 122  loss: 0.10044164418422404  hr: 0  min: 56  sec: 53\n",
      "epoch: 10  batch: 84 / 122  loss: 0.10055970304390593  hr: 0  min: 56  sec: 40\n",
      "epoch: 10  batch: 85 / 122  loss: 0.09972790066864999  hr: 0  min: 56  sec: 25\n",
      "epoch: 10  batch: 86 / 122  loss: 0.09859397443455406  hr: 0  min: 56  sec: 11\n",
      "epoch: 10  batch: 87 / 122  loss: 0.09747798393357374  hr: 0  min: 56  sec: 6\n",
      "epoch: 10  batch: 88 / 122  loss: 0.09638663312018086  hr: 0  min: 56  sec: 3\n",
      "epoch: 10  batch: 89 / 122  loss: 0.09941892341051377  hr: 0  min: 55  sec: 50\n",
      "epoch: 10  batch: 90 / 122  loss: 0.09832474459286054  hr: 0  min: 55  sec: 37\n",
      "epoch: 10  batch: 91 / 122  loss: 0.09737885428482544  hr: 0  min: 55  sec: 27\n",
      "epoch: 10  batch: 92 / 122  loss: 0.09636967754530538  hr: 0  min: 55  sec: 12\n",
      "epoch: 10  batch: 93 / 122  loss: 0.09594116564051458  hr: 0  min: 54  sec: 54\n",
      "epoch: 10  batch: 94 / 122  loss: 0.09495763689034341  hr: 0  min: 54  sec: 54\n",
      "epoch: 10  batch: 95 / 122  loss: 0.09450570362877395  hr: 0  min: 54  sec: 47\n",
      "epoch: 10  batch: 96 / 122  loss: 0.09368294402095974  hr: 0  min: 54  sec: 44\n",
      "epoch: 10  batch: 97 / 122  loss: 0.09316712547124834  hr: 0  min: 54  sec: 33\n",
      "epoch: 10  batch: 98 / 122  loss: 0.0922367360534346  hr: 0  min: 54  sec: 26\n",
      "epoch: 10  batch: 99 / 122  loss: 0.09502132529112971  hr: 0  min: 54  sec: 41\n",
      "epoch: 10  batch: 100 / 122  loss: 0.09682167506369296  hr: 0  min: 54  sec: 28\n",
      "Validation Loss after 100 batches: 1.3168353646993638\n",
      "epoch: 10  batch: 101 / 122  loss: 0.09587902512048639  hr: 0  min: 54  sec: 22\n",
      "epoch: 10  batch: 102 / 122  loss: 0.09559739318016607  hr: 0  min: 54  sec: 11\n",
      "epoch: 10  batch: 103 / 122  loss: 0.09468551406702388  hr: 0  min: 53  sec: 58\n",
      "epoch: 10  batch: 104 / 122  loss: 0.09378149824176664  hr: 0  min: 53  sec: 57\n",
      "epoch: 10  batch: 105 / 122  loss: 0.09291105780284852  hr: 0  min: 53  sec: 46\n",
      "epoch: 10  batch: 106 / 122  loss: 0.0920423549085961  hr: 0  min: 53  sec: 33\n",
      "epoch: 10  batch: 107 / 122  loss: 0.09118879432724701  hr: 0  min: 53  sec: 28\n",
      "epoch: 10  batch: 108 / 122  loss: 0.09235345440619211  hr: 0  min: 53  sec: 20\n",
      "epoch: 10  batch: 109 / 122  loss: 0.09195361108147462  hr: 0  min: 53  sec: 9\n",
      "epoch: 10  batch: 110 / 122  loss: 0.09112315977373245  hr: 0  min: 52  sec: 59\n",
      "epoch: 10  batch: 111 / 122  loss: 0.09054785243839629  hr: 0  min: 52  sec: 48\n",
      "epoch: 10  batch: 112 / 122  loss: 0.08976227136528385  hr: 0  min: 52  sec: 49\n",
      "epoch: 10  batch: 113 / 122  loss: 0.09336425863470124  hr: 0  min: 52  sec: 46\n",
      "epoch: 10  batch: 114 / 122  loss: 0.09255614863982294  hr: 0  min: 52  sec: 34\n",
      "epoch: 10  batch: 115 / 122  loss: 0.09176157710000711  hr: 0  min: 52  sec: 23\n",
      "epoch: 10  batch: 116 / 122  loss: 0.09098118000186113  hr: 0  min: 52  sec: 13\n",
      "epoch: 10  batch: 117 / 122  loss: 0.09113936841937625  hr: 0  min: 52  sec: 0\n",
      "epoch: 10  batch: 118 / 122  loss: 0.0903751171145675  hr: 0  min: 51  sec: 53\n",
      "epoch: 10  batch: 119 / 122  loss: 0.09039126033845804  hr: 0  min: 51  sec: 42\n",
      "epoch: 10  batch: 120 / 122  loss: 0.09096379613183672  hr: 0  min: 51  sec: 40\n",
      "epoch: 10  batch: 121 / 122  loss: 0.09022102412269335  hr: 0  min: 51  sec: 43\n",
      "epoch: 10  batch: 122 / 122  loss: 0.08949298130541078  hr: 0  min: 51  sec: 36\n",
      "Learning rate: 5.925925925925926e-06\n",
      "epoch: 11  batch: 1 / 122  loss: 0.000802059075795114  hr: 0  min: 45  sec: 18\n",
      "epoch: 11  batch: 2 / 122  loss: 0.011734235275071114  hr: 0  min: 44  sec: 38\n",
      "epoch: 11  batch: 3 / 122  loss: 0.009706019850758215  hr: 0  min: 44  sec: 2\n",
      "epoch: 11  batch: 4 / 122  loss: 0.007601394871016964  hr: 0  min: 45  sec: 34\n",
      "epoch: 11  batch: 5 / 122  loss: 0.018645828659646212  hr: 0  min: 49  sec: 53\n",
      "epoch: 11  batch: 6 / 122  loss: 0.01570233702659607  hr: 0  min: 48  sec: 23\n",
      "epoch: 11  batch: 7 / 122  loss: 0.013622837507032923  hr: 0  min: 48  sec: 4\n",
      "epoch: 11  batch: 8 / 122  loss: 0.0174307833367493  hr: 0  min: 47  sec: 9\n",
      "epoch: 11  batch: 9 / 122  loss: 0.030978927259436913  hr: 0  min: 47  sec: 22\n",
      "epoch: 11  batch: 10 / 122  loss: 0.028112446214072405  hr: 0  min: 50  sec: 28\n",
      "epoch: 11  batch: 11 / 122  loss: 0.02589470495215871  hr: 0  min: 49  sec: 23\n",
      "epoch: 11  batch: 12 / 122  loss: 0.023938418036171544  hr: 0  min: 49  sec: 1\n",
      "epoch: 11  batch: 13 / 122  loss: 0.027884340612217784  hr: 0  min: 50  sec: 16\n",
      "epoch: 11  batch: 14 / 122  loss: 0.025983604170115932  hr: 0  min: 50  sec: 13\n",
      "epoch: 11  batch: 15 / 122  loss: 0.02431758972816169  hr: 0  min: 50  sec: 0\n",
      "epoch: 11  batch: 16 / 122  loss: 0.02285786735956208  hr: 0  min: 50  sec: 9\n",
      "epoch: 11  batch: 17 / 122  loss: 0.021987624798545286  hr: 0  min: 50  sec: 10\n",
      "epoch: 11  batch: 18 / 122  loss: 0.03516135189177779  hr: 0  min: 50  sec: 2\n",
      "epoch: 11  batch: 19 / 122  loss: 0.036380101488535536  hr: 0  min: 49  sec: 52\n",
      "epoch: 11  batch: 20 / 122  loss: 0.04545276863791514  hr: 0  min: 51  sec: 22\n",
      "epoch: 11  batch: 21 / 122  loss: 0.043364004916622345  hr: 0  min: 50  sec: 56\n",
      "epoch: 11  batch: 22 / 122  loss: 0.04143411637315611  hr: 0  min: 50  sec: 14\n",
      "epoch: 11  batch: 23 / 122  loss: 0.04616963382273832  hr: 0  min: 49  sec: 51\n",
      "epoch: 11  batch: 24 / 122  loss: 0.048800342451916855  hr: 0  min: 50  sec: 50\n",
      "epoch: 11  batch: 25 / 122  loss: 0.046882295303512365  hr: 0  min: 50  sec: 6\n",
      "epoch: 11  batch: 26 / 122  loss: 0.04513209912469252  hr: 0  min: 49  sec: 51\n",
      "epoch: 11  batch: 27 / 122  loss: 0.05050207423779217  hr: 0  min: 49  sec: 46\n",
      "epoch: 11  batch: 28 / 122  loss: 0.048733430426052236  hr: 0  min: 49  sec: 38\n",
      "epoch: 11  batch: 29 / 122  loss: 0.04711384570491019  hr: 0  min: 50  sec: 15\n",
      "epoch: 11  batch: 30 / 122  loss: 0.04586643188764962  hr: 0  min: 49  sec: 50\n",
      "epoch: 11  batch: 31 / 122  loss: 0.045716515684034675  hr: 0  min: 50  sec: 43\n",
      "epoch: 11  batch: 32 / 122  loss: 0.04431764952096273  hr: 0  min: 51  sec: 2\n",
      "epoch: 11  batch: 33 / 122  loss: 0.052860739404533175  hr: 0  min: 51  sec: 11\n",
      "epoch: 11  batch: 34 / 122  loss: 0.05134172714657753  hr: 0  min: 51  sec: 28\n",
      "epoch: 11  batch: 35 / 122  loss: 0.05723693178234888  hr: 0  min: 51  sec: 10\n",
      "epoch: 11  batch: 36 / 122  loss: 0.0558880195442018  hr: 0  min: 50  sec: 54\n",
      "epoch: 11  batch: 37 / 122  loss: 0.05464814607418973  hr: 0  min: 50  sec: 25\n",
      "epoch: 11  batch: 38 / 122  loss: 0.05323284313137839  hr: 0  min: 50  sec: 48\n",
      "epoch: 11  batch: 39 / 122  loss: 0.0519052778940815  hr: 0  min: 50  sec: 50\n",
      "epoch: 11  batch: 40 / 122  loss: 0.05065392033866374  hr: 0  min: 50  sec: 33\n",
      "epoch: 11  batch: 41 / 122  loss: 0.04948848492619241  hr: 0  min: 50  sec: 10\n",
      "epoch: 11  batch: 42 / 122  loss: 0.0484328482596625  hr: 0  min: 49  sec: 41\n",
      "epoch: 11  batch: 43 / 122  loss: 0.047347729547804786  hr: 0  min: 49  sec: 34\n",
      "epoch: 11  batch: 44 / 122  loss: 0.04629613030093341  hr: 0  min: 49  sec: 24\n",
      "epoch: 11  batch: 45 / 122  loss: 0.045535460679740125  hr: 0  min: 49  sec: 27\n",
      "epoch: 11  batch: 46 / 122  loss: 0.04536755729856415  hr: 0  min: 49  sec: 38\n",
      "epoch: 11  batch: 47 / 122  loss: 0.04441999868945556  hr: 0  min: 49  sec: 32\n",
      "epoch: 11  batch: 48 / 122  loss: 0.04351296921352817  hr: 0  min: 49  sec: 9\n",
      "epoch: 11  batch: 49 / 122  loss: 0.04264911336287362  hr: 0  min: 48  sec: 55\n",
      "epoch: 11  batch: 50 / 122  loss: 0.041824449148261916  hr: 0  min: 48  sec: 37\n",
      "epoch: 11  batch: 51 / 122  loss: 0.04118460566193486  hr: 0  min: 48  sec: 17\n",
      "epoch: 11  batch: 52 / 122  loss: 0.040441006118691385  hr: 0  min: 48  sec: 22\n",
      "epoch: 11  batch: 53 / 122  loss: 0.03969105794687562  hr: 0  min: 48  sec: 16\n",
      "epoch: 11  batch: 54 / 122  loss: 0.039283134813929255  hr: 0  min: 47  sec: 59\n",
      "epoch: 11  batch: 55 / 122  loss: 0.03859070618954402  hr: 0  min: 47  sec: 54\n",
      "epoch: 11  batch: 56 / 122  loss: 0.03792987302482028  hr: 0  min: 47  sec: 42\n",
      "epoch: 11  batch: 57 / 122  loss: 0.037302889580340046  hr: 0  min: 47  sec: 37\n",
      "epoch: 11  batch: 58 / 122  loss: 0.042220485875391046  hr: 0  min: 47  sec: 34\n",
      "epoch: 11  batch: 59 / 122  loss: 0.041518531035300406  hr: 0  min: 47  sec: 14\n",
      "epoch: 11  batch: 60 / 122  loss: 0.04084109890876183  hr: 0  min: 46  sec: 55\n",
      "epoch: 11  batch: 61 / 122  loss: 0.048167690179562656  hr: 0  min: 46  sec: 36\n",
      "epoch: 11  batch: 62 / 122  loss: 0.04747454545201523  hr: 0  min: 46  sec: 22\n",
      "epoch: 11  batch: 63 / 122  loss: 0.046739723460401394  hr: 0  min: 46  sec: 11\n",
      "epoch: 11  batch: 64 / 122  loss: 0.049042700310565124  hr: 0  min: 46  sec: 1\n",
      "epoch: 11  batch: 65 / 122  loss: 0.04831529961128791  hr: 0  min: 45  sec: 56\n",
      "epoch: 11  batch: 66 / 122  loss: 0.04759398124455898  hr: 0  min: 45  sec: 48\n",
      "epoch: 11  batch: 67 / 122  loss: 0.04689453333206197  hr: 0  min: 45  sec: 41\n",
      "epoch: 11  batch: 68 / 122  loss: 0.046287761078394184  hr: 0  min: 45  sec: 31\n",
      "epoch: 11  batch: 69 / 122  loss: 0.04562794069837158  hr: 0  min: 45  sec: 26\n",
      "epoch: 11  batch: 70 / 122  loss: 0.04503361189189101  hr: 0  min: 45  sec: 18\n",
      "epoch: 11  batch: 71 / 122  loss: 0.04555822101103562  hr: 0  min: 45  sec: 11\n",
      "epoch: 11  batch: 72 / 122  loss: 0.04493264912323664  hr: 0  min: 45  sec: 1\n",
      "epoch: 11  batch: 73 / 122  loss: 0.047740895417518914  hr: 0  min: 44  sec: 52\n",
      "epoch: 11  batch: 74 / 122  loss: 0.05124276752011045  hr: 0  min: 45  sec: 9\n",
      "epoch: 11  batch: 75 / 122  loss: 0.05057132766737292  hr: 0  min: 44  sec: 57\n",
      "epoch: 11  batch: 76 / 122  loss: 0.05092180261578362  hr: 0  min: 44  sec: 50\n",
      "epoch: 11  batch: 77 / 122  loss: 0.05032889734100938  hr: 0  min: 44  sec: 38\n",
      "epoch: 11  batch: 78 / 122  loss: 0.04970132381332895  hr: 0  min: 44  sec: 34\n",
      "epoch: 11  batch: 79 / 122  loss: 0.04907962512681732  hr: 0  min: 44  sec: 27\n",
      "epoch: 11  batch: 80 / 122  loss: 0.04847861808739253  hr: 0  min: 44  sec: 18\n",
      "epoch: 11  batch: 81 / 122  loss: 0.05062025179296019  hr: 0  min: 44  sec: 11\n",
      "epoch: 11  batch: 82 / 122  loss: 0.050012042752336484  hr: 0  min: 44  sec: 8\n",
      "epoch: 11  batch: 83 / 122  loss: 0.049510768834215374  hr: 0  min: 44  sec: 22\n",
      "epoch: 11  batch: 84 / 122  loss: 0.05097725571180317  hr: 0  min: 44  sec: 18\n",
      "epoch: 11  batch: 85 / 122  loss: 0.05038463236243628  hr: 0  min: 44  sec: 16\n",
      "epoch: 11  batch: 86 / 122  loss: 0.05129662268323997  hr: 0  min: 44  sec: 9\n",
      "epoch: 11  batch: 87 / 122  loss: 0.05071819929510419  hr: 0  min: 44  sec: 4\n",
      "epoch: 11  batch: 88 / 122  loss: 0.0502867145319628  hr: 0  min: 43  sec: 56\n",
      "epoch: 11  batch: 89 / 122  loss: 0.049729955858770714  hr: 0  min: 43  sec: 45\n",
      "epoch: 11  batch: 90 / 122  loss: 0.049196483676011364  hr: 0  min: 43  sec: 34\n",
      "epoch: 11  batch: 91 / 122  loss: 0.04866363910400401  hr: 0  min: 43  sec: 23\n",
      "epoch: 11  batch: 92 / 122  loss: 0.048144568787234755  hr: 0  min: 43  sec: 15\n",
      "epoch: 11  batch: 93 / 122  loss: 0.04763443835119727  hr: 0  min: 43  sec: 7\n",
      "epoch: 11  batch: 94 / 122  loss: 0.04713446759876418  hr: 0  min: 42  sec: 51\n",
      "epoch: 11  batch: 95 / 122  loss: 0.04665765950431753  hr: 0  min: 42  sec: 35\n",
      "epoch: 11  batch: 96 / 122  loss: 0.046806648760442236  hr: 0  min: 42  sec: 27\n",
      "epoch: 11  batch: 97 / 122  loss: 0.04632988875400582  hr: 0  min: 42  sec: 16\n",
      "epoch: 11  batch: 98 / 122  loss: 0.04586888162647279  hr: 0  min: 42  sec: 11\n",
      "epoch: 11  batch: 99 / 122  loss: 0.045412941571828354  hr: 0  min: 42  sec: 7\n",
      "epoch: 11  batch: 100 / 122  loss: 0.044969284728285853  hr: 0  min: 41  sec: 55\n",
      "Validation Loss after 100 batches: 1.377030186355114\n",
      "epoch: 11  batch: 101 / 122  loss: 0.04452801464928895  hr: 0  min: 41  sec: 45\n",
      "epoch: 11  batch: 102 / 122  loss: 0.04409590325981388  hr: 0  min: 41  sec: 44\n",
      "epoch: 11  batch: 103 / 122  loss: 0.04367105377350879  hr: 0  min: 41  sec: 32\n",
      "epoch: 11  batch: 104 / 122  loss: 0.043254362048453635  hr: 0  min: 41  sec: 21\n",
      "epoch: 11  batch: 105 / 122  loss: 0.04284592068815116  hr: 0  min: 41  sec: 13\n",
      "epoch: 11  batch: 106 / 122  loss: 0.04249028025721068  hr: 0  min: 41  sec: 1\n",
      "epoch: 11  batch: 107 / 122  loss: 0.04209632317102558  hr: 0  min: 40  sec: 50\n",
      "epoch: 11  batch: 108 / 122  loss: 0.0417097291040894  hr: 0  min: 40  sec: 54\n",
      "epoch: 11  batch: 109 / 122  loss: 0.04133033020146311  hr: 0  min: 40  sec: 45\n",
      "epoch: 11  batch: 110 / 122  loss: 0.04218473033926619  hr: 0  min: 40  sec: 34\n",
      "epoch: 11  batch: 111 / 122  loss: 0.0418077179737838  hr: 0  min: 40  sec: 23\n",
      "epoch: 11  batch: 112 / 122  loss: 0.04143716476885727  hr: 0  min: 40  sec: 17\n",
      "epoch: 11  batch: 113 / 122  loss: 0.04109997960478191  hr: 0  min: 40  sec: 8\n",
      "epoch: 11  batch: 114 / 122  loss: 0.04732028047402038  hr: 0  min: 40  sec: 13\n",
      "epoch: 11  batch: 115 / 122  loss: 0.046912000033467925  hr: 0  min: 40  sec: 2\n",
      "epoch: 11  batch: 116 / 122  loss: 0.04651050190471418  hr: 0  min: 39  sec: 55\n",
      "epoch: 11  batch: 117 / 122  loss: 0.04677865193693095  hr: 0  min: 39  sec: 47\n",
      "epoch: 11  batch: 118 / 122  loss: 0.04638569151205248  hr: 0  min: 39  sec: 35\n",
      "epoch: 11  batch: 119 / 122  loss: 0.04850844944486817  hr: 0  min: 39  sec: 25\n",
      "epoch: 11  batch: 120 / 122  loss: 0.04810972957542011  hr: 0  min: 39  sec: 16\n",
      "epoch: 11  batch: 121 / 122  loss: 0.048976274425633376  hr: 0  min: 39  sec: 10\n",
      "epoch: 11  batch: 122 / 122  loss: 0.04858007643574116  hr: 0  min: 39  sec: 1\n",
      "Learning rate: 4.444444444444444e-06\n",
      "epoch: 12  batch: 1 / 122  loss: 0.0006239862414076924  hr: 0  min: 37  sec: 32\n",
      "epoch: 12  batch: 2 / 122  loss: 0.0006317364168353379  hr: 0  min: 36  sec: 51\n",
      "epoch: 12  batch: 3 / 122  loss: 0.0005984245411430796  hr: 0  min: 33  sec: 45\n",
      "epoch: 12  batch: 4 / 122  loss: 0.001591637235833332  hr: 0  min: 32  sec: 53\n",
      "epoch: 12  batch: 5 / 122  loss: 0.001403536123689264  hr: 0  min: 32  sec: 55\n",
      "epoch: 12  batch: 6 / 122  loss: 0.0012564247202438612  hr: 0  min: 33  sec: 11\n",
      "epoch: 12  batch: 7 / 122  loss: 0.0024065134015732576  hr: 0  min: 32  sec: 55\n",
      "epoch: 12  batch: 8 / 122  loss: 0.0021800665999762714  hr: 0  min: 33  sec: 22\n",
      "epoch: 12  batch: 9 / 122  loss: 0.0023300234590553576  hr: 0  min: 33  sec: 1\n",
      "epoch: 12  batch: 10 / 122  loss: 0.0021644697058945893  hr: 0  min: 32  sec: 30\n",
      "epoch: 12  batch: 11 / 122  loss: 0.0020271631656214595  hr: 0  min: 33  sec: 2\n",
      "epoch: 12  batch: 12 / 122  loss: 0.03516649304462286  hr: 0  min: 32  sec: 47\n",
      "epoch: 12  batch: 13 / 122  loss: 0.03249893861357123  hr: 0  min: 32  sec: 22\n",
      "epoch: 12  batch: 14 / 122  loss: 0.030214791040634736  hr: 0  min: 32  sec: 10\n",
      "epoch: 12  batch: 15 / 122  loss: 0.028254151433551065  hr: 0  min: 32  sec: 24\n",
      "epoch: 12  batch: 16 / 122  loss: 0.026575921441690298  hr: 0  min: 32  sec: 25\n",
      "epoch: 12  batch: 17 / 122  loss: 0.03601474390598014  hr: 0  min: 32  sec: 28\n",
      "epoch: 12  batch: 18 / 122  loss: 0.03448297341108426  hr: 0  min: 32  sec: 58\n",
      "epoch: 12  batch: 19 / 122  loss: 0.03269629916911455  hr: 0  min: 32  sec: 51\n",
      "epoch: 12  batch: 20 / 122  loss: 0.031097268234589137  hr: 0  min: 32  sec: 59\n",
      "epoch: 12  batch: 21 / 122  loss: 0.029850270457765355  hr: 0  min: 33  sec: 12\n",
      "epoch: 12  batch: 22 / 122  loss: 0.029420232604024932  hr: 0  min: 34  sec: 15\n",
      "epoch: 12  batch: 23 / 122  loss: 0.0282657408666716  hr: 0  min: 34  sec: 15\n",
      "epoch: 12  batch: 24 / 122  loss: 0.02717286932602292  hr: 0  min: 34  sec: 5\n",
      "epoch: 12  batch: 25 / 122  loss: 0.033093958145473154  hr: 0  min: 34  sec: 18\n",
      "epoch: 12  batch: 26 / 122  loss: 0.03184697124435423  hr: 0  min: 34  sec: 7\n",
      "epoch: 12  batch: 27 / 122  loss: 0.030687626315436017  hr: 0  min: 33  sec: 46\n",
      "epoch: 12  batch: 28 / 122  loss: 0.02961284730034614  hr: 0  min: 34  sec: 27\n",
      "epoch: 12  batch: 29 / 122  loss: 0.02861965094203258  hr: 0  min: 34  sec: 29\n",
      "epoch: 12  batch: 30 / 122  loss: 0.02772961413526597  hr: 0  min: 34  sec: 39\n",
      "epoch: 12  batch: 31 / 122  loss: 0.026893286824962424  hr: 0  min: 34  sec: 56\n",
      "epoch: 12  batch: 32 / 122  loss: 0.026077891070599435  hr: 0  min: 34  sec: 42\n",
      "epoch: 12  batch: 33 / 122  loss: 0.02530579036101699  hr: 0  min: 34  sec: 28\n",
      "epoch: 12  batch: 34 / 122  loss: 0.024584559653543264  hr: 0  min: 34  sec: 47\n",
      "epoch: 12  batch: 35 / 122  loss: 0.023970910386248892  hr: 0  min: 34  sec: 37\n",
      "epoch: 12  batch: 36 / 122  loss: 0.023330571909254003  hr: 0  min: 34  sec: 17\n",
      "epoch: 12  batch: 37 / 122  loss: 0.023858494606699695  hr: 0  min: 34  sec: 3\n",
      "epoch: 12  batch: 38 / 122  loss: 0.023527818195840444  hr: 0  min: 33  sec: 59\n",
      "epoch: 12  batch: 39 / 122  loss: 0.022938113331269376  hr: 0  min: 34  sec: 11\n",
      "epoch: 12  batch: 40 / 122  loss: 0.028990727063501254  hr: 0  min: 34  sec: 11\n",
      "epoch: 12  batch: 41 / 122  loss: 0.039257267041404434  hr: 0  min: 34  sec: 20\n",
      "epoch: 12  batch: 42 / 122  loss: 0.03833499985713778  hr: 0  min: 34  sec: 5\n",
      "epoch: 12  batch: 43 / 122  loss: 0.037456440159964355  hr: 0  min: 33  sec: 50\n",
      "epoch: 12  batch: 44 / 122  loss: 0.036615335002187006  hr: 0  min: 33  sec: 36\n",
      "epoch: 12  batch: 45 / 122  loss: 0.03582265066021743  hr: 0  min: 33  sec: 35\n",
      "epoch: 12  batch: 46 / 122  loss: 0.03674710934169327  hr: 0  min: 33  sec: 36\n",
      "epoch: 12  batch: 47 / 122  loss: 0.03600731079820841  hr: 0  min: 33  sec: 27\n",
      "epoch: 12  batch: 48 / 122  loss: 0.035267792309241486  hr: 0  min: 33  sec: 25\n",
      "epoch: 12  batch: 49 / 122  loss: 0.03456015302977829  hr: 0  min: 33  sec: 14\n",
      "epoch: 12  batch: 50 / 122  loss: 0.03403524255088996  hr: 0  min: 33  sec: 2\n",
      "epoch: 12  batch: 51 / 122  loss: 0.033379837630348574  hr: 0  min: 32  sec: 53\n",
      "epoch: 12  batch: 52 / 122  loss: 0.03274846267315577  hr: 0  min: 32  sec: 50\n",
      "epoch: 12  batch: 53 / 122  loss: 0.032137289417595694  hr: 0  min: 32  sec: 37\n",
      "epoch: 12  batch: 54 / 122  loss: 0.031553085915489915  hr: 0  min: 32  sec: 23\n",
      "epoch: 12  batch: 55 / 122  loss: 0.03098939741612412  hr: 0  min: 32  sec: 16\n",
      "epoch: 12  batch: 56 / 122  loss: 0.03120867505276692  hr: 0  min: 32  sec: 7\n",
      "epoch: 12  batch: 57 / 122  loss: 0.030682171439127017  hr: 0  min: 32  sec: 11\n",
      "epoch: 12  batch: 58 / 122  loss: 0.030181398889720278  hr: 0  min: 32  sec: 17\n",
      "epoch: 12  batch: 59 / 122  loss: 0.029688872471432027  hr: 0  min: 32  sec: 8\n",
      "epoch: 12  batch: 60 / 122  loss: 0.02920500394781508  hr: 0  min: 31  sec: 59\n",
      "epoch: 12  batch: 61 / 122  loss: 0.028961313301105754  hr: 0  min: 32  sec: 12\n",
      "epoch: 12  batch: 62 / 122  loss: 0.028507123548713993  hr: 0  min: 32  sec: 6\n",
      "epoch: 12  batch: 63 / 122  loss: 0.030835664459219616  hr: 0  min: 31  sec: 59\n",
      "epoch: 12  batch: 64 / 122  loss: 0.03105078608268741  hr: 0  min: 31  sec: 47\n",
      "epoch: 12  batch: 65 / 122  loss: 0.03058430850192403  hr: 0  min: 31  sec: 41\n",
      "epoch: 12  batch: 66 / 122  loss: 0.03013123079180139  hr: 0  min: 31  sec: 53\n",
      "epoch: 12  batch: 67 / 122  loss: 0.030582895124967056  hr: 0  min: 31  sec: 46\n",
      "epoch: 12  batch: 68 / 122  loss: 0.030140925649474785  hr: 0  min: 31  sec: 37\n",
      "epoch: 12  batch: 69 / 122  loss: 0.03316897565399404  hr: 0  min: 31  sec: 29\n",
      "epoch: 12  batch: 70 / 122  loss: 0.032736328921497  hr: 0  min: 31  sec: 23\n",
      "epoch: 12  batch: 71 / 122  loss: 0.03242726288088204  hr: 0  min: 31  sec: 17\n",
      "epoch: 12  batch: 72 / 122  loss: 0.03198413842740896  hr: 0  min: 31  sec: 29\n",
      "epoch: 12  batch: 73 / 122  loss: 0.031551726840991424  hr: 0  min: 31  sec: 19\n",
      "epoch: 12  batch: 74 / 122  loss: 0.031131431869800656  hr: 0  min: 31  sec: 7\n",
      "epoch: 12  batch: 75 / 122  loss: 0.030721634960888575  hr: 0  min: 31  sec: 16\n",
      "epoch: 12  batch: 76 / 122  loss: 0.030323315545071016  hr: 0  min: 31  sec: 5\n",
      "epoch: 12  batch: 77 / 122  loss: 0.034382863416239716  hr: 0  min: 30  sec: 51\n",
      "epoch: 12  batch: 78 / 122  loss: 0.03397405622915054  hr: 0  min: 30  sec: 41\n",
      "epoch: 12  batch: 79 / 122  loss: 0.033550911916779426  hr: 0  min: 30  sec: 36\n",
      "epoch: 12  batch: 80 / 122  loss: 0.03321165453889989  hr: 0  min: 30  sec: 30\n",
      "epoch: 12  batch: 81 / 122  loss: 0.03560762229033482  hr: 0  min: 30  sec: 23\n",
      "epoch: 12  batch: 82 / 122  loss: 0.035188998418672734  hr: 0  min: 30  sec: 16\n",
      "epoch: 12  batch: 83 / 122  loss: 0.03477004566685723  hr: 0  min: 30  sec: 3\n",
      "epoch: 12  batch: 84 / 122  loss: 0.03436138570430644  hr: 0  min: 29  sec: 51\n",
      "epoch: 12  batch: 85 / 122  loss: 0.03434182445737807  hr: 0  min: 29  sec: 49\n",
      "epoch: 12  batch: 86 / 122  loss: 0.03407151932925592  hr: 0  min: 29  sec: 41\n",
      "epoch: 12  batch: 87 / 122  loss: 0.03368668117822715  hr: 0  min: 29  sec: 30\n",
      "epoch: 12  batch: 88 / 122  loss: 0.03333064059816851  hr: 0  min: 29  sec: 37\n",
      "epoch: 12  batch: 89 / 122  loss: 0.03296914157912847  hr: 0  min: 29  sec: 32\n",
      "epoch: 12  batch: 90 / 122  loss: 0.03260930928388714  hr: 0  min: 29  sec: 25\n",
      "epoch: 12  batch: 91 / 122  loss: 0.032293422978530016  hr: 0  min: 29  sec: 17\n",
      "epoch: 12  batch: 92 / 122  loss: 0.031948914922237316  hr: 0  min: 29  sec: 11\n",
      "epoch: 12  batch: 93 / 122  loss: 0.03161229597534784  hr: 0  min: 29  sec: 1\n",
      "epoch: 12  batch: 94 / 122  loss: 0.031282231655650514  hr: 0  min: 28  sec: 54\n",
      "epoch: 12  batch: 95 / 122  loss: 0.031910481076614046  hr: 0  min: 28  sec: 53\n",
      "epoch: 12  batch: 96 / 122  loss: 0.031583105762971776  hr: 0  min: 28  sec: 45\n",
      "epoch: 12  batch: 97 / 122  loss: 0.03126182806583304  hr: 0  min: 28  sec: 34\n",
      "epoch: 12  batch: 98 / 122  loss: 0.030947695664731236  hr: 0  min: 28  sec: 28\n",
      "epoch: 12  batch: 99 / 122  loss: 0.03694954071213924  hr: 0  min: 28  sec: 21\n",
      "epoch: 12  batch: 100 / 122  loss: 0.036584008431818804  hr: 0  min: 28  sec: 12\n",
      "Validation Loss after 100 batches: 1.5449498265981674\n",
      "epoch: 12  batch: 101 / 122  loss: 0.03642261996755773  hr: 0  min: 28  sec: 2\n",
      "epoch: 12  batch: 102 / 122  loss: 0.0360679751325983  hr: 0  min: 27  sec: 52\n",
      "epoch: 12  batch: 103 / 122  loss: 0.03572011925152942  hr: 0  min: 27  sec: 47\n",
      "epoch: 12  batch: 104 / 122  loss: 0.0353793638654539  hr: 0  min: 27  sec: 38\n",
      "epoch: 12  batch: 105 / 122  loss: 0.0353990393703238  hr: 0  min: 27  sec: 30\n",
      "epoch: 12  batch: 106 / 122  loss: 0.0350673966680023  hr: 0  min: 27  sec: 22\n",
      "epoch: 12  batch: 107 / 122  loss: 0.034742910541821416  hr: 0  min: 27  sec: 13\n",
      "epoch: 12  batch: 108 / 122  loss: 0.03442855386391683  hr: 0  min: 27  sec: 4\n",
      "epoch: 12  batch: 109 / 122  loss: 0.03411517632602385  hr: 0  min: 27  sec: 2\n",
      "epoch: 12  batch: 110 / 122  loss: 0.03380728420677108  hr: 0  min: 26  sec: 57\n",
      "epoch: 12  batch: 111 / 122  loss: 0.03350489572223343  hr: 0  min: 26  sec: 52\n",
      "epoch: 12  batch: 112 / 122  loss: 0.0332083432640502  hr: 0  min: 26  sec: 43\n",
      "epoch: 12  batch: 113 / 122  loss: 0.03291646169809691  hr: 0  min: 26  sec: 36\n",
      "epoch: 12  batch: 114 / 122  loss: 0.03263032090928806  hr: 0  min: 26  sec: 37\n",
      "epoch: 12  batch: 115 / 122  loss: 0.03234870327135508  hr: 0  min: 26  sec: 31\n",
      "epoch: 12  batch: 116 / 122  loss: 0.03207204015027322  hr: 0  min: 26  sec: 26\n",
      "epoch: 12  batch: 117 / 122  loss: 0.03543345222043662  hr: 0  min: 26  sec: 20\n",
      "epoch: 12  batch: 118 / 122  loss: 0.03513645959408338  hr: 0  min: 26  sec: 13\n",
      "epoch: 12  batch: 119 / 122  loss: 0.03484348210500272  hr: 0  min: 26  sec: 6\n",
      "epoch: 12  batch: 120 / 122  loss: 0.03455560788352159  hr: 0  min: 26  sec: 4\n",
      "epoch: 12  batch: 121 / 122  loss: 0.036874868749969925  hr: 0  min: 25  sec: 56\n",
      "epoch: 12  batch: 122 / 122  loss: 0.0365747485675307  hr: 0  min: 25  sec: 50\n",
      "Learning rate: 2.962962962962963e-06\n",
      "epoch: 13  batch: 1 / 122  loss: 0.0005056640366092324  hr: 0  min: 21  sec: 15\n",
      "epoch: 13  batch: 2 / 122  loss: 0.0007456011371687055  hr: 0  min: 23  sec: 37\n",
      "epoch: 13  batch: 3 / 122  loss: 0.0006759985699318349  hr: 0  min: 22  sec: 29\n",
      "epoch: 13  batch: 4 / 122  loss: 0.02810118156776298  hr: 0  min: 26  sec: 57\n",
      "epoch: 13  batch: 5 / 122  loss: 0.03035230782115832  hr: 0  min: 27  sec: 24\n",
      "epoch: 13  batch: 6 / 122  loss: 0.025363510687990736  hr: 0  min: 28  sec: 17\n",
      "epoch: 13  batch: 7 / 122  loss: 0.022113786727589155  hr: 0  min: 30  sec: 3\n",
      "epoch: 13  batch: 8 / 122  loss: 0.019826274234219454  hr: 0  min: 28  sec: 37\n",
      "epoch: 13  batch: 9 / 122  loss: 0.0437803118256852  hr: 0  min: 27  sec: 55\n",
      "epoch: 13  batch: 10 / 122  loss: 0.0394447504717391  hr: 0  min: 27  sec: 29\n",
      "epoch: 13  batch: 11 / 122  loss: 0.03590048062985509  hr: 0  min: 27  sec: 50\n",
      "epoch: 13  batch: 12 / 122  loss: 0.03320682942042671  hr: 0  min: 27  sec: 30\n",
      "epoch: 13  batch: 13 / 122  loss: 0.030689474419117548  hr: 0  min: 26  sec: 55\n",
      "epoch: 13  batch: 14 / 122  loss: 0.028821643017831126  hr: 0  min: 26  sec: 25\n",
      "epoch: 13  batch: 15 / 122  loss: 0.026936158549506217  hr: 0  min: 26  sec: 1\n",
      "epoch: 13  batch: 16 / 122  loss: 0.02861136851061019  hr: 0  min: 25  sec: 35\n",
      "epoch: 13  batch: 17 / 122  loss: 0.026953510604524875  hr: 0  min: 25  sec: 22\n",
      "epoch: 13  batch: 18 / 122  loss: 0.030743264586716477  hr: 0  min: 25  sec: 21\n",
      "epoch: 13  batch: 19 / 122  loss: 0.029152712371126797  hr: 0  min: 24  sec: 48\n",
      "epoch: 13  batch: 20 / 122  loss: 0.027720285052782855  hr: 0  min: 25  sec: 22\n",
      "epoch: 13  batch: 21 / 122  loss: 0.026421901291801726  hr: 0  min: 25  sec: 1\n",
      "epoch: 13  batch: 22 / 122  loss: 0.025245128449486485  hr: 0  min: 25  sec: 3\n",
      "epoch: 13  batch: 23 / 122  loss: 0.02416938490806269  hr: 0  min: 24  sec: 57\n",
      "epoch: 13  batch: 24 / 122  loss: 0.02336310789420774  hr: 0  min: 24  sec: 51\n",
      "epoch: 13  batch: 25 / 122  loss: 0.022454628114355727  hr: 0  min: 24  sec: 44\n",
      "epoch: 13  batch: 26 / 122  loss: 0.02160934888972686  hr: 0  min: 24  sec: 26\n",
      "epoch: 13  batch: 27 / 122  loss: 0.02975485901589747  hr: 0  min: 24  sec: 5\n",
      "epoch: 13  batch: 28 / 122  loss: 0.029036272017817413  hr: 0  min: 23  sec: 52\n",
      "epoch: 13  batch: 29 / 122  loss: 0.028274822771420766  hr: 0  min: 23  sec: 37\n",
      "epoch: 13  batch: 30 / 122  loss: 0.027351559576345608  hr: 0  min: 23  sec: 23\n",
      "epoch: 13  batch: 31 / 122  loss: 0.026582595450998916  hr: 0  min: 23  sec: 29\n",
      "epoch: 13  batch: 32 / 122  loss: 0.025784939383811434  hr: 0  min: 23  sec: 17\n",
      "epoch: 13  batch: 33 / 122  loss: 0.02501754151131591  hr: 0  min: 23  sec: 5\n",
      "epoch: 13  batch: 34 / 122  loss: 0.02429560446420082  hr: 0  min: 22  sec: 52\n",
      "epoch: 13  batch: 35 / 122  loss: 0.023616988201891738  hr: 0  min: 22  sec: 39\n",
      "epoch: 13  batch: 36 / 122  loss: 0.02325850770769951  hr: 0  min: 22  sec: 43\n",
      "epoch: 13  batch: 37 / 122  loss: 0.022644820107096755  hr: 0  min: 22  sec: 33\n",
      "epoch: 13  batch: 38 / 122  loss: 0.022063812296102315  hr: 0  min: 22  sec: 36\n",
      "epoch: 13  batch: 39 / 122  loss: 0.02152328991677421  hr: 0  min: 22  sec: 30\n",
      "epoch: 13  batch: 40 / 122  loss: 0.022673550024046564  hr: 0  min: 22  sec: 40\n",
      "epoch: 13  batch: 41 / 122  loss: 0.02213228534603287  hr: 0  min: 22  sec: 26\n",
      "epoch: 13  batch: 42 / 122  loss: 0.021615803141945174  hr: 0  min: 22  sec: 20\n",
      "epoch: 13  batch: 43 / 122  loss: 0.02112130163004622  hr: 0  min: 22  sec: 9\n",
      "epoch: 13  batch: 44 / 122  loss: 0.020656891538899137  hr: 0  min: 21  sec: 52\n",
      "epoch: 13  batch: 45 / 122  loss: 0.020259860971580362  hr: 0  min: 21  sec: 41\n",
      "epoch: 13  batch: 46 / 122  loss: 0.021232654043199982  hr: 0  min: 21  sec: 30\n",
      "epoch: 13  batch: 47 / 122  loss: 0.020795002320850704  hr: 0  min: 21  sec: 22\n",
      "epoch: 13  batch: 48 / 122  loss: 0.020420195228022447  hr: 0  min: 21  sec: 15\n",
      "epoch: 13  batch: 49 / 122  loss: 0.020020126968584195  hr: 0  min: 21  sec: 14\n",
      "epoch: 13  batch: 50 / 122  loss: 0.02149443996604532  hr: 0  min: 21  sec: 12\n",
      "epoch: 13  batch: 51 / 122  loss: 0.02108614996084761  hr: 0  min: 21  sec: 14\n",
      "epoch: 13  batch: 52 / 122  loss: 0.02069170646987354  hr: 0  min: 21  sec: 22\n",
      "epoch: 13  batch: 53 / 122  loss: 0.02086403902031411  hr: 0  min: 21  sec: 17\n",
      "epoch: 13  batch: 54 / 122  loss: 0.02048726081934378  hr: 0  min: 21  sec: 12\n",
      "epoch: 13  batch: 55 / 122  loss: 0.02012321646113626  hr: 0  min: 20  sec: 59\n",
      "epoch: 13  batch: 56 / 122  loss: 0.019771131378677507  hr: 0  min: 20  sec: 53\n",
      "epoch: 13  batch: 57 / 122  loss: 0.019432056452690933  hr: 0  min: 20  sec: 43\n",
      "epoch: 13  batch: 58 / 122  loss: 0.01911049107930639  hr: 0  min: 20  sec: 50\n",
      "epoch: 13  batch: 59 / 122  loss: 0.019391146659657705  hr: 0  min: 20  sec: 42\n",
      "epoch: 13  batch: 60 / 122  loss: 0.019075615026425415  hr: 0  min: 20  sec: 31\n",
      "epoch: 13  batch: 61 / 122  loss: 0.025942987416485385  hr: 0  min: 20  sec: 22\n",
      "epoch: 13  batch: 62 / 122  loss: 0.025535010602681957  hr: 0  min: 20  sec: 14\n",
      "epoch: 13  batch: 63 / 122  loss: 0.025138042240296418  hr: 0  min: 20  sec: 5\n",
      "epoch: 13  batch: 64 / 122  loss: 0.029150622861834563  hr: 0  min: 19  sec: 56\n",
      "epoch: 13  batch: 65 / 122  loss: 0.028707148592310168  hr: 0  min: 19  sec: 44\n",
      "epoch: 13  batch: 66 / 122  loss: 0.028279962924760624  hr: 0  min: 19  sec: 37\n",
      "epoch: 13  batch: 67 / 122  loss: 0.027863421205017686  hr: 0  min: 19  sec: 34\n",
      "epoch: 13  batch: 68 / 122  loss: 0.027459822926389547  hr: 0  min: 19  sec: 24\n",
      "epoch: 13  batch: 69 / 122  loss: 0.02707260212628171  hr: 0  min: 19  sec: 16\n",
      "epoch: 13  batch: 70 / 122  loss: 0.027395549335882865  hr: 0  min: 19  sec: 12\n",
      "epoch: 13  batch: 71 / 122  loss: 0.03153929736015951  hr: 0  min: 19  sec: 2\n",
      "epoch: 13  batch: 72 / 122  loss: 0.031106297918288166  hr: 0  min: 18  sec: 53\n",
      "epoch: 13  batch: 73 / 122  loss: 0.030790591952534495  hr: 0  min: 18  sec: 45\n",
      "epoch: 13  batch: 74 / 122  loss: 0.03037985056643437  hr: 0  min: 18  sec: 35\n",
      "epoch: 13  batch: 75 / 122  loss: 0.029982482204601788  hr: 0  min: 18  sec: 26\n",
      "epoch: 13  batch: 76 / 122  loss: 0.029592729327544618  hr: 0  min: 18  sec: 16\n",
      "epoch: 13  batch: 77 / 122  loss: 0.029215584204429396  hr: 0  min: 18  sec: 7\n",
      "epoch: 13  batch: 78 / 122  loss: 0.028850700609977  hr: 0  min: 18  sec: 0\n",
      "epoch: 13  batch: 79 / 122  loss: 0.028491847599485205  hr: 0  min: 17  sec: 58\n",
      "epoch: 13  batch: 80 / 122  loss: 0.029862951399263694  hr: 0  min: 17  sec: 53\n",
      "epoch: 13  batch: 81 / 122  loss: 0.02950020724250705  hr: 0  min: 17  sec: 48\n",
      "epoch: 13  batch: 82 / 122  loss: 0.03315204946379598  hr: 0  min: 17  sec: 48\n",
      "epoch: 13  batch: 83 / 122  loss: 0.036858322580992975  hr: 0  min: 17  sec: 49\n",
      "epoch: 13  batch: 84 / 122  loss: 0.03642533328786071  hr: 0  min: 17  sec: 43\n",
      "epoch: 13  batch: 85 / 122  loss: 0.03600914504666648  hr: 0  min: 17  sec: 36\n",
      "epoch: 13  batch: 86 / 122  loss: 0.03561388478183924  hr: 0  min: 17  sec: 28\n",
      "epoch: 13  batch: 87 / 122  loss: 0.03521213292989923  hr: 0  min: 17  sec: 19\n",
      "epoch: 13  batch: 88 / 122  loss: 0.034816866209770196  hr: 0  min: 17  sec: 10\n",
      "epoch: 13  batch: 89 / 122  loss: 0.034429344404528044  hr: 0  min: 17  sec: 1\n",
      "epoch: 13  batch: 90 / 122  loss: 0.03430911098031275  hr: 0  min: 16  sec: 52\n",
      "epoch: 13  batch: 91 / 122  loss: 0.03393772694987122  hr: 0  min: 16  sec: 44\n",
      "epoch: 13  batch: 92 / 122  loss: 0.03726743089013642  hr: 0  min: 16  sec: 36\n",
      "epoch: 13  batch: 93 / 122  loss: 0.036872176377425694  hr: 0  min: 16  sec: 27\n",
      "epoch: 13  batch: 94 / 122  loss: 0.0364896637512039  hr: 0  min: 16  sec: 20\n",
      "epoch: 13  batch: 95 / 122  loss: 0.03611063771838273  hr: 0  min: 16  sec: 11\n",
      "epoch: 13  batch: 96 / 122  loss: 0.035746547561151  hr: 0  min: 16  sec: 2\n",
      "epoch: 13  batch: 97 / 122  loss: 0.03538431101940697  hr: 0  min: 15  sec: 56\n",
      "epoch: 13  batch: 98 / 122  loss: 0.03502791101702166  hr: 0  min: 15  sec: 50\n",
      "epoch: 13  batch: 99 / 122  loss: 0.0346782364302804  hr: 0  min: 15  sec: 43\n",
      "epoch: 13  batch: 100 / 122  loss: 0.03435252693190705  hr: 0  min: 15  sec: 37\n",
      "Validation Loss after 100 batches: 1.5603659003973007\n",
      "epoch: 13  batch: 101 / 122  loss: 0.03401476469874672  hr: 0  min: 15  sec: 29\n",
      "epoch: 13  batch: 102 / 122  loss: 0.033683757221653794  hr: 0  min: 15  sec: 20\n",
      "epoch: 13  batch: 103 / 122  loss: 0.03336030830534795  hr: 0  min: 15  sec: 13\n",
      "epoch: 13  batch: 104 / 122  loss: 0.033042070996089024  hr: 0  min: 15  sec: 6\n",
      "epoch: 13  batch: 105 / 122  loss: 0.03273044436119519  hr: 0  min: 14  sec: 58\n",
      "epoch: 13  batch: 106 / 122  loss: 0.032424146501278235  hr: 0  min: 14  sec: 50\n",
      "epoch: 13  batch: 107 / 122  loss: 0.03212539235058689  hr: 0  min: 14  sec: 43\n",
      "epoch: 13  batch: 108 / 122  loss: 0.03296155071694994  hr: 0  min: 14  sec: 36\n",
      "epoch: 13  batch: 109 / 122  loss: 0.03266169034666062  hr: 0  min: 14  sec: 30\n",
      "epoch: 13  batch: 110 / 122  loss: 0.032373890045644  hr: 0  min: 14  sec: 22\n",
      "epoch: 13  batch: 111 / 122  loss: 0.03208410863865267  hr: 0  min: 14  sec: 14\n",
      "epoch: 13  batch: 112 / 122  loss: 0.031801367903816366  hr: 0  min: 14  sec: 6\n",
      "epoch: 13  batch: 113 / 122  loss: 0.03179133791590843  hr: 0  min: 13  sec: 59\n",
      "epoch: 13  batch: 114 / 122  loss: 0.03151517139779396  hr: 0  min: 13  sec: 53\n",
      "epoch: 13  batch: 115 / 122  loss: 0.031243517812918467  hr: 0  min: 13  sec: 46\n",
      "epoch: 13  batch: 116 / 122  loss: 0.030978406900650388  hr: 0  min: 13  sec: 38\n",
      "epoch: 13  batch: 117 / 122  loss: 0.03071567321441964  hr: 0  min: 13  sec: 30\n",
      "epoch: 13  batch: 118 / 122  loss: 0.030457245134669592  hr: 0  min: 13  sec: 24\n",
      "epoch: 13  batch: 119 / 122  loss: 0.03020416503745726  hr: 0  min: 13  sec: 18\n",
      "epoch: 13  batch: 120 / 122  loss: 0.029954731458080155  hr: 0  min: 13  sec: 10\n",
      "epoch: 13  batch: 121 / 122  loss: 0.029710728379037647  hr: 0  min: 13  sec: 2\n",
      "epoch: 13  batch: 122 / 122  loss: 0.029470489944854263  hr: 0  min: 12  sec: 56\n",
      "Learning rate: 1.4814814814814815e-06\n",
      "epoch: 14  batch: 1 / 122  loss: 0.014986656606197357  hr: 0  min: 12  sec: 6\n",
      "epoch: 14  batch: 2 / 122  loss: 0.21913620457053185  hr: 0  min: 11  sec: 42\n",
      "epoch: 14  batch: 3 / 122  loss: 0.14634072567181042  hr: 0  min: 11  sec: 27\n",
      "epoch: 14  batch: 4 / 122  loss: 0.11087955863331445  hr: 0  min: 12  sec: 41\n",
      "epoch: 14  batch: 5 / 122  loss: 0.09567430878523737  hr: 0  min: 12  sec: 10\n",
      "epoch: 14  batch: 6 / 122  loss: 0.07978130084423658  hr: 0  min: 13  sec: 4\n",
      "epoch: 14  batch: 7 / 122  loss: 0.06847613251635007  hr: 0  min: 13  sec: 36\n",
      "epoch: 14  batch: 8 / 122  loss: 0.05997906300035538  hr: 0  min: 13  sec: 0\n",
      "epoch: 14  batch: 9 / 122  loss: 0.05343355231323383  hr: 0  min: 12  sec: 38\n",
      "epoch: 14  batch: 10 / 122  loss: 0.04813647825212684  hr: 0  min: 12  sec: 16\n",
      "epoch: 14  batch: 11 / 122  loss: 0.04385490394567817  hr: 0  min: 12  sec: 12\n",
      "epoch: 14  batch: 12 / 122  loss: 0.040260279335295  hr: 0  min: 11  sec: 54\n",
      "epoch: 14  batch: 13 / 122  loss: 0.03719499772817541  hr: 0  min: 11  sec: 46\n",
      "epoch: 14  batch: 14 / 122  loss: 0.03465802910380132  hr: 0  min: 11  sec: 37\n",
      "epoch: 14  batch: 15 / 122  loss: 0.0324509794144736  hr: 0  min: 11  sec: 33\n",
      "epoch: 14  batch: 16 / 122  loss: 0.03046829140112095  hr: 0  min: 11  sec: 31\n",
      "epoch: 14  batch: 17 / 122  loss: 0.028708688570665854  hr: 0  min: 11  sec: 16\n",
      "epoch: 14  batch: 18 / 122  loss: 0.027133405855339434  hr: 0  min: 11  sec: 1\n",
      "epoch: 14  batch: 19 / 122  loss: 0.025730705464650925  hr: 0  min: 11  sec: 6\n",
      "epoch: 14  batch: 20 / 122  loss: 0.02457682092208415  hr: 0  min: 10  sec: 55\n",
      "epoch: 14  batch: 21 / 122  loss: 0.027113721949890965  hr: 0  min: 10  sec: 59\n",
      "epoch: 14  batch: 22 / 122  loss: 0.02589975818012714  hr: 0  min: 10  sec: 51\n",
      "epoch: 14  batch: 23 / 122  loss: 0.024793215220004484  hr: 0  min: 10  sec: 44\n",
      "epoch: 14  batch: 24 / 122  loss: 0.023785052973835263  hr: 0  min: 10  sec: 33\n",
      "epoch: 14  batch: 25 / 122  loss: 0.022854274108540268  hr: 0  min: 10  sec: 26\n",
      "epoch: 14  batch: 26 / 122  loss: 0.021989445775174178  hr: 0  min: 10  sec: 14\n",
      "epoch: 14  batch: 27 / 122  loss: 0.02119304396263841  hr: 0  min: 10  sec: 7\n",
      "epoch: 14  batch: 28 / 122  loss: 0.02045773173033792  hr: 0  min: 10  sec: 0\n",
      "epoch: 14  batch: 29 / 122  loss: 0.0344313289689157  hr: 0  min: 9  sec: 54\n",
      "epoch: 14  batch: 30 / 122  loss: 0.03336501665956651  hr: 0  min: 9  sec: 48\n",
      "epoch: 14  batch: 31 / 122  loss: 0.032307436946974764  hr: 0  min: 9  sec: 41\n",
      "epoch: 14  batch: 32 / 122  loss: 0.03130779432376585  hr: 0  min: 9  sec: 34\n",
      "epoch: 14  batch: 33 / 122  loss: 0.030394909532112775  hr: 0  min: 9  sec: 26\n",
      "epoch: 14  batch: 34 / 122  loss: 0.029514529619893225  hr: 0  min: 9  sec: 22\n",
      "epoch: 14  batch: 35 / 122  loss: 0.028684593127608033  hr: 0  min: 9  sec: 19\n",
      "epoch: 14  batch: 36 / 122  loss: 0.027898815196951747  hr: 0  min: 9  sec: 10\n",
      "epoch: 14  batch: 37 / 122  loss: 0.027161406565495337  hr: 0  min: 9  sec: 3\n",
      "epoch: 14  batch: 38 / 122  loss: 0.026456266924996225  hr: 0  min: 8  sec: 57\n",
      "epoch: 14  batch: 39 / 122  loss: 0.025804045151931066  hr: 0  min: 8  sec: 47\n",
      "epoch: 14  batch: 40 / 122  loss: 0.025171697558835148  hr: 0  min: 8  sec: 49\n",
      "epoch: 14  batch: 41 / 122  loss: 0.024569410945021932  hr: 0  min: 8  sec: 42\n",
      "epoch: 14  batch: 42 / 122  loss: 0.02401245052585312  hr: 0  min: 8  sec: 36\n",
      "epoch: 14  batch: 43 / 122  loss: 0.02394330613978402  hr: 0  min: 8  sec: 29\n",
      "epoch: 14  batch: 44 / 122  loss: 0.023407815976745704  hr: 0  min: 8  sec: 22\n",
      "epoch: 14  batch: 45 / 122  loss: 0.02289812690901777  hr: 0  min: 8  sec: 18\n",
      "epoch: 14  batch: 46 / 122  loss: 0.022410499646313205  hr: 0  min: 8  sec: 9\n",
      "epoch: 14  batch: 47 / 122  loss: 0.021957977291597847  hr: 0  min: 8  sec: 1\n",
      "epoch: 14  batch: 48 / 122  loss: 0.021508497209651978  hr: 0  min: 7  sec: 53\n",
      "epoch: 14  batch: 49 / 122  loss: 0.021098008022372782  hr: 0  min: 7  sec: 45\n",
      "epoch: 14  batch: 50 / 122  loss: 0.021791031644097528  hr: 0  min: 7  sec: 37\n",
      "epoch: 14  batch: 51 / 122  loss: 0.021372501794865134  hr: 0  min: 7  sec: 30\n",
      "epoch: 14  batch: 52 / 122  loss: 0.020985606864717107  hr: 0  min: 7  sec: 24\n",
      "epoch: 14  batch: 53 / 122  loss: 0.026583678409224376  hr: 0  min: 7  sec: 16\n",
      "epoch: 14  batch: 54 / 122  loss: 0.02611550128171479  hr: 0  min: 7  sec: 15\n",
      "epoch: 14  batch: 55 / 122  loss: 0.025649953696516934  hr: 0  min: 7  sec: 8\n",
      "epoch: 14  batch: 56 / 122  loss: 0.025199345761523415  hr: 0  min: 7  sec: 0\n",
      "epoch: 14  batch: 57 / 122  loss: 0.027366719534927  hr: 0  min: 6  sec: 53\n",
      "epoch: 14  batch: 58 / 122  loss: 0.026903026890318746  hr: 0  min: 6  sec: 44\n",
      "epoch: 14  batch: 59 / 122  loss: 0.026496301748951644  hr: 0  min: 6  sec: 37\n",
      "epoch: 14  batch: 60 / 122  loss: 0.026063143334370882  hr: 0  min: 6  sec: 31\n",
      "epoch: 14  batch: 61 / 122  loss: 0.025640786315322104  hr: 0  min: 6  sec: 24\n",
      "epoch: 14  batch: 62 / 122  loss: 0.025242476276264737  hr: 0  min: 6  sec: 19\n",
      "epoch: 14  batch: 63 / 122  loss: 0.024849370394515555  hr: 0  min: 6  sec: 12\n",
      "epoch: 14  batch: 64 / 122  loss: 0.024596826616289036  hr: 0  min: 6  sec: 5\n",
      "epoch: 14  batch: 65 / 122  loss: 0.024224473257961038  hr: 0  min: 5  sec: 57\n",
      "epoch: 14  batch: 66 / 122  loss: 0.02386471919696002  hr: 0  min: 5  sec: 51\n",
      "epoch: 14  batch: 67 / 122  loss: 0.023884375091840222  hr: 0  min: 5  sec: 46\n",
      "epoch: 14  batch: 68 / 122  loss: 0.02354180116697749  hr: 0  min: 5  sec: 39\n",
      "epoch: 14  batch: 69 / 122  loss: 0.023208734779736784  hr: 0  min: 5  sec: 32\n",
      "epoch: 14  batch: 70 / 122  loss: 0.022956425381874267  hr: 0  min: 5  sec: 24\n",
      "epoch: 14  batch: 71 / 122  loss: 0.022638400870254  hr: 0  min: 5  sec: 17\n",
      "epoch: 14  batch: 72 / 122  loss: 0.022329090177259384  hr: 0  min: 5  sec: 11\n",
      "epoch: 14  batch: 73 / 122  loss: 0.022144959909021728  hr: 0  min: 5  sec: 5\n",
      "epoch: 14  batch: 74 / 122  loss: 0.021852249158090108  hr: 0  min: 4  sec: 59\n",
      "epoch: 14  batch: 75 / 122  loss: 0.021565715638765446  hr: 0  min: 4  sec: 52\n",
      "epoch: 14  batch: 76 / 122  loss: 0.021306016233498475  hr: 0  min: 4  sec: 48\n",
      "epoch: 14  batch: 77 / 122  loss: 0.021036938228946808  hr: 0  min: 4  sec: 42\n",
      "epoch: 14  batch: 78 / 122  loss: 0.020774723393305276  hr: 0  min: 4  sec: 35\n",
      "epoch: 14  batch: 79 / 122  loss: 0.020517373665330248  hr: 0  min: 4  sec: 28\n",
      "epoch: 14  batch: 80 / 122  loss: 0.020269760074734224  hr: 0  min: 4  sec: 22\n",
      "epoch: 14  batch: 81 / 122  loss: 0.021656856818963992  hr: 0  min: 4  sec: 16\n",
      "epoch: 14  batch: 82 / 122  loss: 0.021396956480358068  hr: 0  min: 4  sec: 10\n",
      "epoch: 14  batch: 83 / 122  loss: 0.021151817825914597  hr: 0  min: 4  sec: 4\n",
      "epoch: 14  batch: 84 / 122  loss: 0.020905321964251232  hr: 0  min: 3  sec: 57\n",
      "epoch: 14  batch: 85 / 122  loss: 0.02067301640396609  hr: 0  min: 3  sec: 51\n",
      "epoch: 14  batch: 86 / 122  loss: 0.020438935631360903  hr: 0  min: 3  sec: 44\n",
      "epoch: 14  batch: 87 / 122  loss: 0.02021159470648687  hr: 0  min: 3  sec: 39\n",
      "epoch: 14  batch: 88 / 122  loss: 0.02137884632313878  hr: 0  min: 3  sec: 32\n",
      "epoch: 14  batch: 89 / 122  loss: 0.02114637581804202  hr: 0  min: 3  sec: 27\n",
      "epoch: 14  batch: 90 / 122  loss: 0.02115535782262062  hr: 0  min: 3  sec: 21\n",
      "epoch: 14  batch: 91 / 122  loss: 0.020927676611521107  hr: 0  min: 3  sec: 15\n",
      "epoch: 14  batch: 92 / 122  loss: 0.020704391097989053  hr: 0  min: 3  sec: 8\n",
      "epoch: 14  batch: 93 / 122  loss: 0.020486307694383907  hr: 0  min: 3  sec: 2\n",
      "epoch: 14  batch: 94 / 122  loss: 0.020379467018659503  hr: 0  min: 2  sec: 57\n",
      "epoch: 14  batch: 95 / 122  loss: 0.020176658554823677  hr: 0  min: 2  sec: 50\n",
      "epoch: 14  batch: 96 / 122  loss: 0.019970401631023076  hr: 0  min: 2  sec: 44\n",
      "epoch: 14  batch: 97 / 122  loss: 0.02020809508934521  hr: 0  min: 2  sec: 39\n",
      "epoch: 14  batch: 98 / 122  loss: 0.020006421539155595  hr: 0  min: 2  sec: 32\n",
      "epoch: 14  batch: 99 / 122  loss: 0.019808616647038212  hr: 0  min: 2  sec: 26\n",
      "epoch: 14  batch: 100 / 122  loss: 0.019725050672714132  hr: 0  min: 2  sec: 19\n",
      "Validation Loss after 100 batches: 1.5648563921451568\n",
      "epoch: 14  batch: 101 / 122  loss: 0.019532298299513924  hr: 0  min: 2  sec: 13\n",
      "epoch: 14  batch: 102 / 122  loss: 0.019396166197610927  hr: 0  min: 2  sec: 6\n",
      "epoch: 14  batch: 103 / 122  loss: 0.01921023642791218  hr: 0  min: 2  sec: 0\n",
      "epoch: 14  batch: 104 / 122  loss: 0.019027475248899115  hr: 0  min: 1  sec: 53\n",
      "epoch: 14  batch: 105 / 122  loss: 0.018848997463438925  hr: 0  min: 1  sec: 47\n",
      "epoch: 14  batch: 106 / 122  loss: 0.01867577296276445  hr: 0  min: 1  sec: 40\n",
      "epoch: 14  batch: 107 / 122  loss: 0.018503404464643387  hr: 0  min: 1  sec: 34\n",
      "epoch: 14  batch: 108 / 122  loss: 0.01833458268689962  hr: 0  min: 1  sec: 28\n",
      "epoch: 14  batch: 109 / 122  loss: 0.01816839305643919  hr: 0  min: 1  sec: 22\n",
      "epoch: 14  batch: 110 / 122  loss: 0.01800534909403227  hr: 0  min: 1  sec: 15\n",
      "epoch: 14  batch: 111 / 122  loss: 0.017845569904091314  hr: 0  min: 1  sec: 9\n",
      "epoch: 14  batch: 112 / 122  loss: 0.01768825896812944  hr: 0  min: 1  sec: 3\n",
      "epoch: 14  batch: 113 / 122  loss: 0.017534578350924812  hr: 0  min: 0  sec: 56\n",
      "epoch: 14  batch: 114 / 122  loss: 0.01738290885272395  hr: 0  min: 0  sec: 50\n",
      "epoch: 14  batch: 115 / 122  loss: 0.017234732224302284  hr: 0  min: 0  sec: 44\n",
      "epoch: 14  batch: 116 / 122  loss: 0.017088057646795843  hr: 0  min: 0  sec: 37\n",
      "epoch: 14  batch: 117 / 122  loss: 0.01694393120845382  hr: 0  min: 0  sec: 31\n",
      "epoch: 14  batch: 118 / 122  loss: 0.016802222457476614  hr: 0  min: 0  sec: 25\n",
      "epoch: 14  batch: 119 / 122  loss: 0.016662555346862187  hr: 0  min: 0  sec: 18\n",
      "epoch: 14  batch: 120 / 122  loss: 0.01653582745178331  hr: 0  min: 0  sec: 12\n",
      "epoch: 14  batch: 121 / 122  loss: 0.016400890705302696  hr: 0  min: 0  sec: 6\n",
      "epoch: 14  batch: 122 / 122  loss: 0.016268161699923945  hr: 0  min: 0  sec: 0\n",
      "Learning rate: 0.0\n",
      "Early stopping!\n",
      "CPU times: total: 1h 44min 51s\n",
      "Wall time: 3h 53min 49s\n"
     ]
    }
   ],
   "source": [
    "%time train_model_ABSA(train_loader, validation_loader, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emink\\AppData\\Local\\Temp\\ipykernel_8704\\1419488891.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(path), strict=False)\n"
     ]
    }
   ],
   "source": [
    "model_ABSA = load_model(model_ABSA, 'bert_ABSA6.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 50s\n",
      "Wall time: 1min 21s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.89      0.77       196\n",
      "           1       0.64      0.43      0.52       196\n",
      "           2       0.78      0.79      0.78       227\n",
      "\n",
      "    accuracy                           0.71       619\n",
      "   macro avg       0.70      0.70      0.69       619\n",
      "weighted avg       0.70      0.71      0.70       619\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%time x, y = test_model_ABSA(test_loader)\n",
    "print(classification_report(x, y, target_names=[str(i) for i in range(3)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATE + ABSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_model_ABSA(sentence, aspect, tokenizer):\n",
    "    t1 = tokenizer.tokenize(sentence)\n",
    "    t2 = tokenizer.tokenize(aspect)\n",
    "\n",
    "    word_pieces = ['[cls]']\n",
    "    word_pieces += t1\n",
    "    word_pieces += ['[sep]']\n",
    "    word_pieces += t2\n",
    "\n",
    "    segment_tensor = [0] + [0]*len(t1) + [0] + [1]*len(t2)\n",
    "\n",
    "    ids = tokenizer.convert_tokens_to_ids(word_pieces)\n",
    "    input_tensor = torch.tensor([ids]).to(DEVICE)\n",
    "    segment_tensor = torch.tensor(segment_tensor).to(DEVICE)\n",
    "\n",
    "    print(f\"Tokens: {word_pieces}\")\n",
    "    print(f\"Segment Tensor: {segment_tensor}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model_ABSA(input_tensor, None, None, segments_tensors=segment_tensor)\n",
    "        _, predictions = torch.max(outputs, dim=1)\n",
    "    \n",
    "    return word_pieces, predictions, outputs\n",
    "\n",
    "def predict_model_ATE(sentence, tokenizer):\n",
    "    word_pieces = []\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    word_pieces += tokens\n",
    "\n",
    "    ids = tokenizer.convert_tokens_to_ids(word_pieces)\n",
    "    input_tensor = torch.tensor([ids]).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model_ATE(input_tensor, None, None)\n",
    "        _, predictions = torch.max(outputs, dim=2)\n",
    "    predictions = predictions[0].tolist()\n",
    "\n",
    "    return word_pieces, predictions, outputs\n",
    "\n",
    "def ATE_ABSA(text):\n",
    "    terms = []\n",
    "    word = \"\"\n",
    "    \n",
    "    # ATE\n",
    "    x, y, _ = predict_model_ATE(text, tokenizer)\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == 1:  # Start of a new term\n",
    "            if len(word) != 0:\n",
    "                terms.append(word.replace(\" ##\", \"\"))\n",
    "            word = x[i]\n",
    "        elif y[i] == 2:  # Continuation of the term\n",
    "            if x[i].startswith(\"##\"):\n",
    "                word += x[i][2:]  # Remove the '##' prefix\n",
    "            else:\n",
    "                word += \" \" + x[i]\n",
    "        else:\n",
    "            if len(word) != 0:\n",
    "                terms.append(word.replace(\" ##\", \"\"))\n",
    "                word = \"\"\n",
    "    if len(word) != 0:\n",
    "        terms.append(word.replace(\" ##\", \"\"))  # Add the last term\n",
    "    \n",
    "    print(\"tokens:\", x)\n",
    "    print(\"ATE:\", terms)\n",
    "\n",
    "    # ABSA\n",
    "    if len(terms) != 0:\n",
    "        for term in terms:\n",
    "            _, sentiment_class, sentiment_logits = predict_model_ABSA(text, term, tokenizer)\n",
    "\n",
    "####################################################################################\n",
    "# def ATE_ABSA(text):\n",
    "#     terms = []\n",
    "#     current_term = \"\"\n",
    "    \n",
    "#     # ATE: Aspect Term Extraction\n",
    "#     tokens, predictions, _ = predict_model_ATE(text, tokenizer)\n",
    "#     for token, tag in zip(tokens, predictions):\n",
    "#         if tag == 1:  # Start of a new term\n",
    "#             if current_term:  # Append the previous term if it exists\n",
    "#                 terms.append(current_term.strip())  # Finalize the previous term\n",
    "#             current_term = token  # Start a new term\n",
    "#         elif tag == 2:  # Continuation of the term\n",
    "#             if current_term:\n",
    "#                 if token.startswith(\"##\"):\n",
    "#                     current_term += token[2:]  # Append subword without '##'\n",
    "#                 else:\n",
    "#                     current_term += \" \" + token\n",
    "#             else:\n",
    "#                 # Handle unexpected cases where continuation appears without a start\n",
    "#                 current_term = token\n",
    "#         else:  # Tag is 0 (outside)\n",
    "#             if current_term:  # Append the previous term if it exists\n",
    "#                 terms.append(current_term.strip())\n",
    "#                 current_term = \"\"\n",
    "#     if current_term:\n",
    "#         terms.append(current_term.strip())  # Add the last term\n",
    "\n",
    "#     # **Handle Incorrect Subword Splits**\n",
    "#     terms = [\"\".join(term.split(\" ##\")) for term in terms]\n",
    "\n",
    "#     print(\"Tokens:\", tokens)\n",
    "#     print(\"Extracted Aspect Terms (ATE):\", terms)\n",
    "\n",
    "#     # ABSA: Aspect-Based Sentiment Analysis\n",
    "#     results = []\n",
    "#     if terms:\n",
    "#         for term in terms:\n",
    "#             _, sentiment_class, sentiment_logits = predict_model_ABSA(text, term, tokenizer)\n",
    "#             results.append({\n",
    "#                 \"aspect_term\": term,\n",
    "#                 \"sentiment_class\": sentiment_class.item(),\n",
    "#                 \"logits\": sentiment_logits.tolist()\n",
    "#             })\n",
    "    \n",
    "#     # Display Results\n",
    "#     print(\"\\nAspect Terms and Sentiments (ABSA):\")\n",
    "#     for res in results:\n",
    "#         print(f\"Aspect: {res['aspect_term']}, Sentiment Class: {res['sentiment_class']}, Logits: {res['logits']}\")\n",
    "\n",
    "#     return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emink\\AppData\\Local\\Temp\\ipykernel_8704\\1419488891.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(path), strict=False)\n"
     ]
    }
   ],
   "source": [
    "model_ABSA = load_model(model_ABSA, 'bert_ABSA6.pkl')\n",
    "model_ATE = load_model(model_ATE, 'bert_ATE.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['the', 'service', 'was', 'discus', '##ting', '.']\n",
      "ATE: ['service']\n",
      "Tokens: ['[cls]', 'the', 'service', 'was', 'discus', '##ting', '.', '[sep]', 'service']\n",
      "Segment Tensor: tensor([0, 0, 0, 0, 0, 0, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "text = \"the service was discusting.\"\n",
    "ATE_ABSA(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['food', 'was', 'super', 'amazing', '.']\n",
      "ATE: ['food']\n",
      "Tokens: ['[cls]', 'food', 'was', 'super', 'amazing', '.', '[sep]', 'food']\n",
      "Segment Tensor: tensor([0, 0, 0, 0, 0, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "text = \" food was super amazing.\"\n",
    "ATE_ABSA(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['the', 'pasta', 'was', 'delicious', ',', 'but', 'the', 'service', 'was', 'slow', '.']\n",
      "ATE: ['pasta', 'service']\n",
      "Tokens: ['[cls]', 'the', 'pasta', 'was', 'delicious', ',', 'but', 'the', 'service', 'was', 'slow', '.', '[sep]', 'pasta']\n",
      "Segment Tensor: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
      "Tokens: ['[cls]', 'the', 'pasta', 'was', 'delicious', ',', 'but', 'the', 'service', 'was', 'slow', '.', '[sep]', 'service']\n",
      "Segment Tensor: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "text = \"The pasta was delicious, but the service was slow.\"\n",
    "ATE_ABSA(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['the', 'am', '##bian', '##ce', 'was', 'fantastic', ',', 'but', 'the', 'food', 'was', 'over', '##pr', '##ice', '##d', '.']\n",
      "ATE: ['am', '##bian', '##ce', 'food']\n",
      "Tokens: ['[cls]', 'the', 'am', '##bian', '##ce', 'was', 'fantastic', ',', 'but', 'the', 'food', 'was', 'over', '##pr', '##ice', '##d', '.', '[sep]', 'am']\n",
      "Segment Tensor: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
      "Tokens: ['[cls]', 'the', 'am', '##bian', '##ce', 'was', 'fantastic', ',', 'but', 'the', 'food', 'was', 'over', '##pr', '##ice', '##d', '.', '[sep]', '#', '#', 'bi', '##an']\n",
      "Segment Tensor: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1])\n",
      "Tokens: ['[cls]', 'the', 'am', '##bian', '##ce', 'was', 'fantastic', ',', 'but', 'the', 'food', 'was', 'over', '##pr', '##ice', '##d', '.', '[sep]', '#', '#', 'ce']\n",
      "Segment Tensor: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1])\n",
      "Tokens: ['[cls]', 'the', 'am', '##bian', '##ce', 'was', 'fantastic', ',', 'but', 'the', 'food', 'was', 'over', '##pr', '##ice', '##d', '.', '[sep]', 'food']\n",
      "Segment Tensor: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "text = \"The ambiance was fantastic, but the food was overpriced.\"\n",
    "ATE_ABSA(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['the', 'waiter', 'was', 'very', 'friendly', ',', 'and', 'the', 'dessert', '##s', 'were', 'outstanding']\n",
      "ATE: ['waiter', 'dessert', '##s']\n",
      "Tokens: ['[cls]', 'the', 'waiter', 'was', 'very', 'friendly', ',', 'and', 'the', 'dessert', '##s', 'were', 'outstanding', '[sep]', 'waiter']\n",
      "Segment Tensor: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
      "Tokens: ['[cls]', 'the', 'waiter', 'was', 'very', 'friendly', ',', 'and', 'the', 'dessert', '##s', 'were', 'outstanding', '[sep]', 'dessert']\n",
      "Segment Tensor: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
      "Tokens: ['[cls]', 'the', 'waiter', 'was', 'very', 'friendly', ',', 'and', 'the', 'dessert', '##s', 'were', 'outstanding', '[sep]', '#', '#', 's']\n",
      "Segment Tensor: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "text=\"The waiter was very friendly, and the desserts were outstanding\"\n",
    "ATE_ABSA(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
